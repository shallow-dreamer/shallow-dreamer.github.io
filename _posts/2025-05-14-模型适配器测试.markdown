---
layout:     post
title:      "æ¨¡å‹é€‚é…å™¨æµ‹è¯•"
subtitle:   ""
date:       2025-05-14
author:     " Shallow Dreamer"
header-img: "img/post-bg-js-version.jpg"
tags:
    - torch
---

ä¸ºäº†è®¾è®¡ä¸€ä¸ªé€šç”¨çš„ **æ¨¡å‹è®­ç»ƒæµç¨‹æ¡†æ¶**ï¼Œèƒ½å¤Ÿé€‚é…å¤šç§æ¨¡å‹ç±»å‹ï¼ˆå¦‚çº¿æ€§å›å½’ã€æ•°æ®åˆ†æã€å¤§è¯­è¨€æ¨¡å‹ç­‰ï¼‰ï¼Œæœ€å¥½çš„æ–¹æ³•æ˜¯ä½¿ç”¨ **â€œé€‚é…å™¨æ¨¡å¼ï¼ˆAdapter Patternï¼‰â€** æ¥å°è£…ä¸åŒç±»å‹æ¨¡å‹çš„å·®å¼‚ï¼Œä½¿å®ƒä»¬ç»Ÿä¸€å®ç°ä¸€å¥—è®­ç»ƒå’Œè¯„ä¼°æ¥å£ï¼Œä¾¿äºè°ƒåº¦ã€ç®¡ç†ã€æ—¥å¿—è®°å½•ã€ç»“æœå±•ç¤ºç­‰ã€‚

------

## ğŸ§© ä¸€ã€æ ¸å¿ƒè®¾è®¡ç†å¿µ

- **ç»Ÿä¸€æ¥å£**ï¼šå®šä¹‰ä¸€ä¸ªæŠ½è±¡åŸºç±» `BaseModelAdapter`ï¼Œæ‰€æœ‰æ¨¡å‹é€‚é…å™¨ç»§æ‰¿å®ƒï¼Œå®ç°ç»Ÿä¸€çš„æ–¹æ³•ã€‚
- **é€‚é…å™¨ç±»**ï¼šé’ˆå¯¹ä¸åŒæ¨¡å‹ç±»å‹ï¼ˆå¦‚çº¿æ€§å›å½’ã€å¤§è¯­è¨€æ¨¡å‹ç­‰ï¼‰å®šä¹‰å¯¹åº”çš„é€‚é…å™¨ç±»ã€‚
- **è®­ç»ƒç®¡ç†å™¨**ï¼šæä¾›ç»Ÿä¸€çš„æ¨¡å‹è°ƒåº¦ã€è®­ç»ƒæ‰§è¡Œã€æ—¥å¿—æ”¶é›†ã€çŠ¶æ€ä¿å­˜ç­‰åŠŸèƒ½ã€‚
- **å¯æ‰©å±•æ€§å¼º**ï¼šæ–°å¢æ¨¡å‹ç±»å‹æ—¶ï¼Œåªéœ€æ–°å¢é€‚é…å™¨å¹¶æ³¨å†Œå³å¯ï¼Œæ— éœ€æ”¹åŠ¨ä¸»æµç¨‹ã€‚

------

## ğŸ“¦ äºŒã€ç›®å½•ç»“æ„å»ºè®®ï¼ˆDjango + Pythonï¼‰

```
ai_platform/
â”œâ”€â”€ adapters/                 # æ‰€æœ‰æ¨¡å‹é€‚é…å™¨
â”‚   â”œâ”€â”€ base.py              # BaseModelAdapter æŠ½è±¡ç±»
â”‚   â”œâ”€â”€ linear.py            # çº¿æ€§å›å½’é€‚é…å™¨
â”‚   â”œâ”€â”€ analysis.py          # æ•°æ®åˆ†æé€‚é…å™¨
â”‚   â””â”€â”€ llm.py               # å¤§è¯­è¨€æ¨¡å‹é€‚é…å™¨
â”œâ”€â”€ services/
â”‚   â””â”€â”€ trainer.py           # ç»Ÿä¸€è®­ç»ƒå™¨/ä»»åŠ¡ç®¡ç†å™¨
â”œâ”€â”€ models/
â”‚   â””â”€â”€ task.py              # ModelTrainTask ç­‰ä»»åŠ¡æ¨¡å‹
â””â”€â”€ utils/
    â””â”€â”€ logger.py            # æ—¥å¿—å·¥å…·
```

------

## ğŸ§± ä¸‰ã€æ ¸å¿ƒæ¥å£å®šä¹‰

### âœ… `BaseModelAdapter`ï¼ˆæŠ½è±¡åŸºç±»ï¼‰

```python
# adapters/base.py
from abc import ABC, abstractmethod

class BaseModelAdapter(ABC):
    def __init__(self, config, dataset):
        self.config = config      # ç”¨æˆ·é…ç½®å‚æ•°
        self.dataset = dataset    # æ•°æ®é›†å¯¹è±¡æˆ–è·¯å¾„

    @abstractmethod
    def preprocess(self):
        """é¢„å¤„ç†æ•°æ®"""
        pass

    @abstractmethod
    def train(self):
        """æ¨¡å‹è®­ç»ƒä¸»é€»è¾‘"""
        pass

    @abstractmethod
    def evaluate(self):
        """æ¨¡å‹è¯„ä¼°é€»è¾‘"""
        pass

    @abstractmethod
    def save_model(self, output_path):
        """ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶/æ•°æ®åº“"""
        pass
```

------

## ğŸ§  å››ã€æ¨¡å‹é€‚é…å™¨ç¤ºä¾‹

### 1ï¸âƒ£ çº¿æ€§å›å½’é€‚é…å™¨

```python
# adapters/linear.py
from .base import BaseModelAdapter
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import joblib

class LinearRegressionAdapter(BaseModelAdapter):
    def preprocess(self):
        self.X = self.dataset.drop(columns=['target'])
        self.y = self.dataset['target']

    def train(self):
        self.model = LinearRegression()
        self.model.fit(self.X, self.y)

    def evaluate(self):
        y_pred = self.model.predict(self.X)
        return {"mse": mean_squared_error(self.y, y_pred)}

    def save_model(self, output_path):
        joblib.dump(self.model, output_path)
```

------

### 2ï¸âƒ£ å¤§è¯­è¨€æ¨¡å‹é€‚é…å™¨ï¼ˆå¦‚è°ƒç”¨ OpenAI GPTï¼‰

```python
# adapters/llm.py
from .base import BaseModelAdapter
import openai

class LLMAdapter(BaseModelAdapter):
    def preprocess(self):
        self.prompt = self.config.get("prompt", "")

    def train(self):
        # é€šå¸¸å¤§è¯­è¨€æ¨¡å‹æ˜¯ zero/few-shotï¼Œæ— éœ€è®­ç»ƒï¼Œåªæ¨ç†
        self.output = openai.ChatCompletion.create(
            model=self.config.get("model", "gpt-4"),
            messages=[{"role": "user", "content": self.prompt}],
            temperature=self.config.get("temperature", 0.7)
        )

    def evaluate(self):
        return {"output": self.output["choices"][0]["message"]["content"]}

    def save_model(self, output_path):
        # LLM æ¨¡å‹æ— æ³•æœ¬åœ°ä¿å­˜ï¼Œä»…è®°å½• prompt & output
        with open(output_path, 'w') as f:
            f.write(self.output["choices"][0]["message"]["content"])
```

------

## âš™ï¸ äº”ã€è®­ç»ƒä»»åŠ¡ç®¡ç†å™¨ï¼ˆè®­ç»ƒå…¥å£ï¼‰

```python
# services/trainer.py
from adapters.linear import LinearRegressionAdapter
from adapters.llm import LLMAdapter

# æ³¨å†Œé€‚é…å™¨
ADAPTER_REGISTRY = {
    "linear_regression": LinearRegressionAdapter,
    "llm": LLMAdapter,
    # å¯æ‹“å±•æ›´å¤šæ¨¡å‹
}

class ModelTrainer:
    def __init__(self, task_config, dataset):
        self.task_type = task_config["task_type"]
        self.adapter_class = ADAPTER_REGISTRY.get(self.task_type)

        if not self.adapter_class:
            raise ValueError(f"Unsupported model type: {self.task_type}")

        self.adapter = self.adapter_class(task_config, dataset)

    def run(self):
        self.adapter.preprocess()
        self.adapter.train()
        results = self.adapter.evaluate()
        self.adapter.save_model(self._output_path())
        return results

    def _output_path(self):
        return f"/tmp/models/{self.task_type}_result.pkl"
```

------

## ğŸ”Œ å…­ã€ä½¿ç”¨æ–¹å¼ï¼ˆDjango è§†å›¾æˆ– Celery ä¸­è°ƒç”¨ï¼‰

```python
from services.trainer import ModelTrainer
from datasets.utils import load_dataset  # è‡ªå®šä¹‰å‡½æ•°ï¼šä»æ•°æ®åº“æˆ– S3 è½½å…¥æ•°æ®

def train_model(task_id):
    task_config = {
        "task_type": "linear_regression",
        "learning_rate": 0.01,
        "prompt": "æ€»ç»“è¿™æ®µæ–‡æœ¬...",
    }
    dataset = load_dataset(task_id)
    trainer = ModelTrainer(task_config, dataset)
    result = trainer.run()
    return result
```

------

## ğŸ§® ä¸ƒã€æ¨¡å‹é…ç½®å­—æ®µå»ºè®®

| å­—æ®µå           | å«ä¹‰                                          | æ¨¡å‹ç±»å‹   |
| ---------------- | --------------------------------------------- | ---------- |
| `task_type`      | æ¨¡å‹ä»»åŠ¡ç±»å‹ï¼ˆå¦‚ `llm`, `linear_regression`ï¼‰ | æ‰€æœ‰       |
| `learning_rate`  | å­¦ä¹ ç‡                                        | ML/DL æ¨¡å‹ |
| `prompt`         | è¾“å…¥æç¤ºæ–‡æœ¬                                  | LLM        |
| `temperature`    | æ§åˆ¶ LLM è¾“å‡ºçš„éšæœºæ€§                         | LLM        |
| `max_iterations` | æœ€å¤§è®­ç»ƒè½®æ•°                                  | ML æ¨¡å‹    |
| `target_column`  | æ ‡ç­¾åˆ—å                                      | ML æ¨¡å‹    |
| `model_name`     | é¢„è®¾æ¨¡å‹åï¼ˆå¦‚ `gpt-4`, `glm` ç­‰ï¼‰            | LLM        |

------

## âœ… å…«ã€ä¼˜åŠ¿æ€»ç»“

- **è§£è€¦å¼º**ï¼šæ¯ç§æ¨¡å‹é€‚é…å™¨ç‹¬ç«‹å®ç°ï¼Œä¸ä¼šç›¸äº’å½±å“ã€‚
- **æ˜“æ‰©å±•**ï¼šæ–°å¢æ¨¡å‹åªéœ€æ·»åŠ ä¸€ä¸ªç±»å¹¶æ³¨å†Œã€‚
- **æ¥å£ç»Ÿä¸€**ï¼šä¸»è®­ç»ƒé€»è¾‘å’Œè°ƒç”¨æ–¹å¼ä¸å˜ï¼Œä¾¿äºç»Ÿä¸€æ—¥å¿—ã€çŠ¶æ€ç®¡ç†ã€èµ„æºè°ƒåº¦ã€‚
- **é€‚åˆå¹³å°åŒ–**ï¼šéå¸¸é€‚ç”¨äº AI å¹³å°ã€AutoML ç³»ç»Ÿã€è®­ç»ƒå¹³å°æ„å»ºã€‚

------

å¦‚æœä½ æœ‰ç‰¹å®šæ¨¡å‹ã€ç‰¹å®šè¾“å…¥/è¾“å‡ºéœ€æ±‚ï¼ˆæ¯”å¦‚å›¾åƒã€å¤šåˆ†ç±»ã€æ—¶åºé¢„æµ‹ç­‰ï¼‰ï¼Œæˆ‘å¯ä»¥å¸®ä½ è¿›ä¸€æ­¥æ‰©å±•å¯¹åº”çš„é€‚é…å™¨ç±»ã€‚

éœ€è¦æˆ‘ç»§ç»­å¸®ä½ å®Œå–„æ•°æ®åº“æ¨¡å‹è®¾è®¡ã€Celery ä»»åŠ¡å°è£…ã€å‰ç«¯å¯¹æ¥å»ºè®®å—ï¼Ÿ

äº†è§£äº†ï¼Œæˆ‘å°†åŸºäºä½ çš„è¦æ±‚é‡æ–°è®¾è®¡å¹¶ç²¾ç®€è®­ç»ƒä¸é¢„æµ‹æµç¨‹ï¼š

- ä»æ•°æ®åº“ä¸­çš„æ¨¡å‹æ¨¡æ¿è¡¨åŠ è½½æŒ‡å®šæ¨¡å‹ç±»å‹çš„é»˜è®¤å‚æ•°ï¼›
- ä¸å‰ç«¯ä¼ å…¥çš„æ¨¡å‹å‚æ•°è¿›è¡Œåˆå¹¶ï¼ˆå‰ç«¯å€¼ä¼˜å…ˆï¼‰ï¼›
- ä½¿ç”¨é€‚é…å™¨æ¨¡å¼å®Œæˆæ¸…æ´—ã€é¢„å¤„ç†ã€è®­ç»ƒã€ä¿å­˜ã€å‘å¸ƒã€é¢„æµ‹çš„å…¨æµç¨‹ï¼›
- æ‰€æœ‰ç»“æ„è§£è€¦ã€æ¥å£æ¸…æ™°ã€é€»è¾‘æ˜“è¯»å¯ç»´æŠ¤ã€‚

æˆ‘ä¼šè¾“å‡ºå…³é”®æ¨¡å—ä»£ç å’Œè¯´æ˜ï¼Œç¡®ä¿ä½ èƒ½ç›´æ¥é›†æˆä½¿ç”¨ã€‚è¯·ç¨ç­‰ï¼Œæˆ‘æ•´ç†å®Œå°±å‘Šè¯‰ä½ ã€‚

# åç«¯æ¨¡å‹è®­ç»ƒä¸é¢„æµ‹æµç¨‹è®¾è®¡

## æ¶æ„æ¦‚è¿°

æ•°æ®ç®¡é“æ˜¯ä¸€ç§è‡ªåŠ¨åŒ–çš„æ•°æ®å¤„ç†å·¥å…·ï¼Œå®ƒå¯ä»¥ä»å¤šä¸ªæºè·å–æ•°æ®ï¼Œå¯¹å…¶è¿›è¡Œæ¸…æ´—ã€è½¬æ¢å’Œæ•´åˆï¼Œç„¶åå°†å…¶æä¾›ç»™æœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚åœ¨æœ¬æ–¹æ¡ˆä¸­ï¼Œæµç¨‹åŒ…æ‹¬ï¼š

- **æ•°æ®æ¸…æ´—**ï¼šåˆå¹¶å¤šä¸ª CSV æ•°æ®é›†ã€æŒ‰å› å­ç­›é€‰å­—æ®µå¹¶å»é‡ï¼›
- **æ•°æ®é¢„å¤„ç†**ï¼šå¯¹æ ‡è®°ä¸ºå½’ä¸€åŒ–çš„æ•°å€¼åˆ—è¿›è¡Œæ ‡å‡†åŒ–ï¼›
- **æ¨¡å‹è®­ç»ƒ**ï¼šæ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©å¯¹åº”çš„é€‚é…å™¨è¿›è¡Œè®­ç»ƒï¼›
- **æ¨¡å‹ä¿å­˜ä¸å‘å¸ƒ**ï¼šè®­ç»ƒç»“æŸåå°†æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œç”¨æˆ·å¯é€‰æ‹©å°†å…¶ä¸Šä¼ åˆ° S3ï¼›
- **æ¨¡å‹é¢„æµ‹**ï¼šå…¶ä»–ç”¨æˆ·æä¾›è¾“å…¥å­—æ®µï¼Œæ ¹æ®å·²å‘å¸ƒæ¨¡å‹çš„ ID å’Œç±»å‹åŠ è½½æ¨¡å‹å¹¶æ¨ç†ã€‚

## æ•°æ®æ¸…æ´—ä¸é¢„å¤„ç†æ¨¡å—

é¦–å…ˆè¿›è¡Œæ•°æ®æ¸…æ´—ï¼šè¯»å–å¹¶åˆå¹¶å‰ç«¯ä¼ å…¥çš„å¤šä¸ª CSV å­—ç¬¦ä¸²ï¼ŒæŒ‰å› å­åˆ—è¡¨ç­›é€‰æ‰€éœ€å­—æ®µï¼Œæœ€åå»é™¤é‡å¤è¡Œã€‚å®Œæˆæ•°æ®æ¸…æ´—åï¼Œå¯¹éœ€è¦å½’ä¸€åŒ–çš„æ•°å€¼åˆ—è¿›è¡Œå¤„ç†ï¼Œå®ç°åŸºæœ¬çš„æ ‡å‡†åŒ–ã€‚ä»¥ä¸‹æ˜¯ç¤ºä¾‹ä»£ç ç»“æ„ï¼š

```python
import pandas as pd
from typing import List
import io

class DataCleaner:
    @staticmethod
    def merge_datasets(csv_contents: List[str]) -> pd.DataFrame:
        """
        åˆå¹¶å¤šä¸ª CSV æ–‡æœ¬æ•°æ®ä¸ºä¸€ä¸ª DataFrame
        """
        df_list = []
        for csv in csv_contents:
            df_list.append(pd.read_csv(io.StringIO(csv)))
        df = pd.concat(df_list, ignore_index=True)
        return df

    @staticmethod
    def filter_fields(df: pd.DataFrame, field_names: List[str]) -> pd.DataFrame:
        """
        æ ¹æ®å­—æ®µåç­›é€‰åˆ—
        """
        return df[field_names]

    @staticmethod
    def drop_duplicates(df: pd.DataFrame) -> pd.DataFrame:
        """
        å»é™¤é‡å¤è¡Œ
        """
        return df.drop_duplicates()
import pandas as pd
from typing import Dict

class DataPreprocessor:
    @staticmethod
    def normalize(df: pd.DataFrame, factors: List[Dict]) -> pd.DataFrame:
        """
        å¯¹éœ€è¦å½’ä¸€åŒ–çš„æ•°å€¼åˆ—è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
        """
        for factor in factors:
            name = factor['name']
            if factor.get('normalize') and pd.api.types.is_numeric_dtype(df[name]):
                # ä½¿ç”¨å‡å€¼-æ ‡å‡†å·®æ ‡å‡†åŒ–
                df[name] = (df[name] - df[name].mean()) / df[name].std()
        return df
```

## æ¨¡å‹é€‚é…å™¨æ¥å£ä¸å®ç°

ä½¿ç”¨é€‚é…å™¨æ¨¡å¼è®¾è®¡ç»Ÿä¸€çš„æ¨¡å‹æ¥å£ã€‚å®šä¹‰ä¸€ä¸ª `BaseModelAdapter` æŠ½è±¡ç±»ï¼Œè§„å®š `train`ã€`predict`ã€`save`ã€`load` ç­‰æ–¹æ³•ï¼Œæ‰€æœ‰æ¨¡å‹ç±»å‹çš„é€‚é…å™¨éƒ½ç»§æ‰¿è¯¥æ¥å£ã€‚ä¾‹å¦‚ï¼š

```python
import pandas as pd
from typing import Dict, Any
import joblib
from abc import ABC, abstractmethod

class BaseModelAdapter(ABC):
    @abstractmethod
    def train(self, X: pd.DataFrame, y: pd.Series, params: Dict):
        pass

    @abstractmethod
    def predict(self, X: pd.DataFrame) -> Any:
        pass

    def save(self, filepath: str):
        """
        å°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜åˆ°æ–‡ä»¶
        """
        joblib.dump(self.model, filepath)

    @classmethod
    def load(cls, filepath: str):
        """
        ä»æ–‡ä»¶åŠ è½½æ¨¡å‹
        """
        adapter = cls()
        adapter.model = joblib.load(filepath)
        return adapter
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor

class LinearRegressionAdapter(BaseModelAdapter):
    def __init__(self):
        self.model = LinearRegression()

    def train(self, X, y, params):
        # åˆå§‹åŒ–æ¨¡å‹æ—¶åº”ç”¨å‚æ•°ï¼ˆå¦‚æ­£åˆ™åŒ–ç³»æ•°ç­‰ï¼‰
        self.model = LinearRegression(**params)
        self.model.fit(X, y)

    def predict(self, X):
        return self.model.predict(X)

class XGBoostAdapter(BaseModelAdapter):
    def __init__(self):
        self.model = XGBRegressor()

    def train(self, X, y, params):
        self.model = XGBRegressor(**params)
        self.model.fit(X, y)

    def predict(self, X):
        return self.model.predict(X)

# è‹¥æ”¯æŒå¤§è¯­è¨€æ¨¡å‹ï¼Œå¯å®ç°å¯¹åº”é€‚é…å™¨
class LLMAdapter(BaseModelAdapter):
    def __init__(self):
        self.model = None  # åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆä¾‹å¦‚åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼‰

    def train(self, X, y, params):
        # å¯¹äº LLM å¯æ‰§è¡Œå¾®è°ƒæˆ–å…¶å®ƒè®­ç»ƒé€»è¾‘
        pass

    def predict(self, X):
        # ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ¨ç†
        return self.model.generate(X)
```

## è®­ç»ƒè°ƒåº¦ä¸å‚æ•°ç®¡ç†

è®­ç»ƒæ¨¡å—è´Ÿè´£åè°ƒæ•´ä¸ªè®­ç»ƒæµç¨‹ã€‚é¦–å…ˆï¼Œæ ¹æ®å‰ç«¯ä¼ å…¥çš„æ¨¡å‹ç±»å‹ï¼Œä»æ¨¡æ¿è¡¨åŠ è½½é»˜è®¤å‚æ•°ï¼Œç„¶åä¸å‰ç«¯ç»™å®šçš„å‚æ•°åˆå¹¶ï¼ˆå‰ç«¯ä¼˜å…ˆï¼‰ã€‚ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
class ModelTemplateRepo:
    """
    æ¨¡å‹æ¨¡æ¿è¡¨ï¼Œå­˜å‚¨æ¯ç§æ¨¡å‹ç±»å‹çš„é»˜è®¤å‚æ•°
    """
    TEMPLATE = {
        "linear_regression": {"fit_intercept": True, "normalize": False},
        "xgboost": {"max_depth": 5, "learning_rate": 0.1},
        # å¯ä»¥æ·»åŠ å…¶ä»–æ¨¡å‹ç±»å‹åŠå…¶é»˜è®¤å‚æ•°
    }

    @staticmethod
    def get_default_params(model_type: str) -> Dict:
        return ModelTemplateRepo.TEMPLATE.get(model_type, {})

# é€‚é…å™¨æ³¨å†Œè¡¨ï¼šæ ¹æ®æ¨¡å‹ç±»å‹è·å–å¯¹åº”çš„ Adapter ç±»
ADAPTER_REGISTRY = {
    "linear_regression": LinearRegressionAdapter,
    "xgboost": XGBoostAdapter,
    "llm": LLMAdapter
}

class TrainingScheduler:
    def __init__(self):
        pass

    def train_model(self, factors: List[Dict], model_type: str,
                    user_params: Dict, csv_contents: List[str]) -> str:
        # æ•°æ®æ¸…æ´—
        df = DataCleaner.merge_datasets(csv_contents)
        df = DataCleaner.filter_fields(df, [f['name'] for f in factors])
        df = DataCleaner.drop_duplicates(df)
        # æ•°æ®é¢„å¤„ç†
        df = DataPreprocessor.normalize(df, factors)
        # å‡è®¾æœ€åä¸€ä¸ªå­—æ®µä¸ºç›®æ ‡å˜é‡
        X = df[[f['name'] for f in factors if f['name'] != factors[-1]['name']]]
        y = df[factors[-1]['name']]
        # å‚æ•°åˆå¹¶ï¼ˆæ¨¡æ¿é»˜è®¤å‚æ•° + ç”¨æˆ·å‚æ•°ï¼‰
        default_params = ModelTemplateRepo.get_default_params(model_type)
        params = {**default_params, **user_params}
        # è®­ç»ƒæ¨¡å‹
        adapter_cls = ADAPTER_REGISTRY.get(model_type)
        adapter = adapter_cls()
        adapter.train(X, y, params)
        # ä¿å­˜æ¨¡å‹åˆ°æœ¬åœ°
        model_path = f"{model_type}_model.pkl"
        adapter.save(model_path)
        return model_path  # è¿”å›æ¨¡å‹æ–‡ä»¶è·¯å¾„æˆ– ID
```

## æ¨¡å‹ä¿å­˜ä¸å‘å¸ƒ

æ¨¡å‹è®­ç»ƒç»“æŸåï¼Œæ¨¡å‹æ–‡ä»¶ä¿å­˜åœ¨æœ¬åœ°ã€‚ç”¨æˆ·ç¡®è®¤åï¼Œå¯å°†æ¨¡å‹ä¸Šä¼ è‡³ S3 ç­‰å¤–éƒ¨å­˜å‚¨ï¼Œä¾¿äºåç»­è°ƒç”¨ã€‚ä¾‹å¦‚ï¼š

```python
import boto3

class ModelRegistry:
    @staticmethod
    def upload_to_s3(local_path: str, bucket_name: str, model_id: str):
        """
        å°†æœ¬åœ°æ¨¡å‹æ–‡ä»¶ä¸Šä¼ åˆ° S3
        """
        s3 = boto3.client('s3')
        s3.upload_file(local_path, bucket_name, f"{model_id}.pkl")
```

## æ¨¡å‹é¢„æµ‹æ¨¡å—

é¢„æµ‹æ¨¡å—æ ¹æ®ä¼ å…¥çš„å·²å‘å¸ƒæ¨¡å‹ ID å’Œç±»å‹åŠ è½½æ¨¡å‹ï¼Œå¹¶å¯¹æ–°æ•°æ®è¿›è¡Œé¢„æµ‹ï¼š

```python
from pandas import DataFrame

class Predictor:
    def __init__(self, adapter_registry):
        self.adapter_registry = adapter_registry

    def predict(self, model_type: str, model_path: str, input_data: DataFrame):
        """
        åŠ è½½æŒ‡å®šæ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹
        """
        adapter_cls = self.adapter_registry.get(model_type)
        adapter = adapter_cls.load(model_path)
        return adapter.predict(input_data)

# ä½¿ç”¨ç¤ºä¾‹
adapter_registry = ADAPTER_REGISTRY
predictor = Predictor(adapter_registry)
# å…¶ä»–ç”¨æˆ·ä¼ å…¥çš„é¢„æµ‹æ•°æ®ç¤ºä¾‹
# input_df = pd.DataFrame([...])
# preds = predictor.predict("linear_regression", "linear_regression_model.pkl", input_df)
```

ä»¥ä¸Šä»£ç ç»“æ„å®ç°äº†ä»æ•°æ®æ¸…æ´—åˆ°æ¨¡å‹è®­ç»ƒå†åˆ°é¢„æµ‹çš„å®Œæ•´æµç¨‹ã€‚å„æ¨¡å—è®¾è®¡é€šç”¨ç®€æ´ï¼Œå¯æ ¹æ®éœ€è¦æ‰©å±•æ›´å¤šæ¨¡å‹ç±»å‹å’ŒåŠŸèƒ½ã€‚

**å‚è€ƒæ–‡çŒ®ï¼š** æ•°æ®ç®¡é“æ ¸å¿ƒæ¦‚å¿µï¼›å¤šæºæ•°æ®åˆå¹¶å»é‡ï¼›é€‚é…å™¨æ¨¡å¼ä»‹ç»ã€‚

æ˜ç™½äº†ã€‚æˆ‘å°†ä¸ºä½ è®¾è®¡ä¸€ä¸ªå®Œæ•´çš„åç«¯æ¡†æ¶ï¼Œä½¿ç”¨é€‚é…å™¨æ¨¡å¼æ¥æ”¯æŒå¤šç§æ¨¡å‹è®­ç»ƒä¸é¢„æµ‹æµç¨‹ï¼ŒåŒ…å«æ•°æ®æ¸…æ´—ã€é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€æ¨¡å‹å‘å¸ƒï¼ˆS3ï¼‰ã€é¢„æµ‹å‚æ•°ä¼ é€’ç­‰åŠŸèƒ½ï¼Œç¡®ä¿ç»“æ„è§£è€¦ã€æ¸…æ™°å¯æ‰©å±•ã€‚

æˆ‘ä¼šåœ¨å®Œæˆåæä¾›å„ä¸ªæ¨¡å—çš„ä»£ç ç»“æ„ä¸é€»è¾‘è¯´æ˜ï¼Œä¾›ä½ ç›´æ¥é›†æˆã€‚è¯·ç¨ç­‰ï¼Œæˆ‘é©¬ä¸Šæ•´ç†å®Œæ¯•ã€‚

# åç«¯æ¨¡å‹è®­ç»ƒä¸é¢„æµ‹æ¡†æ¶è®¾è®¡

## ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

- **æ•°æ®å¤„ç†æ¨¡å—**ï¼šè´Ÿè´£åˆå¹¶å¤šä¸ªæ•°æ®é›†ï¼ˆCSV å†…å®¹ï¼‰ã€æŒ‰å› å­å‚æ•°é€‰å–ç‰¹å¾åˆ—ã€å»é‡ï¼Œå¹¶æ ¹æ®é…ç½®å¯¹æ•°å€¼ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–ç­‰é¢„å¤„ç†ã€‚
- **æ¨¡å‹é€‚é…å™¨æ¥å£**ï¼šå®šä¹‰ç»Ÿä¸€çš„è®­ç»ƒä¸é¢„æµ‹æ¥å£ï¼ˆ`train`ã€`predict` ç­‰æ–¹æ³•ï¼‰ï¼Œå„æ¨¡å‹ç±»å‹é€šè¿‡å®ç°è¯¥æ¥å£é€‚é…å™¨æ¥è§£è€¦å…·ä½“ç®—æ³•ã€‚
- **ç¤ºä¾‹é€‚é…å™¨**ï¼šé’ˆå¯¹çº¿æ€§å›å½’ã€é€»è¾‘å›å½’ã€XGBoostã€é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ç­‰ä¸åŒæ¨¡å‹ï¼Œå®ç°å…·ä½“çš„é€‚é…å™¨ç±»ï¼Œè´Ÿè´£è°ƒç”¨ç›¸åº”æ¡†æ¶è®­ç»ƒ/æ¨ç†å¹¶ä¿å­˜æ¨¡å‹ã€‚
- **è®­ç»ƒè°ƒåº¦å™¨**ï¼šè´Ÿè´£æ¥æ”¶å‰ç«¯è¯·æ±‚ï¼ˆå› å­å‚æ•°ã€æ¨¡å‹å‚æ•°ã€æ•°æ®æ–‡ä»¶å†…å®¹ï¼‰ï¼Œä¾æ¬¡è°ƒç”¨æ•°æ®å¤„ç†ã€é€‰æ‹©é€‚é…å™¨è®­ç»ƒï¼Œå¹¶è°ƒç”¨æ¨¡å‹æ³¨å†Œä¸å‘å¸ƒé€»è¾‘è¿›è¡Œä¿å­˜å’Œæ ‡è®°ã€‚
- **æ¨¡å‹æ³¨å†Œä¸å‘å¸ƒæ¨¡å—**ï¼šç®¡ç†è®­ç»ƒåçš„æ¨¡å‹å…ƒæ•°æ®ï¼ˆå¦‚æ¨¡å‹ IDã€æœ¬åœ°è·¯å¾„ã€çŠ¶æ€ï¼‰ï¼Œåœ¨ç”¨æˆ·ç¡®è®¤å‘å¸ƒåé€šè¿‡ boto3 ä¸Šä¼ è‡³ S3ï¼Œå¹¶æ›´æ–°æ¨¡å‹å‘å¸ƒçŠ¶æ€ã€‚
- **é¢„æµ‹æœåŠ¡**ï¼šå…è®¸å…¶ä»–ç”¨æˆ·è°ƒç”¨å·²å‘å¸ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼ŒåŠ¨æ€æ¥æ”¶è¾“å…¥å‚æ•°ï¼ŒåŠ è½½æ¨¡å‹å¹¶è¾“å‡ºé¢„æµ‹ç»“æœã€‚

å„æ¨¡å—é€šè¿‡æ¥å£è§£è€¦ï¼Œä¾‹å¦‚è®­ç»ƒè°ƒåº¦å™¨åªä¾èµ–äºæ•°æ®å¤„ç†å’Œé€‚é…å™¨æ¥å£ï¼Œä¸ç›´æ¥ä¾èµ–å…·ä½“æ¨¡å‹åº“ï¼›æ–°å¢æ¨¡å‹ç±»å‹æ—¶ï¼Œåªéœ€æ–°å¢å¯¹åº”çš„é€‚é…å™¨ç±»å¹¶æ³¨å†Œåˆ°å·¥å‚å³å¯ï¼Œæ— éœ€ä¿®æ”¹æ ¸å¿ƒæµç¨‹ã€‚

## æ¨¡å‹é€‚é…å™¨æ¥å£

é‡‡ç”¨**é€‚é…å™¨æ¨¡å¼**ä¸ºå„æ¨¡å‹ç±»å‹å®šä¹‰ç»Ÿä¸€æ¥å£ï¼Œä»¥ä¾¿è®­ç»ƒè°ƒåº¦å™¨å’Œé¢„æµ‹æœåŠ¡å¯ä»¥é€æ˜è°ƒç”¨ã€‚ä¸‹é¢ç»™å‡ºä¸€ä¸ªæŠ½è±¡åŸºç±» `ModelAdapter`ï¼Œå®šä¹‰ç»Ÿä¸€çš„è®­ç»ƒã€é¢„æµ‹ã€æ¨¡å‹ä¿å­˜/åŠ è½½æ¥å£ï¼š

```python
from abc import ABC, abstractmethod

class ModelAdapter(ABC):
    """
    æ¨¡å‹é€‚é…å™¨åŸºç±»ï¼Œå®šä¹‰ç»Ÿä¸€çš„è®­ç»ƒå’Œé¢„æµ‹æ¥å£ã€‚
    """

    def __init__(self, model_params: dict):
        """
        åˆå§‹åŒ–é€‚é…å™¨æ—¶ï¼Œå¯ä¼ å…¥æ¨¡å‹é…ç½®å‚æ•°ã€‚
        """
        self.model_params = model_params
        self.model = None  # åœ¨è®­ç»ƒåä¿å­˜æ¨¡å‹å®ä¾‹

    @abstractmethod
    def train(self, X, y):
        """
        è®­ç»ƒæ¨¡å‹ã€‚X ä¸ºç‰¹å¾æ•°æ®é›†ï¼ˆDataFrame æˆ– ndarrayï¼‰ï¼Œy ä¸ºç›®æ ‡æ ‡ç­¾ã€‚
        """
        pass

    @abstractmethod
    def predict(self, X):
        """
        ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚X ä¸ºè¾“å…¥ç‰¹å¾ï¼Œå¯ä¸ºå•æ¡æˆ–å¤šæ¡æ•°æ®ã€‚
        è¿”å›é¢„æµ‹ç»“æœã€‚
        """
        pass

    @abstractmethod
    def save_model(self, file_path: str):
        """
        å°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶è·¯å¾„ã€‚
        """
        pass

    @abstractmethod
    def load_model(self, file_path: str):
        """
        ä»æŒ‡å®šè·¯å¾„åŠ è½½æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹æ—¶ä½¿ç”¨ã€‚
        """
        pass
```

- **è§£è€¦è®¾è®¡**ï¼šè®­ç»ƒè°ƒåº¦å™¨å’Œé¢„æµ‹æœåŠ¡é€šè¿‡è¯¥æ¥å£ä¸å…·ä½“æ¨¡å‹é€‚é…å™¨äº¤äº’ï¼Œä¸éœ€è¦çŸ¥é“æ¨¡å‹ç»†èŠ‚ã€‚æ–°å¢æ¨¡å‹ç±»å‹æ—¶ï¼Œåªéœ€å®ç°è¯¥æ¥å£å¹¶æ³¨å†Œï¼Œæ— éœ€ä¿®æ”¹å·²æœ‰ä»£ç ã€‚
- **åŠ¨æ€æ‰©å±•**ï¼šå¯é€šè¿‡å·¥å‚æ¨¡å¼æˆ–æ³¨å†Œè¡¨ç»´æŠ¤æ¨¡å‹ç±»å‹ä¸é€‚é…å™¨ç±»çš„æ˜ å°„ï¼Œå¦‚ `"linear_regression" -> LinearRegressionAdapter`ï¼Œæ–¹ä¾¿åŠ¨æ€é€‰æ‹©é€‚é…å™¨ã€‚
- **ç»Ÿä¸€è°ƒç”¨**ï¼šç»Ÿä¸€çš„ `train/predict` æ¥å£ï¼Œå‚æ•°ä¸ºç‰¹å¾æ•°æ®å’Œè¾“å…¥å€¼ï¼Œæ”¯æŒåŠ¨æ€å‚æ•°è¾“å…¥ã€‚

### ç¤ºä¾‹é€‚é…å™¨

ä»¥ä¸‹æä¾›ä¸¤ä¸ªç¤ºä¾‹é€‚é…å™¨ï¼Œä¸€ä¸ªç”¨äºçº¿æ€§å›å½’ï¼Œä¸€ä¸ªç”¨äºé¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œä»¥å±•ç¤ºä¸åŒæ¨¡å‹ç±»å‹çš„é€‚é…å™¨å®ç°æ€è·¯ã€‚

- **çº¿æ€§å›å½’é€‚é…å™¨**ï¼ˆä½¿ç”¨ scikit-learnï¼‰ï¼š

```python
from sklearn.linear_model import LinearRegression
import joblib

class LinearRegressionAdapter(ModelAdapter):
    def train(self, X, y):
        self.model = LinearRegression(**self.model_params.get('params', {}))
        self.model.fit(X, y)
        return self.model

    def predict(self, X):
        if self.model is None:
            raise RuntimeError("æ¨¡å‹å°šæœªè®­ç»ƒæˆ–åŠ è½½")
        return self.model.predict(X)

    def save_model(self, file_path: str):
        if self.model is None:
            raise RuntimeError("æ— æ¨¡å‹å¯ä¿å­˜")
        joblib.dump(self.model, file_path)

    def load_model(self, file_path: str):
        self.model = joblib.load(file_path)
        return self.model
```

- **LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰é€‚é…å™¨**ï¼ˆä½¿ç”¨ Hugging Face Transformersï¼‰ï¼š

```python
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline
import torch

class LLMAdapter(ModelAdapter):
    def train(self, train_texts, train_labels):
        """
        ç®€è¦ç¤ºä¾‹ï¼šåœ¨åˆ†ç±»ä»»åŠ¡ä¸‹ï¼Œç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚
        å®é™…å®ç°å¯ä½¿ç”¨ Trainer æˆ–è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯ã€‚
        """
        model_name = self.model_params.get('model_name', 'bert-base-uncased')
        num_labels = self.model_params.get('num_labels', 2)
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)
        # è¿™é‡Œå¯è¿›è¡Œå¾®è°ƒï¼ˆä»£ç ç®€ç•¥ï¼Œå®é™…å¯ç”¨ Trainerï¼‰
        self.tokenizer = tokenizer
        self.model = model
        return model

    def predict(self, texts):
        """
        ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»é¢„æµ‹ã€‚texts å¯ä»¥æ˜¯å•ä¸ªå­—ç¬¦ä¸²æˆ–å­—ç¬¦ä¸²åˆ—è¡¨ã€‚
        """
        if self.model is None:
            raise RuntimeError("æ¨¡å‹å°šæœªè®­ç»ƒæˆ–åŠ è½½")
        # ä½¿ç”¨pipelineç®€åŒ–æ¨ç†
        classifier = pipeline("text-classification", model=self.model, tokenizer=self.tokenizer)
        results = classifier(texts)
        return results

    def save_model(self, dir_path: str):
        """
        ä¿å­˜æ•´ä¸ªæ¨¡å‹åŠtokenizeråˆ°æ–‡ä»¶å¤¹ã€‚
        """
        if self.model is None:
            raise RuntimeError("æ— æ¨¡å‹å¯ä¿å­˜")
        self.model.save_pretrained(dir_path)
        self.tokenizer.save_pretrained(dir_path)

    def load_model(self, dir_path: str):
        """
        ä»æ–‡ä»¶å¤¹åŠ è½½æ¨¡å‹åŠtokenizerã€‚
        """
        model_name = self.model_params.get('model_name', 'bert-base-uncased')
        self.tokenizer = AutoTokenizer.from_pretrained(dir_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(dir_path)
        return self.model
```

è¿™ä¸¤ä¸ªç¤ºä¾‹å±•ç¤ºäº†ï¼š`LinearRegressionAdapter` è´Ÿè´£è°ƒç”¨ sklearn æ¥å£è®­ç»ƒã€é¢„æµ‹ï¼Œå¹¶ç”¨ `joblib` ä¿å­˜æ¨¡å‹ï¼›`LLMAdapter` åˆ™ä½¿ç”¨ Hugging Face è¿›è¡Œæ–‡æœ¬åˆ†ç±»ç¤ºä¾‹ï¼Œå±•ç¤ºå¯¹å¾®è°ƒå’Œæ¨ç†çš„åŒ…è£…ã€‚å…¶å®ƒæ¨¡å‹ç±»å‹ï¼ˆå¦‚é€»è¾‘å›å½’ã€XGBoost ç­‰ï¼‰ä¹Ÿå¯ç±»ä¼¼å®ç°å„è‡ªçš„é€‚é…å™¨ç±»ï¼Œå¤ç”¨ç›¸åŒçš„ç»Ÿä¸€æ¥å£ã€‚

## æ•°æ®å¤„ç†æ¨¡å—

æ•°æ®å¤„ç†æ¨¡å—è´Ÿè´£ä»å‰ç«¯æ¥æ”¶çš„æ•°æ®æ–‡ä»¶å†…å®¹å¼€å§‹ï¼Œè¿›è¡Œæ¸…æ´—å’Œé¢„å¤„ç†ï¼Œæœ€ç»ˆç”Ÿæˆå¯ä¾›æ¨¡å‹è®­ç»ƒçš„ç‰¹å¾çŸ©é˜µå’Œæ ‡ç­¾ã€‚è®¾è®¡ä¸­å°†å…¶è§£è€¦ä¸ºå•ç‹¬çš„ç±»ï¼Œæ¯”å¦‚ `DataProcessor`ã€‚ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š

1. **æ•°æ®æ¸…æ´—**ï¼šåˆå¹¶å‰ç«¯ä¼ æ¥çš„å¤šä¸ª CSV æ–‡ä»¶å†…å®¹ï¼ˆå­—ç¬¦ä¸²å½¢å¼ï¼‰ï¼Œæ ¹æ®å› å­åˆ—è¡¨æå–å¯¹åº”åˆ—ï¼Œå¹¶å»é™¤é‡å¤è¡Œã€‚
2. **å½’ä¸€åŒ–ç­‰é¢„å¤„ç†**ï¼šéå†å› å­é…ç½®ï¼Œå¦‚æœæŸåˆ—æ ‡è®°éœ€è¦å½’ä¸€åŒ–ä¸”ä¸ºæ•°å€¼ç±»å‹ï¼Œåˆ™å¯¹è¯¥åˆ—è¿›è¡Œ Min-Max å½’ä¸€åŒ–æˆ–å…¶ä»–æ–¹å¼è½¬æ¢ã€‚

ä¸‹é¢ç»™å‡ºä¸€ä¸ªç¤ºä¾‹å®ç°ï¼š

```python
import pandas as pd
from io import StringIO
from sklearn.preprocessing import MinMaxScaler

class DataProcessor:
    def clean(self, file_contents: list, factors: list) -> pd.DataFrame:
        """
        åˆå¹¶å¤šä¸ª CSV å†…å®¹ï¼Œæå–å› å­ç›¸å…³çš„åˆ—ï¼Œå¹¶å»é™¤é‡å¤å€¼ã€‚
        - file_contents: åŒ…å«å¤šä¸ª CSV æ ¼å¼å­—ç¬¦ä¸²çš„åˆ—è¡¨
        - factors: å› å­é…ç½®åˆ—è¡¨ï¼Œæ¯ä¸ªå› å­åŒ…å« 'name' (åˆ—å) å’Œå…¶ä»–å±æ€§
        """
        # è¯»å–å¹¶åˆå¹¶æ‰€æœ‰ CSV å†…å®¹
        dfs = [pd.read_csv(StringIO(content)) for content in file_contents]
        df = pd.concat(dfs, ignore_index=True)

        # æå–å› å­æŒ‡å®šçš„åˆ—
        selected_cols = [f['name'] for f in factors]
        df = df.loc[:, selected_cols]

        # å»é™¤å®Œå…¨é‡å¤çš„è¡Œ
        df = df.drop_duplicates().reset_index(drop=True)
        return df

    def preprocess(self, df: pd.DataFrame, factors: list) -> pd.DataFrame:
        """
        å¯¹æ•°å€¼åˆ—è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼ˆå¦‚é…ç½®äº† normalize=Trueï¼‰ã€‚
        - df: ä¸Šä¸€æ­¥æ¸…æ´—åçš„ DataFrame
        - factors: å› å­é…ç½®ï¼ŒåŒ…å«ç±»å‹å’Œæ˜¯å¦å½’ä¸€åŒ–çš„æ ‡å¿—
        """
        for f in factors:
            col = f['name']
            if f.get('type') == 'numeric' and f.get('normalize', False):
                scaler = MinMaxScaler()
                df[col] = scaler.fit_transform(df[[col]])
        return df
```

- **è§£è€¦è®¾è®¡**ï¼š`TrainingScheduler` ä¼šè°ƒç”¨ `DataProcessor`ï¼Œè€Œä¸ä¼šå…³å¿ƒå…·ä½“çš„æ¸…æ´—é€»è¾‘ç»†èŠ‚ã€‚è‹¥éœ€è¦å¢åŠ æ–°é¢„å¤„ç†æ–¹æ³•ï¼ˆå¦‚æ ‡å‡†åŒ–ã€ç¼ºå¤±å€¼å¡«å……ç­‰ï¼‰ï¼Œåªè¦åœ¨ `DataProcessor` ä¸­æ‰©å±•å³å¯ï¼Œä¸å½±å“å…¶ä»–æ¨¡å—ã€‚
- **æ•°æ®è¯»å–**ï¼šä½¿ç”¨ `StringIO` è¯»å– CSV å†…å®¹å­—ç¬¦ä¸²ï¼Œå®ç°â€œæ–‡ä»¶å†…å®¹â€è€Œéè·¯å¾„ä¼ é€’çš„è¯»å–æ–¹å¼ã€‚
- **å»é‡å’Œç­›é€‰**ï¼šç›´æ¥ä½¿ç”¨ `pandas` çš„ `drop_duplicates()` ä»¥åŠåˆ—é€‰æ‹©åŠŸèƒ½å®ç°ã€‚

## è®­ç»ƒè°ƒåº¦å™¨

è®­ç»ƒè°ƒåº¦å™¨ï¼ˆ`TrainingScheduler`ï¼‰è´Ÿè´£åè°ƒæ•´ä¸ªè®­ç»ƒæµç¨‹ï¼Œå°†å‰ç«¯ä¼ å…¥çš„å‚æ•°å’Œæ•°æ®åˆ†å‘ç»™å„å­æ¨¡å—ï¼Œå¹¶ç®¡ç†æ¨¡å‹è®­ç»ƒä¸ä¿å­˜çš„æµç¨‹ã€‚ä¸»è¦é€»è¾‘åŒ…æ‹¬ï¼š

- æ¥æ”¶å‰ç«¯å‚æ•°ï¼šå› å­é…ç½®åˆ—è¡¨ `factor_params`ã€æ¨¡å‹é…ç½® `model_params`ã€ä»¥åŠä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®æ–‡ä»¶å†…å®¹ `data_contents`ã€‚
- è°ƒç”¨æ•°æ®å¤„ç†æ¨¡å—ï¼šå…ˆè¿›è¡Œæ•°æ®æ¸…æ´— (`clean`)ï¼Œå†è¿›è¡Œé¢„å¤„ç† (`preprocess`)ã€‚
- é€‰æ‹©æ¨¡å‹é€‚é…å™¨ï¼šæ ¹æ® `model_params['type']`ï¼Œä»å·¥å‚æˆ–æ³¨å†Œè¡¨ä¸­è·å–å¯¹åº”çš„é€‚é…å™¨å®ä¾‹ã€‚
- è°ƒç”¨é€‚é…å™¨è®­ç»ƒï¼šä¼ å…¥ç‰¹å¾çŸ©é˜µå’Œæ ‡ç­¾è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¿å­˜æ¨¡å‹åˆ°æœ¬åœ°ä¸´æ—¶è·¯å¾„ã€‚
- æ³¨å†Œæ¨¡å‹å…ƒæ•°æ®ï¼šå°†æ¨¡å‹ä¿å­˜è·¯å¾„ã€å‚æ•°ç­‰ä¿¡æ¯æ³¨å†Œåˆ°æ¨¡å‹æ³¨å†Œè¡¨ï¼Œå¹¶ç”Ÿæˆæ¨¡å‹ ID ã€‚
- ç­‰å¾…å‘å¸ƒï¼šè®­ç»ƒå®Œæˆåæ¨¡å‹å…ˆå¤„äºâ€œå·²è®­ç»ƒæœªå‘å¸ƒâ€çŠ¶æ€ï¼Œå¾…ç”¨æˆ·ç¡®è®¤åä¸Šä¼ åˆ° S3ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹å®ç°ï¼š

```python
import uuid
import os

class TrainingScheduler:
    def __init__(self, data_processor, adapter_factory, model_registry):
        self.data_processor = data_processor
        self.adapter_factory = adapter_factory
        self.model_registry = model_registry

    def schedule(self, factor_params: list, model_params: dict, data_contents: list) -> str:
        """
        è°ƒåº¦è®­ç»ƒæµç¨‹ï¼Œè¿”å›æ¨¡å‹IDï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰ã€‚
        """
        # 1. æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
        df_clean = self.data_processor.clean(data_contents, factor_params)
        df_processed = self.data_processor.preprocess(df_clean, factor_params)

        # æå–ç‰¹å¾çŸ©é˜µXå’Œæ ‡ç­¾y
        target_col = model_params['target']  # å‡è®¾æ¨¡å‹å‚æ•°é‡ŒæŒ‡å®šäº†ç›®æ ‡åˆ—
        feature_cols = [f['name'] for f in factor_params if f['name'] != target_col]
        X = df_processed[feature_cols]
        y = df_processed[target_col]

        # 2. è·å–å¯¹åº”çš„æ¨¡å‹é€‚é…å™¨å¹¶è®­ç»ƒ
        model_type = model_params['type']
        adapter = self.adapter_factory.get_adapter(model_type, model_params)
        adapter.train(X, y)

        # 3. æ¨¡å‹ä¿å­˜ï¼ˆæœ¬åœ°ï¼‰
        model_id = str(uuid.uuid4())
        local_dir = f"/tmp/model_{model_id}"
        os.makedirs(local_dir, exist_ok=True)
        adapter.save_model(local_dir)  # ä¿å­˜æ¨¡å‹æˆ–æ¨¡å‹æ–‡ä»¶å¤¹

        # 4. æ³¨å†Œæ¨¡å‹ä¿¡æ¯
        self.model_registry.register(model_id, {
            'type': model_type,
            'local_path': local_dir,
            'params': model_params,
            'published': False
        })
        return model_id

    def publish_model(self, model_id: str):
        """
        ç”¨æˆ·ç¡®è®¤å‘å¸ƒåè°ƒç”¨æ­¤æ–¹æ³•ï¼Œå°†æ¨¡å‹ä¸Šä¼ åˆ° S3 å¹¶æ›´æ–°çŠ¶æ€ã€‚
        """
        record = self.model_registry.get(model_id)
        if not record:
            raise ValueError("æ¨¡å‹IDä¸å­˜åœ¨")
        if record['published']:
            return  # å·²å‘å¸ƒæ— éœ€é‡å¤
        local_path = record['local_path']
        # æ„é€  S3 keyï¼Œå¯æ ¹æ®éœ€æ±‚ä½¿ç”¨æ¨¡å‹IDç­‰ä¿¡æ¯å‘½å
        s3_key = f"models/{model_id}.zip"
        uploader = S3Uploader(bucket_name="your-bucket-name")
        # å‡è®¾æ¨¡å‹ä¿å­˜ä¸ºä¸€ä¸ªç›®å½•ï¼Œè¿™é‡Œå…ˆå‹ç¼©ä¸ºzipä¸Šä¼ ï¼Œç¤ºä¾‹ä»£ç 
        zip_path = f"{local_path}.zip"
        os.system(f"zip -r {zip_path} {local_path}")
        uploader.upload_file(zip_path, s3_key)
        # æ›´æ–°å‘å¸ƒçŠ¶æ€
        record['published'] = True
        record['s3_key'] = s3_key
        self.model_registry.update(model_id, record)
```

- **æ¨¡å‹ID**ï¼šç”Ÿæˆå”¯ä¸€ `model_id`ï¼ˆå¦‚ä½¿ç”¨ `uuid`ï¼‰ï¼Œä¾¿äºåç»­å¼•ç”¨å’ŒçŠ¶æ€ç®¡ç†ã€‚
- **æœ¬åœ°ä¿å­˜**ï¼šå…ˆå°†æ¨¡å‹ä¿å­˜åˆ°åç«¯æœ¬åœ°è·¯å¾„ï¼ˆæˆ–ä¸´æ—¶ç›®å½•ï¼‰ï¼Œå†åœ¨å‘å¸ƒæ—¶ç»Ÿä¸€ä¸Šä¼ ã€‚
- **å¾…å‘å¸ƒçŠ¶æ€**ï¼šè®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹åœ¨æ³¨å†Œè¡¨ä¸­æ ‡è®°ä¸ºæœªå‘å¸ƒçŠ¶æ€ï¼Œç­‰å¾…ç”¨æˆ·ç¡®è®¤å†è§¦å‘ S3 ä¸Šä¼ ã€‚
- **S3 ä¸Šä¼ **ï¼šç¤ºä¾‹ä¸­ç”¨ `S3Uploader`ï¼ˆè§ä¸‹æ–‡ï¼‰è¿›è¡Œä¸Šä¼ ï¼Œè¿™é‡Œå‡è®¾æ¨¡å‹å…ˆå‹ç¼©åä¸Šä¼ åˆ°æŒ‡å®š bucketã€‚å®é™…å¯æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ä¸åŒçš„æ‰“åŒ…æ–¹å¼ã€‚

## æ¨¡å‹æ³¨å†Œä¸å‘å¸ƒ

`ModelRegistry` è´Ÿè´£ç»´æŠ¤æ‰€æœ‰æ¨¡å‹çš„å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬çŠ¶æ€ï¼ˆå·²è®­ç»ƒ/å·²å‘å¸ƒï¼‰ã€æœ¬åœ°è·¯å¾„ã€S3 è·¯å¾„ç­‰ä¿¡æ¯ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„æ³¨å†Œè¡¨è®¾è®¡ï¼š

```python
class ModelRegistry:
    def __init__(self):
        # å­˜å‚¨æ¨¡å‹å…ƒæ•°æ®ï¼Œkey ä¸º model_id
        self._store = {}

    def register(self, model_id: str, metadata: dict):
        """
        æ³¨å†Œæ–°æ¨¡å‹ä¿¡æ¯ã€‚
        """
        self._store[model_id] = metadata

    def update(self, model_id: str, metadata: dict):
        """
        æ›´æ–°æ¨¡å‹å…ƒæ•°æ®ï¼ˆå¦‚å‘å¸ƒçŠ¶æ€ã€S3è·¯å¾„ç­‰ï¼‰ã€‚
        """
        if model_id in self._store:
            self._store[model_id].update(metadata)
        else:
            raise KeyError("æ¨¡å‹IDæœªæ‰¾åˆ°")

    def get(self, model_id: str) -> dict:
        """
        è·å–æ¨¡å‹å…ƒæ•°æ®ã€‚
        """
        return self._store.get(model_id)
```

- **å…ƒæ•°æ®ç®¡ç†**ï¼š`metadata` åŒ…å«äº†æ¨¡å‹ç±»å‹ã€å‚æ•°ã€æœ¬åœ°å­˜å‚¨è·¯å¾„ã€æ˜¯å¦å‘å¸ƒã€S3 å­˜å‚¨é”®ç­‰ä¿¡æ¯ã€‚å®é™…ç³»ç»Ÿä¸­å¯ä»¥ç»“åˆæ•°æ®åº“æˆ–æŒä¹…åŒ–å­˜å‚¨ï¼Œæ­¤å¤„ç®€åŒ–ä¸ºå†…å­˜å­—å…¸ã€‚
- **å‘å¸ƒé€»è¾‘**ï¼šå½“è°ƒç”¨ `TrainingScheduler.publish_model(model_id)` æ—¶ï¼Œä¼šä¸Šä¼ æ¨¡å‹è‡³ S3ï¼Œå¹¶æ›´æ–° `metadata['published'] = True` åŠç›¸åº”çš„ S3 å­˜å‚¨è·¯å¾„ã€‚è¿™æ ·é¢„æµ‹æœåŠ¡å¯ä¾æ® `published` çŠ¶æ€å†³å®šæ˜¯å¦å…è®¸é¢„æµ‹è°ƒç”¨ã€‚
- **åç»­æ‰©å±•**ï¼šå¯å¢åŠ ç‰ˆæœ¬æ§åˆ¶ã€è®¿é—®æƒé™ã€æ¨¡å‹æè¿°ç­‰å­—æ®µï¼Œä½¿æ¨¡å‹æ³¨å†Œè¡¨æ›´åŠ å®Œå–„ã€‚

## S3 ä¸Šä¼ å·¥å…·

ä½¿ç”¨ `boto3` å®¢æˆ·ç«¯å®ç°æ¨¡å‹æ–‡ä»¶ä¸Šä¼ åˆ° S3ã€‚ç¤ºä¾‹å·¥å…·ç±»å¦‚ä¸‹ï¼š

```python
import boto3

class S3Uploader:
    def __init__(self, bucket_name: str):
        self.s3 = boto3.client('s3')
        self.bucket = bucket_name

    def upload_file(self, file_path: str, key: str):
        """
        ä¸Šä¼ æœ¬åœ°æ–‡ä»¶åˆ°æŒ‡å®š S3 bucket çš„ key è·¯å¾„ã€‚
        """
        self.s3.upload_file(file_path, self.bucket, key)
```

- åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œéœ€è¦é…ç½® AWS çš„è®¿é—®å¯†é’¥æˆ–ä½¿ç”¨ IAM è§’è‰²è¿›è¡Œè®¤è¯ã€‚
- `file_path` æ”¯æŒæœ¬åœ°è·¯å¾„ï¼Œ`key` å®šä¹‰äº†å­˜å‚¨åœ¨ S3 ä¸Šçš„æ–‡ä»¶åï¼ˆå¯åŒ…å«ç›®å½•ï¼‰ã€‚
- ä¸Šä¼ å®Œæˆåï¼Œæ³¨å†Œè¡¨ä¸­ä¿å­˜å¯¹åº”çš„ S3 è·¯å¾„ä¿¡æ¯ï¼Œä»¥ä¾¿åç»­åŠ è½½ä½¿ç”¨ã€‚

## æ¨¡å‹é¢„æµ‹æœåŠ¡

é¢„æµ‹æœåŠ¡å…è®¸å…¶ä»–ç”¨æˆ·æŒ‡å®šå·²å‘å¸ƒçš„æ¨¡å‹ ID å¹¶è¾“å…¥ç‰¹å¾è¿›è¡Œé¢„æµ‹ã€‚ä¸»è¦æ­¥éª¤ï¼š

1. **åŠ è½½æ¨¡å‹**ï¼šæ ¹æ®æ¨¡å‹ ID ä»æ³¨å†Œè¡¨è·å–æ¨¡å‹å…ƒæ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦å·²å‘å¸ƒã€‚è‹¥æ¨¡å‹æ–‡ä»¶å°šåœ¨æœ¬åœ°ï¼Œå¯ç›´æ¥ `load_model`ï¼›è‹¥ä»…åœ¨ S3 ä¸Šï¼Œåˆ™å…ˆä¸‹è½½ï¼ˆæˆ–é€šè¿‡ `load_model` æ”¯æŒç›´æ¥S3 URLï¼‰ã€‚
2. **åŠ¨æ€è¾“å…¥**ï¼šæ¥æ”¶å‰ç«¯ä¼ å…¥çš„é¢„æµ‹å‚æ•°ï¼Œé€šå¸¸ä¸ºé”®å€¼å¯¹å½¢å¼çš„ç‰¹å¾å€¼ã€‚åœ¨ä½¿ç”¨æ—¶éœ€è¦å°†å…¶è½¬æ¢ä¸ºæ¨¡å‹é€‚é…å™¨èƒ½æ¥å—çš„æ ¼å¼ï¼ˆå¦‚ DataFrame æˆ–çŸ©é˜µï¼‰ã€‚
3. **è°ƒç”¨é¢„æµ‹**ï¼šä½¿ç”¨é€‚é…å™¨çš„ `predict` æ–¹æ³•è¿›è¡Œé¢„æµ‹ï¼Œå¹¶è¿”å›ç»“æœç»™å‰ç«¯ã€‚

ç¤ºä¾‹å®ç°å¦‚ä¸‹ï¼š

```python
class PredictionService:
    def __init__(self, adapter_factory, model_registry):
        self.adapter_factory = adapter_factory
        self.model_registry = model_registry

    def predict(self, model_id: str, input_data: dict):
        """
        ä½¿ç”¨å·²å‘å¸ƒæ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚
        - model_id: æ³¨å†Œè¡¨ä¸­çš„æ¨¡å‹ID
        - input_data: åŒ…å«ç‰¹å¾åç§°å’Œå€¼çš„å­—å…¸ï¼ˆåŠ¨æ€å‚æ•°è¾“å…¥ï¼‰
        """
        record = self.model_registry.get(model_id)
        if not record or not record.get('published', False):
            raise ValueError("æ¨¡å‹æœªå‘å¸ƒæˆ–ä¸å­˜åœ¨")

        model_type = record['type']
        model_params = record['params']
        # è·å–å¯¹åº”é€‚é…å™¨
        adapter = self.adapter_factory.get_adapter(model_type, model_params)

        # è‹¥éœ€è¦ï¼Œä» S3 ä¸‹è½½æ¨¡å‹ï¼Œè¿™é‡Œå‡è®¾æœ¬åœ°å·²æœ‰æ¨¡å‹ç›®å½•ï¼Œå¦åˆ™å®ç°ä¸‹è½½é€»è¾‘
        local_path = record['local_path']
        adapter.load_model(local_path)

        # å°†è¾“å…¥æ•°æ®è½¬æ¢ä¸º DataFrame (æˆ–é€‚é…å™¨æ”¯æŒçš„æ ¼å¼)
        import pandas as pd
        input_df = pd.DataFrame([input_data])

        # é¢„æµ‹
        predictions = adapter.predict(input_df)
        return predictions
```

- **åŠ¨æ€å‚æ•°**ï¼šå‰ç«¯å¯ä¼ å…¥ä»»æ„éœ€è¦çš„ç‰¹å¾å­—æ®µå’Œå€¼ï¼ŒæœåŠ¡ç«¯å°†å…¶åŒ…è£…ä¸ºå•è¡Œçš„ `DataFrame` è¿›è¡Œé¢„æµ‹ã€‚è¿™æ · `predict` æ¥å£æ— éœ€å›ºå®šè¾“å…¥ç»´åº¦ã€‚
- **æ¨¡å‹åŠ è½½**ï¼šå‡è®¾æ¨¡å‹å·²ç»ä¸Šä¼ å¹¶ä¸‹è½½è‡³æœ¬åœ°ï¼ˆæˆ–æœ¬åœ°ä¿ç•™è®­ç»ƒç»“æœï¼‰ï¼Œ`load_model` è´Ÿè´£åŠ è½½æ¨¡å‹å®ä¾‹ã€‚è‹¥æ¨¡å‹ä»…åœ¨ S3ï¼Œå¯åœ¨æ­¤å¤„åŠ ä¸‹è½½ä»£ç ï¼ˆå¦‚ `boto3.download_file`ï¼‰åå†åŠ è½½ã€‚
- **è¿”å›ç»“æœ**ï¼šå°†æ¨¡å‹è¾“å‡ºç›´æ¥è¿”å›ç»™å‰ç«¯ã€‚å¯¹äºåˆ†ç±»ä»»åŠ¡å¯èƒ½éœ€è¦æ˜ å°„ç±»åˆ«æ ‡ç­¾ï¼Œå›å½’åˆ™è¿”å›æ•°å€¼ã€‚

## ä»£ç è°ƒç”¨ç¤ºä¾‹

ä¸‹é¢ç»™å‡ºä¸€ä¸ªç®€å•çš„æµç¨‹ç¤ºä¾‹ï¼Œè¯´æ˜å¦‚ä½•ä½¿ç”¨ä¸Šè¿°ç»„ä»¶å®Œæˆè®­ç»ƒå’Œé¢„æµ‹ï¼š

```python
# å‡è®¾å‰ç«¯ä¼ é€’ï¼š
factor_params = [
    {'name': 'age', 'type': 'numeric', 'normalize': True},
    {'name': 'salary', 'type': 'numeric', 'normalize': True},
    {'name': 'gender', 'type': 'categorical', 'normalize': False},
    {'name': 'income', 'type': 'numeric', 'normalize': False},  # ç›®æ ‡åˆ—
]
model_params = {
    'type': 'linear_regression',
    'target': 'income',
    'params': {}  # çº¿æ€§å›å½’è¶…å‚æ•°
}
data_contents = [csv_string1, csv_string2]  # CSVæ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²åˆ—è¡¨

# åˆå§‹åŒ–ç»„ä»¶
data_processor = DataProcessor()
adapter_factory = ModelAdapterFactory()  # å‡è®¾å·¥å‚å·²å®ç°ç±»å‹->é€‚é…å™¨æ˜ å°„
model_registry = ModelRegistry()
scheduler = TrainingScheduler(data_processor, adapter_factory, model_registry)

# è°ƒåº¦è®­ç»ƒ
model_id = scheduler.schedule(factor_params, model_params, data_contents)
print(f"æ¨¡å‹å·²è®­ç»ƒå®Œæˆï¼ŒID = {model_id}ï¼Œç­‰å¾…å‘å¸ƒã€‚")

# ç”¨æˆ·ç¡®è®¤å‘å¸ƒåè°ƒç”¨
scheduler.publish_model(model_id)
print("æ¨¡å‹å·²å‘å¸ƒè‡³ S3ã€‚")

# é¢„æµ‹ç¤ºä¾‹
prediction_service = PredictionService(adapter_factory, model_registry)
input_features = {'age': 30, 'salary': 60000, 'gender': 'Male'}
result = prediction_service.predict(model_id, input_features)
print("é¢„æµ‹ç»“æœï¼š", result)
```

ä»¥ä¸Šç¤ºä¾‹æ¼”ç¤ºäº†æ•´ä¸ªæµç¨‹ï¼šå‰ç«¯ä¼ å…¥æ•°æ®åï¼Œ**è®­ç»ƒè°ƒåº¦å™¨**å®Œæˆæ•°æ®å¤„ç†å’Œæ¨¡å‹è®­ç»ƒï¼›è®­ç»ƒå®Œæˆåï¼Œç®¡ç†å‘˜ç¡®è®¤å‘å¸ƒæ¨¡å‹ï¼›å…¶ä»–ç”¨æˆ·å†è°ƒç”¨**é¢„æµ‹æœåŠ¡**ï¼Œé€šè¿‡æ¨¡å‹ ID å’ŒåŠ¨æ€è¾“å…¥å‚æ•°è·å–é¢„æµ‹ç»“æœã€‚æ•´ä¸ªè¿‡ç¨‹ä¸­çš„å„æ¨¡å—èŒè´£æ¸…æ™°ï¼Œä½¿ç”¨**é€‚é…å™¨æ¨¡å¼**ä¿è¯äº†å¯¹ä¸åŒæ¨¡å‹ç±»å‹çš„ä¸€è‡´è°ƒç”¨æ¥å£ï¼Œå¹¶é€šè¿‡å·¥å‚/æ³¨å†Œè¡¨æ”¯æŒçµæ´»æ‰©å±•æ–°çš„æ¨¡å‹ç±»å‹ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ª**é«˜åº¦è§£è€¦ã€å¯æ‰©å±•**çš„**AI æ¨¡å‹è®­ç»ƒä¸é¢„æµ‹é€šç”¨æµç¨‹**å®ç°ï¼Œé‡‡ç”¨**é€‚é…å™¨æ¨¡å¼**æ¥æ”¯æŒå¤šç§æ¨¡å‹ï¼ˆçº¿æ€§å›å½’ã€XGBoostã€å¤§è¯­è¨€æ¨¡å‹ç­‰ï¼‰ï¼Œå¹¶å›´ç»•ä½ çš„éœ€æ±‚ï¼ˆæ•°æ®æ¸…æ´—ã€é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€ä¿å­˜ã€å‘å¸ƒã€é¢„æµ‹ï¼‰è¿›è¡Œæ¨¡å—åŒ–æ‹†åˆ†ã€‚

------

## ğŸ§© 1. ç›®å½•ç»“æ„å»ºè®®

```
ai_platform/
â”œâ”€â”€ adapters/                 # å„ç±»æ¨¡å‹é€‚é…å™¨
â”‚   â”œâ”€â”€ base.py              # æ¨¡å‹é€‚é…å™¨æ¥å£
â”‚   â”œâ”€â”€ linear_regression.py
â”‚   â”œâ”€â”€ xgboost_model.py
â”‚   â””â”€â”€ llm_model.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ cleaner.py           # æ•°æ®æ¸…æ´—
â”‚   â”œâ”€â”€ preprocessor.py      # æ•°æ®é¢„å¤„ç†
â”‚   â”œâ”€â”€ scheduler.py         # è®­ç»ƒè°ƒåº¦å™¨
â”‚   â”œâ”€â”€ registry.py          # æ¨¡å‹ä¿å­˜å’Œå‘å¸ƒ
â”‚   â””â”€â”€ predictor.py         # é¢„æµ‹æ¨¡å—
â”œâ”€â”€ config/
â”‚   â””â”€â”€ registry.py          # æ¨¡å‹ç±»å‹æ³¨å†Œè¡¨
â””â”€â”€ main.py                  # è®­ç»ƒ/é¢„æµ‹å…¥å£
```

------

## ğŸ§  2. é€‚é…å™¨æ¥å£å®šä¹‰ï¼ˆ`adapters/base.py`ï¼‰

```python
from abc import ABC, abstractmethod
import pandas as pd
from typing import Dict, Any

class BaseModelAdapter(ABC):
    @abstractmethod
    def train(self, X: pd.DataFrame, y: pd.Series, params: Dict[str, Any]):
        pass

    @abstractmethod
    def predict(self, X: pd.DataFrame) -> Any:
        pass

    @abstractmethod
    def save(self, path: str):
        pass

    @abstractmethod
    def load(self, path: str):
        pass
```

------

## ğŸ“ˆ 3. ç¤ºä¾‹æ¨¡å‹é€‚é…å™¨ï¼šçº¿æ€§å›å½’ï¼ˆ`adapters/linear_regression.py`ï¼‰

```python
from sklearn.linear_model import LinearRegression
from .base import BaseModelAdapter
import joblib

class LinearRegressionAdapter(BaseModelAdapter):
    def __init__(self):
        self.model = None

    def train(self, X, y, params):
        self.model = LinearRegression(**params)
        self.model.fit(X, y)

    def predict(self, X):
        return self.model.predict(X)

    def save(self, path):
        joblib.dump(self.model, path)

    def load(self, path):
        self.model = joblib.load(path)
```

å…¶ä»–æ¨¡å‹å¦‚ XGBoost å’Œ LLM åŒç†ã€‚

------

## ğŸ§¼ 4. æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†æ¨¡å—ï¼ˆ`core/cleaner.py`, `core/preprocessor.py`ï¼‰

```python
# cleaner.py
import pandas as pd
import io
from typing import List

class DataCleaner:
    @staticmethod
    def clean(csv_contents: List[str], factor_names: List[str]) -> pd.DataFrame:
        dfs = [pd.read_csv(io.StringIO(c)) for c in csv_contents]
        df = pd.concat(dfs).drop_duplicates()
        return df[factor_names]
# preprocessor.py
class DataPreprocessor:
    @staticmethod
    def normalize(df: pd.DataFrame, factors: List[Dict]):
        for factor in factors:
            name = factor["name"]
            if factor.get("normalize") and pd.api.types.is_numeric_dtype(df[name]):
                df[name] = (df[name] - df[name].mean()) / df[name].std()
        return df
```

------

## ğŸ§  5. æ¨¡å‹è°ƒåº¦å™¨ï¼šè®­ç»ƒæ‰§è¡Œå™¨ï¼ˆ`core/scheduler.py`ï¼‰

```python
from config.registry import ADAPTER_REGISTRY
from .cleaner import DataCleaner
from .preprocessor import DataPreprocessor
import pandas as pd
import os

class TrainingScheduler:
    def train(self, model_type: str, factors: List[Dict], model_params: Dict, csv_contents: List[str]) -> str:
        # 1. æ¸…æ´—æ•°æ®
        field_names = [f["name"] for f in factors]
        df = DataCleaner.clean(csv_contents, field_names)

        # 2. é¢„å¤„ç†
        df = DataPreprocessor.normalize(df, factors)

        # 3. ç”Ÿæˆ X/y
        target = field_names[-1]
        X = df.drop(columns=[target])
        y = df[target]

        # 4. è·å–é€‚é…å™¨
        adapter_cls = ADAPTER_REGISTRY[model_type]
        model = adapter_cls()
        model.train(X, y, model_params)

        # 5. ä¿å­˜æ¨¡å‹
        path = f"models/{model_type}_{hash(tuple(field_names))}.pkl"
        os.makedirs("models", exist_ok=True)
        model.save(path)

        return path
```

------

## â˜ï¸ 6. å‘å¸ƒæ¨¡å—ï¼ˆ`core/registry.py`ï¼‰

```python
import boto3

class ModelPublisher:
    def upload_to_s3(self, local_path: str, model_key: str, bucket: str):
        s3 = boto3.client("s3")
        s3.upload_file(local_path, bucket, model_key)
```

------

## ğŸ” 7. æ¨ç†æ¨¡å—ï¼ˆ`core/predictor.py`ï¼‰

```python
from config.registry import ADAPTER_REGISTRY

class Predictor:
    def predict(self, model_type: str, model_path: str, input_df):
        adapter_cls = ADAPTER_REGISTRY[model_type]
        model = adapter_cls()
        model.load(model_path)
        return model.predict(input_df)
```

------

## ğŸ§© 8. æ¨¡å‹æ³¨å†Œè¡¨ï¼ˆ`config/registry.py`ï¼‰

```python
from adapters.linear_regression import LinearRegressionAdapter
from adapters.xgboost_model import XGBoostAdapter
from adapters.llm_model import LLMAdapter

ADAPTER_REGISTRY = {
    "linear_regression": LinearRegressionAdapter,
    "xgboost": XGBoostAdapter,
    "llm": LLMAdapter
}
```

------

## ğŸš€ 9. ä¸»è°ƒç”¨æµç¨‹ï¼ˆ`main.py` ç¤ºä¾‹ï¼‰

```python
from core.scheduler import TrainingScheduler
from core.predictor import Predictor

# æ¨¡æ‹Ÿå‰ç«¯è¾“å…¥
factors = [
    {"name": "feature1", "normalize": True},
    {"name": "feature2", "normalize": False},
    {"name": "target", "normalize": False}
]
model_type = "linear_regression"
model_params = {"fit_intercept": True}
csvs = [open("data1.csv").read(), open("data2.csv").read()]

# è®­ç»ƒæµç¨‹
scheduler = TrainingScheduler()
model_path = scheduler.train(model_type, factors, model_params, csvs)

# æ¨ç†æµç¨‹
predictor = Predictor()
import pandas as pd
input_data = pd.DataFrame([{"feature1": 1.2, "feature2": 3.4}])
pred = predictor.predict(model_type, model_path, input_data)
print(pred)
```

------

## âœ… æ€»ç»“ï¼šæ ¸å¿ƒè§£è€¦ç‚¹

| æ¨¡å—                               | åŠŸèƒ½         | è§£è€¦è¯´æ˜                   |
| ---------------------------------- | ------------ | -------------------------- |
| `BaseModelAdapter`                 | æ¨¡å‹æ ‡å‡†æ¥å£ | é€‚é…ä¸åŒæ¨¡å‹è®­ç»ƒä¸æ¨ç†é€»è¾‘ |
| `TrainingScheduler`                | è°ƒåº¦è®­ç»ƒæµç¨‹ | ç‹¬ç«‹äºå…·ä½“æ¨¡å‹ä¸æ•°æ®æ ¼å¼   |
| `DataCleaner` + `DataPreprocessor` | æ•°æ®å¤„ç†æ¨¡å— | ä¸ä¾èµ–æ¨¡å‹é€»è¾‘ï¼ŒæŒ‰å› å­é©±åŠ¨ |
| `ADAPTER_REGISTRY`                 | é€‚é…å™¨æ³¨å†Œè¡¨ | æ¨¡å‹æ‰©å±•é›¶ä¾µå…¥             |
| `Predictor`                        | æ¨ç†ç»Ÿä¸€å…¥å£ | å°è£…æ¨¡å‹åŠ è½½å’Œæ¨ç†é€»è¾‘     |

------

å¦‚ä½ éœ€è¦ï¼Œæˆ‘å¯ä»¥è¿›ä¸€æ­¥è¡¥å……ï¼š

- FastAPI æ¥å£å°è£…ï¼›
- S3 æ¥å£æœ¬åœ° mock æµ‹è¯•ï¼›
- å¯¹æ¥ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå¦‚ Celeryï¼‰æ‰§è¡Œå¼‚æ­¥è®­ç»ƒã€‚

æ˜¯å¦éœ€è¦æˆ‘ç»§ç»­å°è£…è¿™äº›æ¨¡å—ï¼Ÿ

