---
layout:     post
title:      "Django celeryä»»åŠ¡ç®¡ç†"
subtitle:   ""
date:       2025-04-01
author:     " Shallow Dreamer"
header-img: "img/post-bg-js-version.jpg"
tags:
    - Django
    - celery
---

å¥½çš„ï¼Œæˆ‘ä¼šæä¾›ä¸€ä¸ª**å®Œæ•´çš„ Django + Celery ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ**ï¼Œå®ƒæ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š

âœ… **ä¸€æ¬¡æ€§ä»»åŠ¡**ï¼ˆæŒ‡å®šæ—¶é—´æ‰§è¡Œä¸€æ¬¡ï¼‰
 âœ… **å‘¨æœŸä»»åŠ¡**ï¼ˆæ¯éš”å›ºå®šæ—¶é—´æ‰§è¡Œä¸€æ¬¡ï¼‰
 âœ… **å®šæ—¶ä»»åŠ¡**ï¼ˆæ¯å¤©æŸä¸ªæ—¶é—´ç‚¹æ‰§è¡Œï¼‰
 âœ… **ä»»åŠ¡å¯ç”¨/ç¦ç”¨**
 âœ… **æ”¯æŒ Django Admin å’Œ REST API è¿›è¡Œä»»åŠ¡ç®¡ç†**
 âœ… **å¯æ‰©å±•ï¼Œæ”¯æŒä¸åŒç±»å‹çš„ Celery ä»»åŠ¡**

------

# **ğŸ“Œ ç›®å½•ç»“æ„**

```bash
your_project/
â”‚â”€â”€ your_project/            # Django é¡¹ç›®
â”‚   â”‚â”€â”€ settings.py          # Django é…ç½®
â”‚   â”‚â”€â”€ urls.py              # URL è·¯ç”±
â”‚   â””â”€â”€ celery.py            # Celery é…ç½®
â”‚
â”‚â”€â”€ your_app/                # Django åº”ç”¨
â”‚   â”‚â”€â”€ models.py            # ä»»åŠ¡æ•°æ®åº“æ¨¡å‹
â”‚   â”‚â”€â”€ tasks.py             # Celery ä»»åŠ¡
â”‚   â”‚â”€â”€ views.py             # ä»»åŠ¡ API è§†å›¾
â”‚   â”‚â”€â”€ serializers.py       # Django REST æ¡†æ¶åºåˆ—åŒ–
â”‚   â”‚â”€â”€ admin.py             # Django Admin é…ç½®
â”‚   â””â”€â”€ urls.py              # ä»»åŠ¡ API è·¯ç”±
â”‚
â”‚â”€â”€ manage.py                # Django å…¥å£æ–‡ä»¶
â”‚â”€â”€ requirements.txt         # ä¾èµ–åˆ—è¡¨
â”‚â”€â”€ celery_worker.sh         # Celery å¯åŠ¨è„šæœ¬
â””â”€â”€ README.md                # é¡¹ç›®è¯´æ˜
```

------

# **1ï¸âƒ£ å®‰è£… Celery å’Œ Redis**

å…ˆå®‰è£… Celeryã€Redis å’Œ Django REST Frameworkï¼š

```bash
pip install celery redis django djangorestframework
```

Redis éœ€è¦å•ç‹¬å®‰è£…ï¼Œè¿è¡Œï¼š

```bash
sudo apt install redis  # Ubuntu
brew install redis  # macOS
```

------

# **2ï¸âƒ£ é…ç½® Celery**

åœ¨ `your_project/celery.py` æ·»åŠ  Celery é…ç½®ï¼š

```python
import os
from celery import Celery

# è®¾ç½® Django çš„ settings æ¨¡å—
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'your_project.settings')

app = Celery('your_project')

# ä» Django é…ç½®æ–‡ä»¶ä¸­è¯»å– Celery é…ç½®
app.config_from_object('django.conf:settings', namespace='CELERY')

# è‡ªåŠ¨å‘ç°æ‰€æœ‰ Django app ä¸­çš„ tasks.py
app.autodiscover_tasks()
```

åœ¨ `your_project/settings.py` é‡Œæ·»åŠ  Celery é…ç½®ï¼š

```python
CELERY_BROKER_URL = 'redis://localhost:6379/0'
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
```

------

# **3ï¸âƒ£ å®šä¹‰ä»»åŠ¡æ¨¡å‹**

åœ¨ `your_app/models.py` å®šä¹‰ä»»åŠ¡å­˜å‚¨ï¼š

```python
from django.db import models

class ScheduledTask(models.Model):
    TASK_TYPES = (
        ('one_time', 'ä¸€æ¬¡æ€§ä»»åŠ¡'),
        ('interval', 'é—´éš”ä»»åŠ¡'),
        ('cron', 'å®šæ—¶ä»»åŠ¡'),
    )

    name = models.CharField(max_length=255, unique=True, verbose_name="ä»»åŠ¡åç§°")
    task_name = models.CharField(max_length=255, verbose_name="Celery ä»»åŠ¡è·¯å¾„")
    task_type = models.CharField(max_length=10, choices=TASK_TYPES, verbose_name="ä»»åŠ¡ç±»å‹")
    run_at = models.DateTimeField(null=True, blank=True, verbose_name="æ‰§è¡Œæ—¶é—´")  # ä»…é€‚ç”¨äºä¸€æ¬¡æ€§ä»»åŠ¡
    interval_seconds = models.IntegerField(null=True, blank=True, verbose_name="é—´éš”ç§’æ•°")  # ä»…é€‚ç”¨äºé—´éš”ä»»åŠ¡
    cron_schedule = models.CharField(max_length=50, null=True, blank=True, verbose_name="Cron è¡¨è¾¾å¼")  # ä»…é€‚ç”¨äºå®šæ—¶ä»»åŠ¡
    args = models.JSONField(default=list, verbose_name="ä»»åŠ¡å‚æ•°")
    enabled = models.BooleanField(default=True, verbose_name="æ˜¯å¦å¯ç”¨")

    def __str__(self):
        return self.name
```

------

# **4ï¸âƒ£ åˆ›å»º Celery ä»»åŠ¡**

åœ¨ `your_app/tasks.py` é‡Œå®šä¹‰ä»»åŠ¡ï¼š

```python
from celery import shared_task

@shared_task
def example_task(message):
    print(f"æ‰§è¡Œä»»åŠ¡: {message}")
    return f"ä»»åŠ¡å®Œæˆ: {message}"

@shared_task
def check_and_run_tasks():
    """å®šæœŸæ£€æŸ¥æ•°æ®åº“ä¸­çš„ä»»åŠ¡ï¼Œå¹¶è§¦å‘ Celery æ‰§è¡Œ"""
    from your_app.models import ScheduledTask
    from django.utils.timezone import now
    from datetime import datetime
    import crontab

    tasks = ScheduledTask.objects.filter(enabled=True)
    
    for task in tasks:
        if task.task_type == "one_time" and task.run_at and task.run_at <= now():
            example_task.apply_async(args=task.args)
            task.enabled = False  # åªæ‰§è¡Œä¸€æ¬¡
            task.save()

        elif task.task_type == "interval" and task.interval_seconds:
            example_task.apply_async(args=task.args, countdown=task.interval_seconds)

        elif task.task_type == "cron" and task.cron_schedule:
            cron = crontab.CronTab(task.cron_schedule)
            if cron.next(default_utc=True) == 0:
                example_task.apply_async(args=task.args)
```

**è§£é‡Šï¼š**

- `one_time` ä»»åŠ¡ï¼šåªæ‰§è¡Œä¸€æ¬¡ï¼Œå®Œæˆåè‡ªåŠ¨ç¦ç”¨ã€‚
- `interval` ä»»åŠ¡ï¼šæ¯ `interval_seconds` è¿è¡Œä¸€æ¬¡ã€‚
- `cron` ä»»åŠ¡ï¼šæ ¹æ® `cron_schedule` æ‰§è¡Œã€‚

------

# **5ï¸âƒ£ é…ç½® Celery Worker**

åœ¨ `your_project/celery.py` é‡Œæ·»åŠ ï¼š

```python
from celery.schedules import crontab

app.conf.beat_schedule = {
    "check_scheduled_tasks": {
        "task": "your_app.tasks.check_and_run_tasks",
        "schedule": crontab(minute="*"),  # æ¯åˆ†é’Ÿæ‰§è¡Œ
    },
}
```

è¿è¡Œ Celeryï¼š

```bash
celery -A your_project worker --loglevel=info
```

------

# **6ï¸âƒ£ Django Admin ç®¡ç†ä»»åŠ¡**

åœ¨ `your_app/admin.py` é‡Œæ³¨å†Œï¼š

```python
from django.contrib import admin
from .models import ScheduledTask

@admin.register(ScheduledTask)
class ScheduledTaskAdmin(admin.ModelAdmin):
    list_display = ("name", "task_type", "enabled", "updated_at")
    search_fields = ("name",)
```

------

# **7ï¸âƒ£ åˆ›å»º Django API**

åœ¨ `your_app/views.py` é‡Œï¼š

```python
from rest_framework import viewsets
from .models import ScheduledTask
from .serializers import ScheduledTaskSerializer
from rest_framework.response import Response
from rest_framework.decorators import action

class ScheduledTaskViewSet(viewsets.ModelViewSet):
    queryset = ScheduledTask.objects.all()
    serializer_class = ScheduledTaskSerializer

    @action(detail=True, methods=["post"])
    def run_task(self, request, pk=None):
        """æ‰‹åŠ¨è§¦å‘ä»»åŠ¡"""
        task = self.get_object()
        from your_app.tasks import example_task
        example_task.apply_async(args=task.args)
        return Response({"status": "ä»»åŠ¡å·²è§¦å‘"})
```

åœ¨ `your_app/serializers.py` é‡Œï¼š

```python
from rest_framework import serializers
from .models import ScheduledTask

class ScheduledTaskSerializer(serializers.ModelSerializer):
    class Meta:
        model = ScheduledTask
        fields = "__all__"
```

åœ¨ `your_project/urls.py` é‡Œï¼š

```python
from django.urls import path, include
from rest_framework.routers import DefaultRouter
from your_app.views import ScheduledTaskViewSet

router = DefaultRouter()
router.register(r"tasks", ScheduledTaskViewSet)

urlpatterns = [
    path("api/", include(router.urls)),
]
```

------

# **8ï¸âƒ£ è¿è¡Œé¡¹ç›®**

1. è¿è¡Œ Djangoï¼š

   ```bash
   python manage.py runserver
   ```

2. è¿è¡Œ Celery Workerï¼š

   ```bash
   celery -A your_project worker --loglevel=info
   ```

3. è¿è¡Œ Celery Beatï¼ˆå¦‚æœä½¿ç”¨ `cron` ä»»åŠ¡ï¼‰ï¼š

   ```bash
   celery -A your_project beat --loglevel=info
   ```

------

# **âœ… ç»“æœ**

- è®¿é—® `/admin/` å¯ç®¡ç†ä»»åŠ¡ã€‚
- è®¿é—® `/api/tasks/` å¯åˆ›å»º/ä¿®æ”¹ä»»åŠ¡ã€‚
- Celery **è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡** ğŸ‰

è¿™ä¸ªæ–¹æ¡ˆ**å¯æ‰©å±•ã€æ”¯æŒå„ç§ä»»åŠ¡ç±»å‹**ï¼Œå¹¶èƒ½é€šè¿‡ Django Admin æˆ– API è¿›è¡Œç®¡ç†ï¼ğŸš€

æ˜¯çš„ï¼Œä½ åˆ›å»ºçš„ä»»åŠ¡ä¼šå­˜å‚¨åœ¨**æ•°æ®åº“**ä¸­ï¼Œå…·ä½“æ¥è¯´ï¼Œæ‰€æœ‰ä»»åŠ¡æ•°æ®éƒ½ä¼šå­˜å…¥ `ScheduledTask` è¿™ä¸ªæ•°æ®åº“è¡¨é‡Œã€‚

------

# **ğŸ“Œ ä»»åŠ¡å­˜å‚¨æ–¹å¼**

åœ¨ `your_app/models.py` é‡Œï¼Œæˆ‘ä»¬å®šä¹‰äº† `ScheduledTask` æ¨¡å‹ï¼ŒDjango ä¼šè‡ªåŠ¨å°†ä»»åŠ¡æ•°æ®å­˜å…¥æ•°æ®åº“ï¼š

```python
class ScheduledTask(models.Model):
    TASK_TYPES = (
        ('one_time', 'ä¸€æ¬¡æ€§ä»»åŠ¡'),
        ('interval', 'é—´éš”ä»»åŠ¡'),
        ('cron', 'å®šæ—¶ä»»åŠ¡'),
    )

    name = models.CharField(max_length=255, unique=True, verbose_name="ä»»åŠ¡åç§°")
    task_name = models.CharField(max_length=255, verbose_name="Celery ä»»åŠ¡è·¯å¾„")
    task_type = models.CharField(max_length=10, choices=TASK_TYPES, verbose_name="ä»»åŠ¡ç±»å‹")
    run_at = models.DateTimeField(null=True, blank=True, verbose_name="æ‰§è¡Œæ—¶é—´")  # ä»…é€‚ç”¨äºä¸€æ¬¡æ€§ä»»åŠ¡
    interval_seconds = models.IntegerField(null=True, blank=True, verbose_name="é—´éš”ç§’æ•°")  # ä»…é€‚ç”¨äºé—´éš”ä»»åŠ¡
    cron_schedule = models.CharField(max_length=50, null=True, blank=True, verbose_name="Cron è¡¨è¾¾å¼")  # ä»…é€‚ç”¨äºå®šæ—¶ä»»åŠ¡
    args = models.JSONField(default=list, verbose_name="ä»»åŠ¡å‚æ•°")
    enabled = models.BooleanField(default=True, verbose_name="æ˜¯å¦å¯ç”¨")

    def __str__(self):
        return self.name
```

------

# **ğŸ“Œ ä»»åŠ¡å­˜åœ¨å“ªï¼Ÿ**

ä»»åŠ¡æ•°æ®å­˜å‚¨åœ¨ Django **æ•°æ®åº“**ï¼ˆå¦‚ PostgreSQL æˆ– MySQLï¼‰ä¸­ï¼š

1. **å¦‚æœä½ ä½¿ç”¨ SQLite**ï¼Œä»»åŠ¡æ•°æ®ä¼šå­˜å…¥ `db.sqlite3` æ–‡ä»¶ã€‚
2. **å¦‚æœä½ ä½¿ç”¨ PostgreSQL**ï¼Œä»»åŠ¡æ•°æ®ä¼šå­˜å…¥ `scheduled_task` è¡¨ã€‚

ä½ å¯ä»¥é€šè¿‡ **Django Admin** ç›´æ¥æŸ¥çœ‹è¿™äº›ä»»åŠ¡ï¼Œä¹Ÿå¯ä»¥åœ¨æ•°æ®åº“é‡Œæ‰§è¡Œ SQL æŸ¥è¯¢ï¼š

```sql
SELECT * FROM your_app_scheduledtask;
```

------

# **ğŸ“Œ ä»»åŠ¡åˆ›å»ºæ–¹å¼**

## **æ–¹å¼ 1ï¸âƒ£ï¼šDjango Admin ç•Œé¢**

è®¿é—® `/admin/`ï¼Œå¯ä»¥**æ‰‹åŠ¨åˆ›å»ºå’Œç®¡ç†ä»»åŠ¡**ã€‚

------

## **æ–¹å¼ 2ï¸âƒ£ï¼šREST API**

å¯ä»¥é€šè¿‡ **REST API** æ¥åˆ›å»ºä»»åŠ¡ï¼š

```bash
curl -X POST http://127.0.0.1:8000/api/tasks/ \
     -H "Content-Type: application/json" \
     -d '{
         "name": "æµ‹è¯•ä»»åŠ¡",
         "task_name": "your_app.tasks.example_task",
         "task_type": "one_time",
         "run_at": "2025-04-01T12:00:00Z",
         "args": ["Hello, Celery!"],
         "enabled": true
     }'
```

è¿™æ ·ï¼Œä»»åŠ¡ä¼šè¢«å­˜å…¥æ•°æ®åº“ï¼ŒCelery Worker ä¹Ÿä¼šè‡ªåŠ¨æ‰§è¡Œå®ƒã€‚

------

# **ğŸ“Œ ä»»åŠ¡å¦‚ä½•æ‰§è¡Œï¼Ÿ**

**Celery Worker** æ¯éš” 1 åˆ†é’Ÿ**æ£€æŸ¥æ•°æ®åº“**ï¼Œç„¶åè§¦å‘ç¬¦åˆæ¡ä»¶çš„ä»»åŠ¡ï¼š

```python
@shared_task
def check_and_run_tasks():
    """å®šæœŸæ£€æŸ¥æ•°æ®åº“ä¸­çš„ä»»åŠ¡ï¼Œå¹¶è§¦å‘ Celery æ‰§è¡Œ"""
    from your_app.models import ScheduledTask
    from django.utils.timezone import now
    from datetime import datetime
    import crontab

    tasks = ScheduledTask.objects.filter(enabled=True)
    
    for task in tasks:
        if task.task_type == "one_time" and task.run_at and task.run_at <= now():
            example_task.apply_async(args=task.args)
            task.enabled = False  # åªæ‰§è¡Œä¸€æ¬¡
            task.save()

        elif task.task_type == "interval" and task.interval_seconds:
            example_task.apply_async(args=task.args, countdown=task.interval_seconds)

        elif task.task_type == "cron" and task.cron_schedule:
            cron = crontab.CronTab(task.cron_schedule)
            if cron.next(default_utc=True) == 0:
                example_task.apply_async(args=task.args)
```

è¿™æ ·ï¼Œæ•°æ®åº“é‡Œçš„ä»»åŠ¡**ä¼šè¢« Celery è‡ªåŠ¨æ‰§è¡Œ**ï¼Œè€Œä¸”ä»»åŠ¡çŠ¶æ€ä¹Ÿä¼šæ›´æ–°ï¼

------

# **ğŸ“Œ å¦‚ä½•æŸ¥çœ‹å·²å­˜å‚¨çš„ä»»åŠ¡ï¼Ÿ**

ä½ å¯ä»¥åœ¨ **Django Admin** é‡ŒæŸ¥çœ‹ï¼š

1. è®¿é—® `http://127.0.0.1:8000/admin/`
2. è¿›å…¥ `ScheduledTask` è¡¨
3. æŸ¥çœ‹æ‰€æœ‰å·²å­˜å‚¨çš„ä»»åŠ¡

æˆ–è€…ç›´æ¥ç”¨ **æ•°æ®åº“æŸ¥è¯¢**ï¼š

```sql
SELECT * FROM your_app_scheduledtask;
```

------

# **âœ… æ€»ç»“**

- **ä»»åŠ¡ä¼šå­˜å…¥æ•°æ®åº“ `ScheduledTask` è¡¨**
- **æ”¯æŒ Django Admin ç®¡ç†ä»»åŠ¡**
- **æ”¯æŒ REST API åˆ›å»ºä»»åŠ¡**
- **Celery Worker æ¯åˆ†é’Ÿæ£€æŸ¥æ•°æ®åº“ï¼Œè‡ªåŠ¨æ‰§è¡Œä»»åŠ¡**

è¿™æ ·ï¼Œä½ å°±å¯ä»¥**åœ¨æ•°æ®åº“é‡ŒåŠ¨æ€ç®¡ç† Celery ä»»åŠ¡**ï¼Œä¸éœ€è¦é‡å¯ Celery Workerï¼ğŸš€

æ˜¯çš„ï¼Œå¦‚æœ **Celery Worker æ¯åˆ†é’Ÿè½®è¯¢æ•°æ®åº“** æ¥æ£€æŸ¥ä»»åŠ¡ï¼Œ**æ•°æ®åº“æŸ¥è¯¢é¢‘ç¹** å¯èƒ½ä¼šå½±å“æ€§èƒ½ï¼Œå°¤å…¶æ˜¯å½“ä»»åŠ¡é‡å¾ˆå¤§æ—¶ã€‚

## **ğŸ“Œ å­˜åœ¨çš„é—®é¢˜**

1. **é«˜é¢‘æŸ¥è¯¢æ•°æ®åº“**ï¼šæ¯åˆ†é’Ÿè½®è¯¢æ•°æ®åº“ï¼Œéšç€ä»»åŠ¡é‡å¢åŠ ï¼ŒæŸ¥è¯¢è´Ÿæ‹…ä¼šå˜é‡ã€‚
2. **Celery Worker éœ€è¦ä¸»åŠ¨æ£€æŸ¥**ï¼šè¿™ç§è½®è¯¢æ–¹å¼å¹¶ä¸æ˜¯æœ€ä¼˜çš„ï¼Œå¯èƒ½ä¼šæµªè´¹è®¡ç®—èµ„æºã€‚
3. **ä»»åŠ¡è§¦å‘å¯èƒ½ä¼šæœ‰å»¶è¿Ÿ**ï¼šå¦‚æœä»»åŠ¡æ—¶é—´ç‚¹æ­£å¥½è½åœ¨ä¸¤ä¸ªæŸ¥è¯¢é—´éš”ä¹‹é—´ï¼Œå¯èƒ½ä¼šå»¶è¿Ÿæ‰§è¡Œã€‚

------

## **âœ… æ›´é«˜æ•ˆçš„æ–¹å¼**

æˆ‘ä»¬å¯ä»¥æ”¹è¿›ï¼š

1. **ä½¿ç”¨ Celery Beat æ¥ç®¡ç†å‘¨æœŸä»»åŠ¡**ï¼ˆå®˜æ–¹æ¨èï¼‰
2. **ä½¿ç”¨æ•°æ®åº“è§¦å‘å™¨æˆ– Webhook è®© Celery Worker åœ¨ä»»åŠ¡æ›´æ–°æ—¶è‡ªåŠ¨è§¦å‘**
3. **ä½¿ç”¨ Django Signals ç›‘å¬ä»»åŠ¡å˜åŒ–**

------

# **æ–¹æ¡ˆ 1ï¸âƒ£ï¼šä½¿ç”¨ Celery Beatï¼ˆå®˜æ–¹æ¨èï¼‰**

**Celery Beat** å…è®¸ä½ æŠŠ**å®šæ—¶ä»»åŠ¡å­˜å…¥æ•°æ®åº“**ï¼Œç„¶åè‡ªåŠ¨è§¦å‘ Celery æ‰§è¡Œï¼Œè€Œä¸éœ€è¦æ‰‹åŠ¨è½®è¯¢æ•°æ®åº“ã€‚

### **ğŸ“Œ å®‰è£… Celery Beat**

```bash
pip install django-celery-beat
```

### **ğŸ“Œ é…ç½® `INSTALLED_APPS`**

åœ¨ `settings.py` é‡Œæ·»åŠ ï¼š

```python
INSTALLED_APPS = [
    ...,
    'django_celery_beat',
]
```

### **ğŸ“Œ è¿è¡Œæ•°æ®åº“è¿ç§»**

```bash
python manage.py migrate django_celery_beat
```

### **ğŸ“Œ åœ¨ `your_project/celery.py` é‡Œæ·»åŠ **

```python
from celery.schedules import crontab
from django_celery_beat.models import PeriodicTask, IntervalSchedule

app.conf.beat_scheduler = 'django_celery_beat.schedulers.DatabaseScheduler'
```

### **ğŸ“Œ è¿è¡Œ Celery Beat**

```bash
celery -A your_project beat --loglevel=info
```

### **ğŸ“Œ è¿™æ ·æ”¹è¿›äº†ä»€ä¹ˆï¼Ÿ**

âœ… **ä»»åŠ¡å­˜å…¥æ•°æ®åº“ï¼ŒCelery Beat è¯»å–æ•°æ®åº“å¹¶è§¦å‘ä»»åŠ¡**
 âœ… **ä¸éœ€è¦æ‰‹åŠ¨è½®è¯¢æ•°æ®åº“ï¼Œå‡å°‘ Worker è´Ÿæ‹…**
 âœ… **ä»»åŠ¡å¯ä»¥åœ¨ Django Admin é‡Œç®¡ç†ï¼ˆ`django_celery_beat` æä¾›çš„åŠŸèƒ½ï¼‰**

------

# **æ–¹æ¡ˆ 2ï¸âƒ£ï¼šä½¿ç”¨ Django Signals**

**Django Signals å¯ä»¥åœ¨ä»»åŠ¡åˆ›å»ºæˆ–æ›´æ–°æ—¶ï¼Œ** **è‡ªåŠ¨è§¦å‘ Celery Worker**ï¼Œé¿å…ä¸å¿…è¦çš„è½®è¯¢ã€‚

åœ¨ `your_app/signals.py` é‡Œï¼š

```python
from django.db.models.signals import post_save
from django.dispatch import receiver
from .models import ScheduledTask
from .tasks import example_task
from django.utils.timezone import now

@receiver(post_save, sender=ScheduledTask)
def trigger_task_on_create(sender, instance, **kwargs):
    """å½“ä»»åŠ¡åˆ›å»ºæˆ–æ›´æ–°æ—¶ï¼Œè‡ªåŠ¨è§¦å‘ Celery æ‰§è¡Œ"""
    if instance.enabled:
        if instance.task_type == "one_time" and instance.run_at and instance.run_at <= now():
            example_task.apply_async(args=instance.args)
            instance.enabled = False  # åªæ‰§è¡Œä¸€æ¬¡
            instance.save()
```

### **ğŸ“Œ è¿™æ ·æ”¹è¿›äº†ä»€ä¹ˆï¼Ÿ**

âœ… **ä»»åŠ¡åˆ›å»ºåè‡ªåŠ¨è§¦å‘ï¼Œä¸éœ€è¦è½®è¯¢æ•°æ®åº“**
 âœ… **Celery Worker åªæ‰§è¡ŒçœŸæ­£éœ€è¦çš„ä»»åŠ¡**
 âœ… **å‡å°‘æ•°æ®åº“å‹åŠ›ï¼Œæé«˜æ•ˆç‡**

------

# **æ–¹æ¡ˆ 3ï¸âƒ£ï¼šä½¿ç”¨ PostgreSQL è§¦å‘å™¨**

å¦‚æœä½ çš„æ•°æ®åº“æ˜¯ **PostgreSQL**ï¼Œå¯ä»¥ä½¿ç”¨ **è§¦å‘å™¨** è®© Celery åœ¨ä»»åŠ¡æ›´æ–°æ—¶è‡ªåŠ¨æ‰§è¡Œï¼Œè€Œä¸æ˜¯è®© Celery Worker è½®è¯¢æ•°æ®åº“ã€‚

### **ğŸ“Œ 1. åˆ›å»ºæ•°æ®åº“è§¦å‘å™¨**

åœ¨ PostgreSQL é‡Œæ‰§è¡Œï¼š

```sql
CREATE FUNCTION notify_task_created() RETURNS TRIGGER AS $$
BEGIN
    NOTIFY new_task, json_build_object('id', NEW.id, 'task_name', NEW.task_name)::text;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER task_trigger
AFTER INSERT OR UPDATE ON your_app_scheduledtask
FOR EACH ROW EXECUTE FUNCTION notify_task_created();
```

### **ğŸ“Œ 2. åœ¨ Celery Worker ç›‘å¬é€šçŸ¥**

ä¿®æ”¹ Celery Workerï¼Œè®©å®ƒç›‘å¬ `new_task` äº‹ä»¶ï¼š

```python
import psycopg2
import select
from your_app.tasks import example_task

def listen_for_new_tasks():
    conn = psycopg2.connect("dbname=yourdb user=youruser password=yourpassword")
    conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)
    cur = conn.cursor()
    cur.execute("LISTEN new_task;")

    print("Listening for new tasks...")
    while True:
        select.select([conn], [], [], None)
        conn.poll()
        while conn.notifies:
            notify = conn.notifies.pop(0)
            task_data = json.loads(notify.payload)
            example_task.apply_async(args=[task_data["task_name"]])

listen_for_new_tasks()
```

### **ğŸ“Œ è¿™æ ·æ”¹è¿›äº†ä»€ä¹ˆï¼Ÿ**

âœ… **ä»»åŠ¡æ’å…¥æˆ–æ›´æ–°æ—¶ï¼Œæ•°æ®åº“ä¸»åŠ¨é€šçŸ¥ Celeryï¼Œä¸ç”¨è½®è¯¢æ•°æ®åº“**
 âœ… **ä½å»¶è¿Ÿï¼Œä»»åŠ¡å‡ ä¹ç«‹å³è§¦å‘**
 âœ… **é€‚åˆå¤§è§„æ¨¡ä»»åŠ¡ç®¡ç†ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢è´Ÿæ‹…**

------

# **ğŸ“Œ æ€»ç»“**

| æ–¹æ¡ˆ                  | é€‚ç”¨åœºæ™¯         | ä¼˜ç‚¹                          | ç¼ºç‚¹                        |
| --------------------- | ---------------- | ----------------------------- | --------------------------- |
| **Celery Beat**       | éœ€è¦å‘¨æœŸæ€§ä»»åŠ¡   | ä»»åŠ¡å­˜æ•°æ®åº“ï¼Œè‡ªåŠ¨è°ƒåº¦        | ä»éœ€ `beat` è¿›ç¨‹            |
| **Django Signals**    | ä»»åŠ¡æ‰‹åŠ¨åˆ›å»ºè¾ƒå¤š | ä»»åŠ¡åˆ›å»ºæ—¶è‡ªåŠ¨æ‰§è¡Œï¼Œæ— éœ€è½®è¯¢  | ä»…é€‚ç”¨äºä»»åŠ¡åˆ›å»ºæ—¶è§¦å‘      |
| **PostgreSQL è§¦å‘å™¨** | å¤§è§„æ¨¡ä»»åŠ¡ç®¡ç†   | æ•°æ®åº“ä¸»åŠ¨é€šçŸ¥ Celeryï¼Œä½å»¶è¿Ÿ | éœ€è¦ PostgreSQLï¼Œé…ç½®è¾ƒå¤æ‚ |

------

# **ğŸš€ æ¨èæ–¹æ¡ˆ**

- **å¦‚æœä½ ä½¿ç”¨å‘¨æœŸæ€§ä»»åŠ¡ï¼ˆinterval/cronï¼‰** ğŸ‘‰ ç”¨ `Celery Beat`
- **å¦‚æœä½ éœ€è¦ä»»åŠ¡åˆ›å»ºåç«‹åˆ»æ‰§è¡Œ** ğŸ‘‰ ç”¨ `Django Signals`
- **å¦‚æœä½ æœ‰å¤§é‡ä»»åŠ¡ï¼Œæ•°æ®åº“æ€§èƒ½è¦æœ€ä¼˜** ğŸ‘‰ ç”¨ `PostgreSQL è§¦å‘å™¨`

è¿™æ ·ï¼Œä½ çš„ Celery Worker **ä¸ä¼šä¸€ç›´è½®è¯¢æ•°æ®åº“**ï¼Œé¿å…æ€§èƒ½é—®é¢˜ï¼ŒåŒæ—¶è¿˜èƒ½ç¡®ä¿ä»»åŠ¡èƒ½åŠæ—¶æ‰§è¡Œï¼ ğŸš€

ä¸‹é¢æ˜¯ä¸€ä¸ª**å®Œæ•´çš„ Django + Celery + Celery Beat è§£å†³æ–¹æ¡ˆ**ï¼Œå®ƒæ”¯æŒ **ä¸€æ¬¡æ€§ä»»åŠ¡ã€å®šæ—¶ä»»åŠ¡ï¼ˆCronï¼‰ã€é—´éš”ä»»åŠ¡ï¼ˆIntervalï¼‰**ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡ **Django Admin æˆ– REST API** è¿›è¡Œç®¡ç†ï¼ŒåŒæ—¶å…·æœ‰**é«˜æ‰©å±•æ€§**ã€‚

------

# **ğŸ“Œ ä¸»è¦æŠ€æœ¯æ ˆ**

- **Celery**ï¼šæ‰§è¡Œå¼‚æ­¥ä»»åŠ¡
- **Celery Beat**ï¼šç®¡ç†å‘¨æœŸæ€§ä»»åŠ¡ï¼ˆå­˜å…¥æ•°æ®åº“ï¼‰
- **Redis**ï¼šä½œä¸º Celery Brokerï¼ˆæ¶ˆæ¯é˜Ÿåˆ—ï¼‰
- **Django REST Framework**ï¼ˆå¯é€‰ï¼‰ï¼šç”¨äº API ç®¡ç†ä»»åŠ¡

------

# **1ï¸âƒ£ å®‰è£…å¿…è¦çš„ä¾èµ–**

```bash
pip install celery redis django-celery-beat django-celery-results djangorestframework
```

------

# **2ï¸âƒ£ é…ç½® Django Settings**

åœ¨ `settings.py` é‡Œæ·»åŠ  Celery å’Œ Celery Beat é…ç½®ï¼š

```python
from celery.schedules import crontab

# Celery é…ç½®
CELERY_BROKER_URL = 'redis://localhost:6379/0'  # ä½¿ç”¨ Redis ä½œä¸ºæ¶ˆæ¯é˜Ÿåˆ—
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_TIMEZONE = 'UTC'

# Celery ç»“æœå­˜å‚¨
CELERY_RESULT_BACKEND = 'django-db'

# Celery Beat é…ç½®
INSTALLED_APPS = [
    ...,
    'django_celery_beat',
    'django_celery_results',  # å­˜å‚¨ä»»åŠ¡ç»“æœ
]
```

ç„¶åè¿è¡Œæ•°æ®åº“è¿ç§»ï¼š

```bash
python manage.py migrate django_celery_beat
python manage.py migrate django_celery_results
```

------

# **3ï¸âƒ£ é…ç½® Celery**

åˆ›å»º `your_project/celery.py` æ–‡ä»¶ï¼š

```python
import os
from celery import Celery

# è®¾ç½® Django çš„é»˜è®¤è®¾ç½®æ¨¡å—
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'your_project.settings')

app = Celery('your_project')

# ä» settings.py åŠ è½½é…ç½®
app.config_from_object('django.conf:settings', namespace='CELERY')

# è‡ªåŠ¨å‘ç°ä»»åŠ¡
app.autodiscover_tasks()

@app.task(bind=True)
def debug_task(self):
    print(f'Request: {self.request!r}')
```

åœ¨ `your_project/__init__.py` é‡Œæ·»åŠ ï¼š

```python
from .celery import app as celery_app

__all__ = ('celery_app',)
```

------

# **4ï¸âƒ£ åˆ›å»º Celery ä»»åŠ¡**

åœ¨ `your_app/tasks.py` é‡Œå®šä¹‰ä¸€ä¸ª Celery ä»»åŠ¡ï¼š

```python
from celery import shared_task

@shared_task
def example_task(message):
    print(f'æ‰§è¡Œä»»åŠ¡: {message}')
    return f'ä»»åŠ¡å®Œæˆ: {message}'
```

------

# **5ï¸âƒ£ è¿è¡Œ Celery Worker å’Œ Celery Beat**

### **ğŸ“Œ è¿è¡Œ Celery Worker**

```bash
celery -A your_project worker --loglevel=info
```

### **ğŸ“Œ è¿è¡Œ Celery Beat**

```bash
celery -A your_project beat --loglevel=info
```

------

# **6ï¸âƒ£ ä½¿ç”¨ Django Admin ç®¡ç†ä»»åŠ¡**

Django-Celery-Beat æä¾›äº† **Admin ç•Œé¢** æ¥ç®¡ç†å®šæ—¶ä»»åŠ¡ï¼š

1. **è¿è¡Œ Django æœåŠ¡å™¨**

   ```bash
   python manage.py runserver
   ```

2. **è®¿é—® `http://127.0.0.1:8000/admin/`**

3. **åˆ›å»ºé—´éš”ä»»åŠ¡**

   - è¿›å…¥ `Periodic Tasks`
   - **é€‰æ‹© `example_task` ä»»åŠ¡**
   - **æ·»åŠ é—´éš”æ—¶é—´ï¼ˆæ¯”å¦‚æ¯ 10 åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡ï¼‰**
   - **å¯ç”¨ä»»åŠ¡**
   - **ä¿å­˜**

------

# **7ï¸âƒ£ ä½¿ç”¨ API è¿›è¡Œä»»åŠ¡ç®¡ç†**

å¦‚æœä½ æƒ³é€šè¿‡ API åˆ›å»ºå’Œç®¡ç†ä»»åŠ¡ï¼Œå¯ä»¥ä½¿ç”¨ Django REST Frameworkï¼š

## **ğŸ“Œ 1. åˆ›å»º API è§†å›¾**

åœ¨ `your_app/views.py` é‡Œï¼š

```python
from rest_framework.views import APIView
from rest_framework.response import Response
from django_celery_beat.models import PeriodicTask, IntervalSchedule
import json
from your_app.tasks import example_task

class TaskAPI(APIView):
    """API è§†å›¾ï¼šåŠ¨æ€åˆ›å»º Celery ä»»åŠ¡"""

    def post(self, request):
        data = request.data
        task_name = data.get("task_name", "example_task")
        interval = data.get("interval", 10)
        message = data.get("message", "é»˜è®¤ä»»åŠ¡")

        # åˆ›å»ºé—´éš”æ—¶é—´ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        schedule, created = IntervalSchedule.objects.get_or_create(
            every=interval, period=IntervalSchedule.SECONDS
        )

        # åˆ›å»ºä»»åŠ¡
        task = PeriodicTask.objects.create(
            interval=schedule,
            name=f"ä»»åŠ¡-{message}",
            task=task_name,
            args=json.dumps([message]),  # ä¼ é€’å‚æ•°
        )

        return Response({"status": "ä»»åŠ¡å·²åˆ›å»º", "task_id": task.id})
```

## **ğŸ“Œ 2. é…ç½® URL**

åœ¨ `your_app/urls.py` é‡Œï¼š

```python
from django.urls import path
from .views import TaskAPI

urlpatterns = [
    path('api/tasks/', TaskAPI.as_view(), name='task-api'),
]
```

------

# **8ï¸âƒ£ é€šè¿‡ API åˆ›å»ºä»»åŠ¡**

```bash
curl -X POST http://127.0.0.1:8000/api/tasks/ \
     -H "Content-Type: application/json" \
     -d '{
         "task_name": "your_app.tasks.example_task",
         "interval": 30,
         "message": "é€šè¿‡ API åˆ›å»ºçš„ä»»åŠ¡"
     }'
```

è¿™æ ·ï¼ŒCelery å°±ä¼šæ¯ **30 ç§’** æ‰§è¡Œ `example_task`ï¼Œå¹¶è¾“å‡ºï¼š

```
æ‰§è¡Œä»»åŠ¡: é€šè¿‡ API åˆ›å»ºçš„ä»»åŠ¡
```

------

# **ğŸ“Œ æ€»ç»“**

| æ–¹æ¡ˆ             | æ–¹å¼          | é€‚ç”¨åœºæ™¯           | æ˜¯å¦å¯æ‰©å±•                  |
| ---------------- | ------------- | ------------------ | --------------------------- |
| **Django Admin** | æ‰‹åŠ¨ç®¡ç†ä»»åŠ¡  | é€‚ç”¨äºæ‰‹åŠ¨è°ƒæ•´ä»»åŠ¡ | âœ… å¯ç®¡ç† Cron/Interval ä»»åŠ¡ |
| **API æ–¹å¼**     | é€šè¿‡ API åˆ›å»º | é€‚ç”¨äºåŠ¨æ€åˆ›å»ºä»»åŠ¡ | âœ… å¯åŠ¨æ€ç®¡ç†ä»»åŠ¡            |
| **Celery Beat**  | å®šæœŸæ‰§è¡Œä»»åŠ¡  | é€‚ç”¨äºå‘¨æœŸä»»åŠ¡     | âœ… ä»»åŠ¡æ•°æ®å­˜æ•°æ®åº“          |

------

# **ğŸš€ ä½ çš„ Celery Beat ä»»åŠ¡ç®¡ç†ç³»ç»Ÿå·²å®Œæˆ**

- **æ”¯æŒ** ä¸€æ¬¡æ€§ä»»åŠ¡ã€å‘¨æœŸä»»åŠ¡ï¼ˆInterval & Cronï¼‰
- **æ”¯æŒ** Django Admin æ‰‹åŠ¨ç®¡ç†ä»»åŠ¡
- **æ”¯æŒ** API æ–¹å¼åŠ¨æ€åˆ›å»ºä»»åŠ¡
- **æ”¯æŒ** Celery Beat è‡ªåŠ¨è°ƒåº¦ä»»åŠ¡
- **æ”¯æŒ** å¯æ‰©å±•çš„ä»»åŠ¡ç®¡ç†æ–¹å¼

è¿™æ ·ï¼Œä½ å°±æ‹¥æœ‰äº†ä¸€ä¸ª **ä¼ä¸šçº§çš„ Celery ä»»åŠ¡è°ƒåº¦ç®¡ç†ç³»ç»Ÿ** ğŸ¯ğŸš€

å¦‚æœä½ åªä½¿ç”¨ **`django-celery-beat`** æ¥ç®¡ç†å®šæ—¶ä»»åŠ¡ï¼Œå¹¶ä¸”ä¸éœ€è¦ä½¿ç”¨ **`django-celery-results`** æ¥å­˜å‚¨ä»»åŠ¡ç»“æœï¼Œä½ å¯ä»¥å°†ä»»åŠ¡ç»“æœç›´æ¥å­˜å‚¨åœ¨ **Redis** æˆ–è‡ªå·±çš„æ•°æ®åº“ä¸­ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ª **å®Œæ•´çš„å¯æ‰©å±•æ–¹æ¡ˆ**ï¼Œå®ç°äº† **å¯¹å„ç§ç±»å‹çš„ Celery ä»»åŠ¡çš„ç®¡ç†**ï¼ŒåŒ…æ‹¬å‘¨æœŸä»»åŠ¡ï¼ˆIntervalï¼‰ã€å®šæ—¶ä»»åŠ¡ï¼ˆCronï¼‰ç­‰ã€‚

## **ğŸ“Œ ä¸»è¦æµç¨‹ï¼š**

1. **ä½¿ç”¨ `django-celery-beat`** æ¥ç®¡ç† Celery å®šæ—¶ä»»åŠ¡ã€‚
2. **ä½¿ç”¨ Redis ä½œä¸º Celery çš„æ¶ˆæ¯é˜Ÿåˆ—**ï¼ˆBrokerï¼‰ï¼Œå¹¶ä½¿ç”¨ä½ è‡ªå·±çš„æ•°æ®åº“æ¥å­˜å‚¨ä»»åŠ¡æ‰§è¡Œçš„ç»“æœã€‚
3. **ä½¿ç”¨ Django Admin æˆ– API åŠ¨æ€ç®¡ç†ä»»åŠ¡**ã€‚

------

## **1ï¸âƒ£ å®‰è£…ä¾èµ–**

å®‰è£…ä»¥ä¸‹å¿…è¦çš„ä¾èµ–ï¼š

```bash
pip install celery redis django-celery-beat djangorestframework
```

------

## **2ï¸âƒ£ é…ç½® `settings.py`**

åœ¨ `settings.py` é…ç½® Celeryã€Redis å’Œ `django-celery-beat`ã€‚

```python
# settings.py

from celery.schedules import crontab

# Celery é…ç½®
CELERY_BROKER_URL = 'redis://localhost:6379/0'  # Redis ä½œä¸ºæ¶ˆæ¯é˜Ÿåˆ—
CELERY_RESULT_BACKEND = 'redis://localhost:6379/0'  # Redis å­˜å‚¨ä»»åŠ¡ç»“æœï¼Œæˆ–ä½¿ç”¨è‡ªå·±çš„æ•°æ®åº“
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_TIMEZONE = 'UTC'

# Celery Beat é…ç½®
INSTALLED_APPS = [
    ...,
    'django_celery_beat',  # ç”¨äºç®¡ç†å‘¨æœŸä»»åŠ¡
]
```

ç„¶åè¿è¡Œæ•°æ®åº“è¿ç§»ï¼š

```bash
python manage.py migrate django_celery_beat
```

------

## **3ï¸âƒ£ é…ç½® Celery**

åœ¨ `your_project/celery.py` æ–‡ä»¶ä¸­é…ç½® Celeryã€‚

```python
import os
from celery import Celery

# è®¾ç½® Django çš„é»˜è®¤è®¾ç½®æ¨¡å—
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'your_project.settings')

app = Celery('your_project')

# ä» settings.py åŠ è½½é…ç½®
app.config_from_object('django.conf:settings', namespace='CELERY')

# è‡ªåŠ¨å‘ç°ä»»åŠ¡
app.autodiscover_tasks()

@app.task(bind=True)
def debug_task(self):
    print(f'Request: {self.request!r}')
```

åœ¨ `your_project/__init__.py` ä¸­æ·»åŠ ä»¥ä¸‹ä»£ç ï¼Œç¡®ä¿ Celery åœ¨å¯åŠ¨æ—¶åŠ è½½ï¼š

```python
from __future__ import absolute_import, unicode_literals

# è®¾ç½®é»˜è®¤ Django è®¾ç½®æ¨¡å—
from .celery import app as celery_app

__all__ = ('celery_app',)
```

------

## **4ï¸âƒ£ åˆ›å»º Celery ä»»åŠ¡**

åœ¨ `your_app/tasks.py` ä¸­åˆ›å»º Celery ä»»åŠ¡ã€‚

```python
from celery import shared_task

@shared_task
def example_task(message):
    print(f'æ‰§è¡Œä»»åŠ¡: {message}')
    return f'ä»»åŠ¡å®Œæˆ: {message}'

@shared_task
def another_task(message):
    print(f'æ‰§è¡Œä»»åŠ¡: {message}')
    return f'å¦ä¸€ä¸ªä»»åŠ¡å®Œæˆ: {message}'
```

------

## **5ï¸âƒ£ åœ¨ Django Admin ä¸­ç®¡ç†ä»»åŠ¡**

`django-celery-beat` æä¾›äº† Django Admin ç•Œé¢æ¥ç®¡ç†å‘¨æœŸä»»åŠ¡ï¼ˆæ¯”å¦‚ï¼Œå®šæ—¶ä»»åŠ¡ã€é—´éš”ä»»åŠ¡ï¼‰ã€‚

1. å¯åŠ¨ **Django æœåŠ¡**ï¼š

```bash
python manage.py runserver
```

1. **è¿›å…¥ Admin åå°**ï¼š`http://127.0.0.1:8000/admin/`ã€‚
2. åˆ›å»ºå‘¨æœŸä»»åŠ¡ï¼šè¿›å…¥ `Periodic Tasks`ï¼Œåˆ›å»º **å®šæ—¶ä»»åŠ¡** æˆ– **é—´éš”ä»»åŠ¡**ã€‚

ä¾‹å¦‚ï¼Œåˆ›å»ºä¸€ä¸ªæ¯ **10 ç§’** æ‰§è¡Œä¸€æ¬¡çš„ `example_task`ã€‚

------

## **6ï¸âƒ£ ä½¿ç”¨ Django REST API ç®¡ç†ä»»åŠ¡**

å¦‚æœä½ å¸Œæœ›é€šè¿‡ API åŠ¨æ€ç®¡ç†ä»»åŠ¡ï¼Œå¯ä»¥ä½¿ç”¨ Django REST Framework åˆ›å»ºä¸€ä¸ª APIã€‚

### 1. **åˆ›å»º API è§†å›¾**

åœ¨ `your_app/views.py` ä¸­ï¼š

```python
from rest_framework.views import APIView
from rest_framework.response import Response
from django_celery_beat.models import PeriodicTask, IntervalSchedule, CrontabSchedule
import json
from your_app.tasks import example_task, another_task

class TaskAPI(APIView):
    """API è§†å›¾ï¼šåŠ¨æ€åˆ›å»ºå’Œç®¡ç† Celery ä»»åŠ¡"""

    def post(self, request):
        data = request.data
        task_name = data.get("task_name", "your_app.tasks.example_task")
        interval = data.get("interval", 10)  # ä»»åŠ¡é—´éš”ï¼Œå•ä½ä¸ºç§’
        message = data.get("message", "é»˜è®¤ä»»åŠ¡")
        schedule_type = data.get("schedule_type", "interval")  # ä»»åŠ¡ç±»å‹ï¼šinterval æˆ– cron
        cron_expression = data.get("cron_expression", "")  # Cron è¡¨è¾¾å¼

        if schedule_type == "interval":
            # åˆ›å»ºæˆ–è·å– IntervalScheduleï¼ˆå‘¨æœŸä»»åŠ¡é—´éš”ï¼‰
            schedule, created = IntervalSchedule.objects.get_or_create(
                every=interval, period=IntervalSchedule.SECONDS
            )
        elif schedule_type == "cron":
            # åˆ›å»º Cron è¡¨è¾¾å¼ä»»åŠ¡
            schedule, created = CrontabSchedule.objects.get_or_create(
                minute=cron_expression.get("minute", "*"),
                hour=cron_expression.get("hour", "*"),
                day_of_week=cron_expression.get("day_of_week", "*"),
                day_of_month=cron_expression.get("day_of_month", "*"),
                month_of_year=cron_expression.get("month_of_year", "*"),
            )

        # åˆ›å»º PeriodicTaskï¼ˆå‘¨æœŸä»»åŠ¡ï¼‰
        task = PeriodicTask.objects.create(
            interval=schedule,
            name=f"ä»»åŠ¡-{message}",
            task=task_name,
            args=json.dumps([message]),  # ä»»åŠ¡å‚æ•°
        )

        return Response({"status": "ä»»åŠ¡å·²åˆ›å»º", "task_id": task.id})
```

### 2. **é…ç½® URL è·¯ç”±**

åœ¨ `your_app/urls.py` ä¸­é…ç½® API è·¯ç”±ï¼š

```python
from django.urls import path
from .views import TaskAPI

urlpatterns = [
    path('api/tasks/', TaskAPI.as_view(), name='task-api'),
]
```

------

## **7ï¸âƒ£ æµ‹è¯•é€šè¿‡ API åˆ›å»ºä»»åŠ¡**

ä½ å¯ä»¥é€šè¿‡ API åŠ¨æ€åˆ›å»ºå‘¨æœŸä»»åŠ¡ï¼š

### 1. **å¯åŠ¨ Django æœåŠ¡**ï¼š

```bash
python manage.py runserver
```

### 2. **é€šè¿‡ `POST` è¯·æ±‚åˆ›å»ºä»»åŠ¡**ï¼š

ä½¿ç”¨ `curl` å‘½ä»¤æˆ– Postman åˆ›å»ºä»»åŠ¡ã€‚

#### ç¤ºä¾‹ï¼šåˆ›å»ºä¸€ä¸ªæ¯ **30 ç§’** æ‰§è¡Œä¸€æ¬¡çš„ä»»åŠ¡ï¼š

```bash
curl -X POST http://127.0.0.1:8000/api/tasks/ \
     -H "Content-Type: application/json" \
     -d '{
         "task_name": "your_app.tasks.example_task",
         "interval": 30,
         "message": "é€šè¿‡ API åˆ›å»ºçš„ä»»åŠ¡",
         "schedule_type": "interval"
     }'
```

#### ç¤ºä¾‹ï¼šåˆ›å»ºä¸€ä¸ªä½¿ç”¨ Cron è¡¨è¾¾å¼çš„ä»»åŠ¡ï¼š

```bash
curl -X POST http://127.0.0.1:8000/api/tasks/ \
     -H "Content-Type: application/json" \
     -d '{
         "task_name": "your_app.tasks.another_task",
         "cron_expression": {"minute": "*/5"},
         "message": "é€šè¿‡ Cron è¡¨è¾¾å¼åˆ›å»ºçš„ä»»åŠ¡",
         "schedule_type": "cron"
     }'
```

------

## **8ï¸âƒ£ æ€»ç»“**

### **å…³é”®åŠŸèƒ½ï¼š**

1. **`django-celery-beat`** ç”¨äºç®¡ç†å‘¨æœŸä»»åŠ¡ï¼ˆå®šæ—¶ä»»åŠ¡å’Œé—´éš”ä»»åŠ¡ï¼‰ï¼Œæ”¯æŒé€šè¿‡ **Admin** å’Œ **API** åŠ¨æ€åˆ›å»ºä»»åŠ¡ã€‚
2. é€šè¿‡ **Redis** ä½œä¸º Celery çš„ **æ¶ˆæ¯é˜Ÿåˆ—**ï¼ˆBrokerï¼‰ï¼Œå¹¶ä½¿ç”¨ä½ çš„ **è‡ªå®šä¹‰æ•°æ®åº“** æ¥æŒä¹…åŒ–å­˜å‚¨ä»»åŠ¡ç»“æœã€‚
3. ä½¿ç”¨ **Django REST Framework** åˆ›å»º APIï¼Œå¯ä»¥åŠ¨æ€ç®¡ç†ä»»åŠ¡ã€‚

### **å¯æ‰©å±•æ€§ï¼š**

- ä½ å¯ä»¥æ‰©å±•ä»»åŠ¡ç±»å‹æ”¯æŒï¼Œå¦‚æ·»åŠ æ›´å¤šçš„ä»»åŠ¡å‚æ•°ï¼Œæˆ–è€…æ”¯æŒå¤æ‚çš„ `Cron` è¡¨è¾¾å¼ã€‚
- API ç«¯ç‚¹æ”¯æŒåŠ¨æ€åˆ›å»ºã€åˆ é™¤ã€ä¿®æ”¹ä»»åŠ¡ï¼Œå› æ­¤éå¸¸çµæ´»ã€‚
- å¯ä»¥æ ¹æ®éœ€æ±‚å°†ä»»åŠ¡ç»“æœå­˜å‚¨åœ¨è‡ªå·±çš„æ•°æ®åº“ä¸­ï¼ˆä¸ä½¿ç”¨ `django-celery-results`ï¼‰ï¼Œä»¥æä¾›è‡ªå®šä¹‰çš„æ•°æ®æŒä¹…åŒ–æ–¹å¼ã€‚

### **é€‚ç”¨åœºæ™¯ï¼š**

- **å‘¨æœŸæ€§ä»»åŠ¡ç®¡ç†**ï¼šéœ€è¦å‘¨æœŸæ€§ä»»åŠ¡çš„è°ƒåº¦ï¼Œæ”¯æŒå®šæ—¶ä»»åŠ¡å’Œé—´éš”ä»»åŠ¡ã€‚
- **è‡ªå®šä¹‰ç»“æœå­˜å‚¨**ï¼šä½¿ç”¨è‡ªå®šä¹‰æ•°æ®åº“æ¥æŒä¹…åŒ–å­˜å‚¨ä»»åŠ¡ç»“æœï¼Œè€Œä¸ä¾èµ– `django-celery-results`ã€‚
- **çµæ´»çš„ä»»åŠ¡ç®¡ç†**ï¼šé€šè¿‡ API æˆ– Admin åŠ¨æ€ç®¡ç†ä»»åŠ¡ã€‚

------

è¿™æ ·ï¼Œä½ å°±å®ç°äº†ä¸€ä¸ªçµæ´»ä¸”å¯æ‰©å±•çš„ **Celery ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ**ï¼Œå¹¶èƒ½é€šè¿‡ **Django Admin æˆ– REST API** è½»æ¾ç®¡ç†ä»»åŠ¡ï¼ğŸš€

ä½ å¸Œæœ›åœ¨ **é¡µé¢ä¸Šç®¡ç† Celery ä»»åŠ¡**ï¼Œä½†ä¸åªæ˜¯åˆ›å»ºå‘¨æœŸä»»åŠ¡ï¼Œè€Œæ˜¯èƒ½å¤Ÿåœ¨é¡µé¢ä¸Šé…ç½®å’Œç®¡ç† **å·²ç¼–å†™çš„ Celery ä»»åŠ¡**ï¼ˆå³ï¼Œå¼€å‘è€…å®šä¹‰çš„ä»»åŠ¡ï¼‰ã€‚

**ğŸ”¹ æ ¸å¿ƒç›®æ ‡ï¼š**

1. **å¼€å‘è€…å®šä¹‰ Celery ä»»åŠ¡**ï¼Œå¹¶èƒ½åœ¨é¡µé¢ä¸­é€‰æ‹©ã€é…ç½®å®ƒä»¬ï¼ˆè€Œä¸æ˜¯ç”¨æˆ·è‡ªå·±å¡«å†™ä»»åŠ¡è·¯å¾„ï¼‰ã€‚
2. **æ”¯æŒå„ç§ä»»åŠ¡ç±»å‹**ï¼šä¸€æ¬¡æ€§ä»»åŠ¡ï¼ˆAd-hoc Taskï¼‰ã€å®šæ—¶ä»»åŠ¡ï¼ˆPeriodic Taskï¼‰ã€‚
3. **ç”¨æˆ·å¯ä»¥åŠ¨æ€é…ç½®ä»»åŠ¡å‚æ•°**ï¼Œå¹¶å­˜å‚¨åˆ°æ•°æ®åº“ã€‚
4. **å¯æ‰©å±•æ€§**ï¼šæœªæ¥å¯ä»¥æ”¯æŒæ›´å¤šä»»åŠ¡ç±»å‹ã€‚

------

## **ğŸ“Œ è§£å†³æ–¹æ¡ˆ**

æˆ‘ä»¬å¯ä»¥ **åœ¨ Django åå°æˆ– API æä¾› Celery ä»»åŠ¡çš„å¯é€‰åˆ—è¡¨**ï¼Œç„¶åï¼š

- **é¡µé¢ä¸Šæ˜¾ç¤ºå¯ç”¨ Celery ä»»åŠ¡åˆ—è¡¨**ï¼ˆä»ä»£ç åŠ¨æ€è·å–ï¼‰ã€‚
- **ç”¨æˆ·é€‰æ‹©ä»»åŠ¡ï¼Œå¹¶è¾“å…¥å‚æ•°ï¼Œæäº¤ååˆ›å»ºä»»åŠ¡**ã€‚
- **æ”¯æŒå®šæ—¶/ä¸€æ¬¡æ€§ä»»åŠ¡ï¼Œå¹¶å­˜å‚¨åˆ°æ•°æ®åº“**ã€‚
- **Celery Worker è¯»å–ä»»åŠ¡å¹¶æ‰§è¡Œ**ã€‚

------

## **1ï¸âƒ£ è·å–æ‰€æœ‰ Celery ä»»åŠ¡**

ä½ å¯ä»¥åŠ¨æ€è·å– **æ‰€æœ‰å®šä¹‰çš„ Celery ä»»åŠ¡**ï¼Œè€Œä¸æ˜¯è®©ç”¨æˆ·æ‰‹åŠ¨è¾“å…¥ä»»åŠ¡åç§°ã€‚

### **ğŸ“Œ æ–¹æ³•ï¼šéå† Celery å·²æ³¨å†Œçš„ä»»åŠ¡**

Celery **ä¼šè‡ªåŠ¨æ³¨å†Œ** `@shared_task` çš„ä»»åŠ¡ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ `app.tasks` è·å–ä»»åŠ¡åˆ—è¡¨ã€‚

```python
# your_app/utils.py
from celery import current_app

def get_all_registered_tasks():
    """ è·å–æ‰€æœ‰å¯ç”¨çš„ Celery ä»»åŠ¡ """
    return list(current_app.tasks.keys())
```

ä½ å¯ä»¥åœ¨ Django API é‡Œè°ƒç”¨è¿™ä¸ªæ–¹æ³•ï¼ŒæŠŠå¯ç”¨ä»»åŠ¡è¿”å›ç»™å‰ç«¯é¡µé¢ã€‚

------

## **2ï¸âƒ£ åˆ›å»º Django API è·å–ä»»åŠ¡åˆ—è¡¨**

åœ¨ `views.py` é‡Œï¼Œæä¾›ä¸€ä¸ª APIï¼Œè¿”å› **æ‰€æœ‰å¯ç”¨ Celery ä»»åŠ¡**ã€‚

```python
# your_app/views.py
from rest_framework.views import APIView
from rest_framework.response import Response
from your_app.utils import get_all_registered_tasks

class TaskListAPI(APIView):
    """ API è§†å›¾ï¼šè·å–æ‰€æœ‰ Celery ä»»åŠ¡ """

    def get(self, request):
        tasks = get_all_registered_tasks()
        return Response({"tasks": tasks})
```

### **ğŸ“Œ é…ç½® Django è·¯ç”±**

åœ¨ `urls.py` é‡Œæ·»åŠ  API å…¥å£ï¼š

```python
from django.urls import path
from .views import TaskListAPI

urlpatterns = [
    path('api/tasks/', TaskListAPI.as_view(), name='task-list'),
]
```

#### **ğŸ“Œ æµ‹è¯• API**

å¯åŠ¨ Django æœåŠ¡å™¨ï¼š

```bash
python manage.py runserver
```

ç„¶åè®¿é—®ï¼š

```
http://127.0.0.1:8000/api/tasks/
```

è¿”å› JSONï¼š

```json
{
    "tasks": [
        "your_app.tasks.example_task",
        "your_app.tasks.another_task",
        "celery.backend_cleanup"
    ]
}
```

------

## **3ï¸âƒ£ åœ¨é¡µé¢é€‰æ‹©ä»»åŠ¡å¹¶é…ç½®å‚æ•°**

å‰ç«¯é¡µé¢å¯ä»¥è°ƒç”¨ `http://127.0.0.1:8000/api/tasks/`ï¼Œç„¶åè®©ç”¨æˆ·é€‰æ‹©ä»»åŠ¡ï¼Œå¹¶è¾“å…¥å‚æ•°ã€‚

**ç¤ºä¾‹å‰ç«¯è¡¨å•ï¼š**

- é€‰æ‹©ä»»åŠ¡ï¼š`<select>` ä¸‹æ‹‰æ¡†ï¼Œé€‰æ‹© `example_task`
- è¾“å…¥å‚æ•°ï¼šä¸€ä¸ª `<input>` è®©ç”¨æˆ·è¾“å…¥å‚æ•°
- é€‰æ‹©æ‰§è¡Œæ–¹å¼ï¼š
  - **ç«‹å³æ‰§è¡Œ**ï¼ˆAd-hoc Taskï¼‰
  - **å®šæ—¶æ‰§è¡Œ**ï¼ˆScheduled Taskï¼‰
  - **å‘¨æœŸæ‰§è¡Œ**ï¼ˆPeriodic Taskï¼‰

------

## **4ï¸âƒ£ ç”¨æˆ·æäº¤ä»»åŠ¡ï¼Œåç«¯åˆ›å»ºä»»åŠ¡**

å½“ç”¨æˆ·æäº¤ä»»åŠ¡åï¼ŒDjango API éœ€è¦ **æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„ä»»åŠ¡å’Œå‚æ•°ï¼Œåˆ›å»º Celery ä»»åŠ¡**ã€‚

åœ¨ `views.py` æ·»åŠ  API **åˆ›å»ºä»»åŠ¡**ï¼š

```python
import json
from django_celery_beat.models import PeriodicTask, IntervalSchedule
from rest_framework.views import APIView
from rest_framework.response import Response
from celery import current_app
from datetime import datetime, timedelta

class TaskCreateAPI(APIView):
    """ API è§†å›¾ï¼šç”¨æˆ·åŠ¨æ€åˆ›å»º Celery ä»»åŠ¡ """

    def post(self, request):
        """
        è¯·æ±‚æ ¼å¼ï¼š
        {
            "task_name": "your_app.tasks.example_task",
            "params": ["Hello, Celery!"],  # ä»»åŠ¡å‚æ•°
            "execution_type": "adhoc" | "scheduled" | "periodic",
            "run_at": "2025-04-01 10:00:00",  # ä»…å¯¹ scheduled ä»»åŠ¡æœ‰æ•ˆ
            "interval_seconds": 60  # ä»…å¯¹ periodic ä»»åŠ¡æœ‰æ•ˆ
        }
        """
        data = request.data
        task_name = data.get("task_name")
        params = data.get("params", [])
        execution_type = data.get("execution_type")

        if task_name not in current_app.tasks:
            return Response({"error": "ä»»åŠ¡ä¸å­˜åœ¨"}, status=400)

        # **1ï¸âƒ£ ç«‹å³æ‰§è¡Œçš„ä»»åŠ¡**
        if execution_type == "adhoc":
            result = current_app.send_task(task_name, args=params)
            return Response({"status": "ä»»åŠ¡å·²æäº¤", "task_id": result.id})

        # **2ï¸âƒ£ å®šæ—¶æ‰§è¡Œçš„ä»»åŠ¡**
        elif execution_type == "scheduled":
            run_at = datetime.strptime(data.get("run_at"), "%Y-%m-%d %H:%M:%S")
            result = current_app.send_task(task_name, args=params, eta=run_at)
            return Response({"status": "ä»»åŠ¡å·²å®šæ—¶", "task_id": result.id})

        # **3ï¸âƒ£ å‘¨æœŸæ‰§è¡Œçš„ä»»åŠ¡**
        elif execution_type == "periodic":
            interval, _ = IntervalSchedule.objects.get_or_create(
                every=data.get("interval_seconds", 60),
                period=IntervalSchedule.SECONDS
            )
            task = PeriodicTask.objects.create(
                interval=interval,
                name=f"{task_name}-{datetime.now()}",
                task=task_name,
                args=json.dumps(params),
            )
            return Response({"status": "å‘¨æœŸä»»åŠ¡å·²åˆ›å»º", "task_id": task.id})

        return Response({"error": "æœªçŸ¥çš„æ‰§è¡Œç±»å‹"}, status=400)
```

------

## **5ï¸âƒ£ é…ç½® Django è·¯ç”±**

åœ¨ `urls.py` é‡Œæ·»åŠ åˆ›å»ºä»»åŠ¡çš„ API å…¥å£ï¼š

```python
from django.urls import path
from .views import TaskCreateAPI

urlpatterns = [
    path('api/create-task/', TaskCreateAPI.as_view(), name='create-task'),
]
```

------

## **6ï¸âƒ£ å‰ç«¯è°ƒç”¨ API æäº¤ä»»åŠ¡**

ç”¨æˆ·é€‰æ‹©ä»»åŠ¡åï¼Œå‰ç«¯æäº¤ï¼š

```bash
curl -X POST http://127.0.0.1:8000/api/create-task/ \
     -H "Content-Type: application/json" \
     -d '{
         "task_name": "your_app.tasks.example_task",
         "params": ["Hello, Celery!"],
         "execution_type": "adhoc"
     }'
```

è¿”å›ï¼š

```json
{
    "status": "ä»»åŠ¡å·²æäº¤",
    "task_id": "4c5e7a32-ef4e-4c4e-9b3f-7e32d813e676"
}
```

------

## **ğŸ¯ æ€»ç»“**

1. **è·å–æ‰€æœ‰ Celery ä»»åŠ¡**ï¼ŒåŠ¨æ€æ˜¾ç¤ºç»™ç”¨æˆ·é€‰æ‹© âœ…
2. **ç”¨æˆ·è¾“å…¥å‚æ•°ã€é€‰æ‹©æ‰§è¡Œæ–¹å¼**ï¼ˆç«‹å³æ‰§è¡Œ/å®šæ—¶æ‰§è¡Œ/å‘¨æœŸæ‰§è¡Œï¼‰âœ…
3. **Django API å¤„ç†ä»»åŠ¡**ï¼š
   - **ç«‹å³æ‰§è¡Œ**ï¼ˆAd-hoc Taskï¼‰ğŸš€
   - **å®šæ—¶æ‰§è¡Œ**ï¼ˆScheduled Taskï¼‰â°
   - **å‘¨æœŸä»»åŠ¡**ï¼ˆPeriodic Taskï¼Œå­˜å…¥ `django-celery-beat`ï¼‰ğŸ“…
4. **Celery Worker æ‰§è¡Œä»»åŠ¡** ğŸ¯

------

ğŸ’¡ **è¿™æ ·ï¼Œä½ çš„ Celery ä»»åŠ¡ç®¡ç†ç³»ç»Ÿå˜å¾—æ›´çµæ´»ï¼Œå¯ä»¥åœ¨é¡µé¢ä¸Šè‡ªç”±é…ç½®ä»»åŠ¡ï¼** ğŸš€

åœ¨ Django ä¸­å®ç°ä¸€ä¸ª Celery ä»»åŠ¡ç®¡ç†é¡µé¢ï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹åŠŸèƒ½ï¼š

1. **æŸ¥çœ‹ä»»åŠ¡åˆ—è¡¨**ï¼ˆåŒ…æ‹¬è¿è¡Œä¸­çš„ã€ç­‰å¾…ä¸­çš„ã€å¤±è´¥çš„ä»»åŠ¡ï¼‰ã€‚
2. **è·å–ä»»åŠ¡è¯¦æƒ…**ï¼ˆä»»åŠ¡å‚æ•°ã€çŠ¶æ€ã€ç»“æœç­‰ï¼‰ã€‚
3. **å–æ¶ˆ/ç»ˆæ­¢ä»»åŠ¡**ã€‚
4. **é‡æ–°è¿è¡Œä»»åŠ¡**ï¼ˆå¤±è´¥çš„ä»»åŠ¡æˆ–æŒ‡å®šä»»åŠ¡ï¼‰ã€‚
5. **æ¸…é™¤å·²å®Œæˆæˆ–å¤±è´¥çš„ä»»åŠ¡**ã€‚

## **åç«¯å®ç°é€»è¾‘**

ä½¿ç”¨ **Celery æä¾›çš„ API** è·å–ä»»åŠ¡ä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨ Django çš„ **DRFï¼ˆDjango REST Frameworkï¼‰** è®¾è®¡ API ä¾›å‰ç«¯è°ƒç”¨ã€‚

------

## **1. Celery é…ç½®**

ç¡®ä¿ Celery å·²åœ¨ Django é¡¹ç›®ä¸­æ­£ç¡®é…ç½®ï¼Œå¹¶ä¸” Celery Beat ç”¨äºå‘¨æœŸæ€§ä»»åŠ¡ç®¡ç†ï¼š

```python
# settings.py
CELERY_BROKER_URL = "redis://localhost:6379/0"  # æˆ–å…¶ä»–æ¶ˆæ¯é˜Ÿåˆ—
CELERY_RESULT_BACKEND = "redis://localhost:6379/0"
```

------

## **2. Celery ä»»åŠ¡ç®¡ç† API**

åˆ›å»º Django API è§†å›¾ï¼Œç®¡ç† Celery ä»»åŠ¡ã€‚

```python
from celery.result import AsyncResult
from django_celery_results.models import TaskResult
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from myapp.tasks import sample_task  # ä½ çš„ä»»åŠ¡

# è·å–æ‰€æœ‰ä»»åŠ¡
class TaskListView(APIView):
    def get(self, request):
        tasks = TaskResult.objects.all().values("task_id", "status", "date_done", "result")
        return Response({"tasks": list(tasks)}, status=status.HTTP_200_OK)


# è·å–å•ä¸ªä»»åŠ¡è¯¦æƒ…
class TaskDetailView(APIView):
    def get(self, request, task_id):
        result = AsyncResult(task_id)
        return Response({
            "task_id": task_id,
            "status": result.status,
            "result": result.result if result.ready() else None
        }, status=status.HTTP_200_OK)


# ç»ˆæ­¢ä»»åŠ¡
class TaskRevokeView(APIView):
    def post(self, request, task_id):
        result = AsyncResult(task_id)
        result.revoke(terminate=True)
        return Response({"message": f"Task {task_id} revoked"}, status=status.HTTP_200_OK)


# é‡æ–°æ‰§è¡Œä»»åŠ¡
class TaskRetryView(APIView):
    def post(self, request, task_id):
        result = AsyncResult(task_id)
        if result.failed():
            new_task = sample_task.apply_async(args=result.args, kwargs=result.kwargs)
            return Response({"message": "Task retried", "new_task_id": new_task.id}, status=status.HTTP_200_OK)
        return Response({"error": "Task is not failed"}, status=status.HTTP_400_BAD_REQUEST)


# æ¸…é™¤ä»»åŠ¡
class TaskPurgeView(APIView):
    def delete(self, request):
        TaskResult.objects.all().delete()
        return Response({"message": "All tasks cleared"}, status=status.HTTP_200_OK)
```

------

## **3. æ³¨å†Œ API è·¯ç”±**

åœ¨ `urls.py` ä¸­æ·»åŠ  API è·¯ç”±ï¼š

```python
from django.urls import path
from .views import TaskListView, TaskDetailView, TaskRevokeView, TaskRetryView, TaskPurgeView

urlpatterns = [
    path("tasks/", TaskListView.as_view(), name="task-list"),
    path("tasks/<str:task_id>/", TaskDetailView.as_view(), name="task-detail"),
    path("tasks/<str:task_id>/revoke/", TaskRevokeView.as_view(), name="task-revoke"),
    path("tasks/<str:task_id>/retry/", TaskRetryView.as_view(), name="task-retry"),
    path("tasks/purge/", TaskPurgeView.as_view(), name="task-purge"),
]
```

------

## **4. åˆ›å»º Celery ä»»åŠ¡**

ç¤ºä¾‹ Celery ä»»åŠ¡ï¼š

```python
from celery import shared_task
import time

@shared_task(bind=True)
def sample_task(self, x, y):
    time.sleep(5)  # æ¨¡æ‹Ÿé•¿æ—¶é—´ä»»åŠ¡
    return x + y
```

------

## **5. æµ‹è¯• API**

å¯åŠ¨ Celery Workerï¼š

```sh
celery -A myproject worker --loglevel=info
```

æµ‹è¯•åˆ›å»ºä»»åŠ¡ï¼š

```sh
curl -X POST http://localhost:8000/tasks/ -H "Content-Type: application/json"
```

æµ‹è¯•æŸ¥çœ‹ä»»åŠ¡åˆ—è¡¨ï¼š

```sh
curl http://localhost:8000/tasks/
```

æµ‹è¯•ç»ˆæ­¢ä»»åŠ¡ï¼š

```sh
curl -X POST http://localhost:8000/tasks/<task_id>/revoke/
```

------

## **æ€»ç»“**

è¿™æ ·ï¼Œæˆ‘ä»¬å°±å®ç°äº†ä¸€ä¸ª Celery ä»»åŠ¡ç®¡ç†ç³»ç»Ÿï¼Œæ”¯æŒï¼š

- ä»»åŠ¡æŸ¥è¯¢ï¼ˆè¿›è¡Œä¸­ã€å·²å®Œæˆã€å¤±è´¥ï¼‰ã€‚
- ä»»åŠ¡è¯¦æƒ…æŸ¥çœ‹ã€‚
- ä»»åŠ¡ç»ˆæ­¢ã€‚
- ä»»åŠ¡é‡è¯•ã€‚
- ä»»åŠ¡æ¸…ç†ã€‚

å‰ç«¯å¯ä»¥è°ƒç”¨è¿™äº› APIï¼Œå®ç°ä»»åŠ¡ç®¡ç†ç•Œé¢ã€‚

å¦‚æœéœ€è¦ **ç®¡ç† Celery ä»»åŠ¡çš„é˜Ÿåˆ—ã€æ’é˜Ÿã€åˆ†å‘ç­‰**ï¼Œå¯ä»¥ä½¿ç”¨ **Celery çš„é˜Ÿåˆ—ã€ä¼˜å…ˆçº§ã€è·¯ç”±ç­‰æœºåˆ¶**ï¼Œå¹¶æ‰©å±• API ä»¥æä¾›é˜Ÿåˆ—ç®¡ç†åŠŸèƒ½ã€‚ä»¥ä¸‹æ˜¯è¯¦ç»†çš„å®ç°æ–¹å¼ï¼š

------

## **1. ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†**

Celery å…è®¸åˆ›å»ºå¤šä¸ªé˜Ÿåˆ—ï¼Œå¹¶å°†ä¸åŒä»»åŠ¡åˆ†é…åˆ°ä¸åŒé˜Ÿåˆ—ä¸­ã€‚

### **ï¼ˆ1ï¼‰å®šä¹‰ä¸åŒçš„é˜Ÿåˆ—**

åœ¨ `settings.py` é…ç½®å¤šä¸ªé˜Ÿåˆ—ï¼š

```python
CELERY_BROKER_URL = "redis://localhost:6379/0"
CELERY_RESULT_BACKEND = "redis://localhost:6379/0"

# å®šä¹‰é˜Ÿåˆ—
CELERY_TASK_QUEUES = {
    "default": {"exchange": "default", "routing_key": "default"},
    "high_priority": {"exchange": "high", "routing_key": "high"},
    "low_priority": {"exchange": "low", "routing_key": "low"},
}
```

### **ï¼ˆ2ï¼‰æŒ‡å®šä»»åŠ¡ä½¿ç”¨ç‰¹å®šé˜Ÿåˆ—**

åœ¨ `tasks.py` é‡Œï¼Œè®¾ç½®ä»»åŠ¡é»˜è®¤é˜Ÿåˆ—ï¼š

```python
from celery import shared_task

@shared_task(queue="high_priority")
def high_priority_task(x, y):
    return x + y

@shared_task(queue="low_priority")
def low_priority_task(x, y):
    return x - y
```

### **ï¼ˆ3ï¼‰å¯åŠ¨ä¸åŒçš„ Celery Worker ç›‘å¬ä¸åŒçš„é˜Ÿåˆ—**

```sh
# å¯åŠ¨é»˜è®¤é˜Ÿåˆ—çš„ Worker
celery -A myproject worker --loglevel=info -Q default

# å¯åŠ¨é«˜ä¼˜å…ˆçº§é˜Ÿåˆ—çš„ Worker
celery -A myproject worker --loglevel=info -Q high_priority

# å¯åŠ¨ä½ä¼˜å…ˆçº§é˜Ÿåˆ—çš„ Worker
celery -A myproject worker --loglevel=info -Q low_priority
```

------

## **2. ä»»åŠ¡è·¯ç”±**

ä½ å¯ä»¥é€šè¿‡ Celery è·¯ç”±è§„åˆ™ **è‡ªåŠ¨åˆ†å‘ä»»åŠ¡åˆ°æŒ‡å®šé˜Ÿåˆ—**ã€‚

### **ï¼ˆ1ï¼‰åœ¨ `celery.py` ä¸­é…ç½®ä»»åŠ¡è·¯ç”±**

```python
CELERY_TASK_ROUTES = {
    "myapp.tasks.high_priority_task": {"queue": "high_priority"},
    "myapp.tasks.low_priority_task": {"queue": "low_priority"},
}
```

------

## **3. API æ‰©å±•ï¼šåŠ¨æ€åˆ†é…ä»»åŠ¡åˆ°ä¸åŒé˜Ÿåˆ—**

åœ¨ Django API é‡Œï¼Œæ·»åŠ ç®¡ç†é˜Ÿåˆ—çš„æ¥å£ã€‚

### **ï¼ˆ1ï¼‰åŠ¨æ€åˆ›å»ºä»»åŠ¡åˆ°ä¸åŒé˜Ÿåˆ—**

```python
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from myapp.tasks import high_priority_task, low_priority_task
from celery import current_app

# æäº¤ä»»åŠ¡åˆ°ä¸åŒçš„é˜Ÿåˆ—
class TaskCreateView(APIView):
    def post(self, request):
        queue = request.data.get("queue", "default")
        x = request.data.get("x", 1)
        y = request.data.get("y", 2)

        if queue == "high_priority":
            task = high_priority_task.apply_async(args=[x, y], queue="high_priority")
        elif queue == "low_priority":
            task = low_priority_task.apply_async(args=[x, y], queue="low_priority")
        else:
            return Response({"error": "Invalid queue"}, status=status.HTTP_400_BAD_REQUEST)

        return Response({"task_id": task.id, "queue": queue}, status=status.HTTP_201_CREATED)
```

### **ï¼ˆ2ï¼‰è·å–æ‰€æœ‰é˜Ÿåˆ—ä¿¡æ¯**

```python
class QueueListView(APIView):
    def get(self, request):
        inspector = current_app.control.inspect()
        active_queues = inspector.active_queues()
        return Response({"queues": active_queues}, status=status.HTTP_200_OK)
```

### **ï¼ˆ3ï¼‰æ¸…ç©ºç‰¹å®šé˜Ÿåˆ—**

```python
class QueuePurgeView(APIView):
    def delete(self, request, queue_name):
        inspector = current_app.control.inspect()
        inspector.purge(queue=queue_name)
        return Response({"message": f"Queue {queue_name} purged"}, status=status.HTTP_200_OK)
```

------

## **4. ä»»åŠ¡ä¼˜å…ˆçº§**

Celery æ”¯æŒä»»åŠ¡çš„ä¼˜å…ˆçº§ï¼ˆä½†ä»…é€‚ç”¨äº RabbitMQï¼‰ã€‚

```python
@shared_task(queue="default")
def priority_task(x, y, priority=5):
    return x + y
```

å‘é€ä»»åŠ¡æ—¶è®¾ç½®ä¼˜å…ˆçº§ï¼š

```python
priority_task.apply_async(args=[1, 2], queue="default", priority=0)  # æœ€é«˜ä¼˜å…ˆçº§
priority_task.apply_async(args=[3, 4], queue="default", priority=9)  # æœ€ä½ä¼˜å…ˆçº§
```

------

## **5. ä»»åŠ¡è°ƒåº¦**

Celery Beat å¯ä»¥å®šæ—¶æ‰§è¡Œä»»åŠ¡ï¼š

```python
@shared_task(queue="default")
def scheduled_task():
    print("This task runs every minute!")
```

åœ¨ `celery.py` é…ç½® Celery Beatï¼š

```python
CELERY_BEAT_SCHEDULE = {
    "run_scheduled_task": {
        "task": "myapp.tasks.scheduled_task",
        "schedule": crontab(minute="*/1"),
    },
}
```

å¯åŠ¨ Celery Beatï¼š

```sh
celery -A myproject beat --loglevel=info
```

------

## **6. ä»»åŠ¡åˆ†å‘ç®¡ç†**

å¯ä»¥åŠ¨æ€ç®¡ç†ä»»åŠ¡å¹¶æ§åˆ¶ Workerï¼š

```python
from celery import current_app

class WorkerControlView(APIView):
    def post(self, request, action):
        inspector = current_app.control.inspect()

        if action == "pause":
            inspector.suspend()
            return Response({"message": "Workers paused"}, status=status.HTTP_200_OK)
        elif action == "resume":
            inspector.resume()
            return Response({"message": "Workers resumed"}, status=status.HTTP_200_OK)
        elif action == "terminate":
            inspector.shutdown()
            return Response({"message": "Workers terminated"}, status=status.HTTP_200_OK)
        else:
            return Response({"error": "Invalid action"}, status=status.HTTP_400_BAD_REQUEST)
```

å‰ç«¯å¯ä»¥è°ƒç”¨ï¼š

```sh
curl -X POST http://localhost:8000/workers/pause/  # æš‚åœ Worker
curl -X POST http://localhost:8000/workers/resume/  # æ¢å¤ Worker
curl -X POST http://localhost:8000/workers/terminate/  # ç»ˆæ­¢ Worker
```

------

## **æ€»ç»“**

âœ… **ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†**

- å¯ä»¥åŠ¨æ€åˆ†é…ä»»åŠ¡åˆ°ä¸åŒé˜Ÿåˆ—ã€‚
- æ”¯æŒæŸ¥çœ‹æ‰€æœ‰é˜Ÿåˆ—çŠ¶æ€ã€‚
- å…è®¸æ¸…ç©ºæŸä¸ªé˜Ÿåˆ—çš„ä»»åŠ¡ã€‚

âœ… **ä»»åŠ¡ä¼˜å…ˆçº§**

- RabbitMQ æ”¯æŒä»»åŠ¡ä¼˜å…ˆçº§é˜Ÿåˆ—ã€‚

âœ… **ä»»åŠ¡è°ƒåº¦**

- Celery Beat å¯ç”¨äºå®šæ—¶ä»»åŠ¡ã€‚

âœ… **Worker ç®¡ç†**

- å¯ä»¥æš‚åœã€æ¢å¤æˆ–ç»ˆæ­¢ Worker è¿›ç¨‹ã€‚

è¿™æ ·ï¼Œæ•´ä¸ª Celery ä»»åŠ¡ç®¡ç†ç³»ç»Ÿå°±å…·å¤‡äº† **ä»»åŠ¡ç›‘æ§ã€è°ƒåº¦ã€åˆ†å‘ã€é˜Ÿåˆ—ç®¡ç†ã€ä»»åŠ¡ç»ˆæ­¢ã€Worker ç»´æŠ¤** ç­‰å®Œæ•´åŠŸèƒ½ï¼ ğŸš€

åœ¨ Celery ä»»åŠ¡é˜Ÿåˆ—ä¸­ï¼Œé»˜è®¤æƒ…å†µä¸‹ä»»åŠ¡æ˜¯æŒ‰ **FIFOï¼ˆå…ˆè¿›å…ˆå‡ºï¼‰** æ–¹å¼æ‰§è¡Œçš„ï¼Œ**Redis** ä½œä¸ºæ¶ˆæ¯é˜Ÿåˆ—ï¼ˆBrokerï¼‰æ—¶ï¼Œä»»åŠ¡æ˜¯æŒ‰ç…§é˜Ÿåˆ—é¡ºåºå­˜å‚¨çš„ã€‚ä½† Celery æœ¬èº«**ä¸æ”¯æŒç›´æ¥è°ƒæ•´ä»»åŠ¡çš„é˜Ÿåˆ—é¡ºåº**ï¼Œè¦å®ç° **"æ›´æ”¹ä»»åŠ¡çš„æ’é˜Ÿä½ç½®"**ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‡ ç§æ–¹æ¡ˆï¼š

------

## **æ–¹æ¡ˆ 1ï¼šé‡æ–°æäº¤ä»»åŠ¡ï¼ˆæ¨èï¼‰**

### **æ€è·¯**

1. **æ‰¾åˆ°ç›®æ ‡ä»»åŠ¡**ï¼ˆå³éœ€è¦è°ƒæ•´é¡ºåºçš„ä»»åŠ¡ï¼‰ã€‚
2. **å–æ¶ˆä»»åŠ¡ï¼ˆrevokeï¼‰**ï¼Œä½†ä¸ç»ˆæ­¢æ­£åœ¨æ‰§è¡Œçš„ Worker è¿›ç¨‹ã€‚
3. **é‡æ–°æäº¤ä»»åŠ¡**ï¼Œè®©å®ƒæ’åˆ°é˜Ÿåˆ—æœ€å‰é¢ã€‚

### **å®ç°**

```python
from celery.result import AsyncResult
from celery import current_app
from django_celery_results.models import TaskResult
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from myapp.tasks import sample_task  # éœ€è¦é‡æ–°æäº¤çš„ä»»åŠ¡

class TaskReorderView(APIView):
    def post(self, request):
        task_id = request.data.get("task_id")

        # è·å–ä»»åŠ¡çŠ¶æ€
        result = AsyncResult(task_id)

        if result.state not in ["PENDING", "RECEIVED"]:  # åªå…è®¸è°ƒæ•´æœªæ‰§è¡Œçš„ä»»åŠ¡
            return Response({"error": "Task is already running or completed"}, status=status.HTTP_400_BAD_REQUEST)

        # è·å–åŸä»»åŠ¡å‚æ•°ï¼ˆå¦‚æœä»»åŠ¡å­˜å‚¨äº†å‚æ•°ï¼‰
        original_task = TaskResult.objects.filter(task_id=task_id).first()
        if not original_task:
            return Response({"error": "Task not found"}, status=status.HTTP_404_NOT_FOUND)

        # å–æ¶ˆåŸä»»åŠ¡
        result.revoke(terminate=False)

        # é‡æ–°æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—æœ€å‰é¢
        new_task = sample_task.apply_async(args=original_task.args, kwargs=original_task.kwargs, queue=original_task.task_queue, priority=0)

        return Response({"message": "Task reordered", "new_task_id": new_task.id}, status=status.HTTP_200_OK)
```

### **è¯´æ˜**

- `revoke(terminate=False)` åªå–æ¶ˆä»»åŠ¡ï¼Œä½†ä¸ä¼šå½±å“ Worker è¿›ç¨‹ã€‚
- `apply_async(..., priority=0)` é‡æ–°æäº¤ä»»åŠ¡ï¼Œå¹¶è®¾å®šä¼˜å…ˆçº§ä¸ºæœ€é«˜ï¼ˆRabbitMQ æ”¯æŒï¼‰ã€‚
- é€‚ç”¨äº Redis/RabbitMQï¼Œä½† **ä»»åŠ¡ ID ä¼šå˜åŒ–**ï¼Œéœ€è¦é€šçŸ¥ç”¨æˆ·æ–°çš„ä»»åŠ¡ IDã€‚

------

## **æ–¹æ¡ˆ 2ï¼šä½¿ç”¨è‡ªå®šä¹‰ä»»åŠ¡é˜Ÿåˆ—**

### **æ€è·¯**

1. ç»´æŠ¤ä¸€ä¸ª **ä»»åŠ¡åˆ—è¡¨**ï¼ˆæ¯”å¦‚å­˜å‚¨åœ¨ **Redis** æˆ– **æ•°æ®åº“** ä¸­ï¼‰ã€‚
2. æäº¤ä»»åŠ¡æ—¶ï¼Œä¸ç›´æ¥æ”¾å…¥ Celeryï¼Œè€Œæ˜¯å…ˆå…¥è‡ªå®šä¹‰é˜Ÿåˆ—ã€‚
3. **ç”¨æˆ·å¯è°ƒæ•´é˜Ÿåˆ—é¡ºåº**ï¼Œç„¶åå†æ‰‹åŠ¨è§¦å‘ Celery æ‰§è¡Œã€‚

### **å®ç°**

ä½¿ç”¨ **Redis** å­˜å‚¨ä»»åŠ¡é˜Ÿåˆ—ï¼š

```python
import redis
import json
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from myapp.tasks import sample_task

redis_client = redis.StrictRedis(host="localhost", port=6379, db=1)

TASK_QUEUE_KEY = "custom_task_queue"

class TaskQueueView(APIView):
    """ æäº¤ä»»åŠ¡åˆ° Redis é˜Ÿåˆ— """
    def post(self, request):
        task_data = {
            "x": request.data.get("x", 1),
            "y": request.data.get("y", 2),
            "priority": request.data.get("priority", 5)
        }
        redis_client.rpush(TASK_QUEUE_KEY, json.dumps(task_data))
        return Response({"message": "Task added to queue"}, status=status.HTTP_201_CREATED)

class TaskReorderView(APIView):
    """ è°ƒæ•´ä»»åŠ¡é¡ºåº """
    def post(self, request):
        task_index = request.data.get("index")  # éœ€è¦è°ƒæ•´çš„ä»»åŠ¡ä½ç½®
        new_index = request.data.get("new_index")  # ç›®æ ‡ä½ç½®

        queue = redis_client.lrange(TASK_QUEUE_KEY, 0, -1)
        if task_index >= len(queue) or new_index >= len(queue):
            return Response({"error": "Invalid index"}, status=status.HTTP_400_BAD_REQUEST)

        # äº¤æ¢ä»»åŠ¡é¡ºåº
        task = queue.pop(task_index)
        queue.insert(new_index, task)

        # æ›´æ–° Redis é˜Ÿåˆ—
        redis_client.delete(TASK_QUEUE_KEY)
        for item in queue:
            redis_client.rpush(TASK_QUEUE_KEY, item)

        return Response({"message": "Task order updated"}, status=status.HTTP_200_OK)

class TaskWorkerView(APIView):
    """ Worker ä» Redis é˜Ÿåˆ—æ‹‰å–ä»»åŠ¡å¹¶æäº¤åˆ° Celery """
    def post(self, request):
        task_data = redis_client.lpop(TASK_QUEUE_KEY)
        if not task_data:
            return Response({"error": "No tasks in queue"}, status=status.HTTP_400_BAD_REQUEST)

        task = json.loads(task_data)
        new_task = sample_task.apply_async(args=[task["x"], task["y"]], priority=task["priority"])

        return Response({"message": "Task submitted", "task_id": new_task.id}, status=status.HTTP_200_OK)
```

### **æµç¨‹**

1. `TaskQueueView`: ç”¨æˆ·æäº¤ä»»åŠ¡ï¼Œä»»åŠ¡å­˜å…¥ Redis é˜Ÿåˆ—ã€‚
2. `TaskReorderView`: å…è®¸ç”¨æˆ·è°ƒæ•´ä»»åŠ¡åœ¨ Redis é˜Ÿåˆ—ä¸­çš„é¡ºåºã€‚
3. `TaskWorkerView`: ç”±åå°è¿›ç¨‹**ä¸»åŠ¨æ‹‰å–ä»»åŠ¡**å¹¶æäº¤ç»™ Celeryã€‚

### **é€‚ç”¨åœºæ™¯**

- é€‚ç”¨äº Redis ä½œä¸º Brokerï¼Œä¸”ä»»åŠ¡**éœ€è¦åŠ¨æ€è°ƒæ•´**æ‰§è¡Œé¡ºåºçš„æƒ…å†µã€‚
- é€‚ç”¨äº**ä»»åŠ¡å¿…é¡»ä¸¥æ ¼æŒ‰ç…§è°ƒæ•´åé¡ºåºæ‰§è¡Œ**çš„åœºæ™¯ã€‚

------

## **æ–¹æ¡ˆ 3ï¼šä»»åŠ¡ä¼˜å…ˆçº§è°ƒæ•´ï¼ˆé€‚ç”¨äº RabbitMQï¼‰**

**RabbitMQ** æ”¯æŒ**ä»»åŠ¡ä¼˜å…ˆçº§é˜Ÿåˆ—**ï¼Œå¯è®©é«˜ä¼˜å…ˆçº§ä»»åŠ¡å…ˆæ‰§è¡Œã€‚

### **æ­¥éª¤**

1. **è®¾ç½®é˜Ÿåˆ—æ”¯æŒä¼˜å…ˆçº§**ï¼ˆ`x-max-priority`ï¼‰ã€‚
2. **ä»»åŠ¡é‡æ–°æäº¤æ—¶æå‡ä¼˜å…ˆçº§**ã€‚

### **Celery é…ç½®**

```python
CELERY_TASK_QUEUES = {
    "default": {
        "exchange": "default",
        "routing_key": "default",
        "queue_arguments": {"x-max-priority": 10},  # æœ€é«˜ 10 çº§
    }
}
```

### **ä»»åŠ¡é‡æ–°æäº¤æ—¶è°ƒæ•´ä¼˜å…ˆçº§**

```python
from myapp.tasks import sample_task
from rest_framework.views import APIView
from rest_framework.response import Response

class TaskPriorityView(APIView):
    def post(self, request):
        task_id = request.data.get("task_id")
        new_priority = request.data.get("priority", 5)

        result = AsyncResult(task_id)
        if result.state not in ["PENDING", "RECEIVED"]:
            return Response({"error": "Task is already running or completed"}, status=400)

        # å–æ¶ˆåŸä»»åŠ¡
        result.revoke(terminate=False)

        # é‡æ–°æäº¤ä»»åŠ¡ï¼Œæå‡ä¼˜å…ˆçº§
        new_task = sample_task.apply_async(args=result.args, kwargs=result.kwargs, priority=new_priority)

        return Response({"message": "Task priority updated", "new_task_id": new_task.id}, status=200)
```

### **é€‚ç”¨åœºæ™¯**

- **é€‚ç”¨äº RabbitMQ**ï¼Œä½† Redis ä¸æ”¯æŒ `priority` å‚æ•°ã€‚

------

## **æ€»ç»“**

| æ–¹æ¡ˆ                                   | é€‚ç”¨åœºæ™¯                      | ä¼˜ç‚¹                          | ç¼ºç‚¹                 |
| -------------------------------------- | ----------------------------- | ----------------------------- | -------------------- |
| **æ–¹æ¡ˆ 1ï¼šé‡æ–°æäº¤ä»»åŠ¡ï¼ˆæ¨èï¼‰**       | é€‚ç”¨äº **å¤§å¤šæ•° Celery ç¯å¢ƒ** | å®ç°ç®€å•ï¼Œé€šç”¨æ€§å¼º            | ä»»åŠ¡ ID ä¼šå˜åŒ–       |
| **æ–¹æ¡ˆ 2ï¼šè‡ªå®šä¹‰é˜Ÿåˆ—ç®¡ç†ï¼ˆRedisï¼‰**    | ä»»åŠ¡éœ€è¦**ä¸¥æ ¼æŒ‰ç…§é¡ºåºè°ƒæ•´**  | ä»»åŠ¡é¡ºåºå¯éšæ„è°ƒæ•´            | éœ€è¦é¢å¤– Worker å¤„ç† |
| **æ–¹æ¡ˆ 3ï¼šä»»åŠ¡ä¼˜å…ˆçº§è°ƒæ•´ï¼ˆRabbitMQï¼‰** | RabbitMQ ä½œä¸º Broker          | ä¸å½±å“ä»»åŠ¡ IDï¼Œç›´æ¥è°ƒæ•´ä¼˜å…ˆçº§ | ä»…é€‚ç”¨äº RabbitMQ    |

âœ… **å¦‚æœä½ ä½¿ç”¨ Redis**ï¼Œå»ºè®® **æ–¹æ¡ˆ 1 æˆ– 2**ã€‚
 âœ… **å¦‚æœä½ ä½¿ç”¨ RabbitMQ**ï¼Œå¯ä»¥ä½¿ç”¨ **æ–¹æ¡ˆ 3**ï¼ˆä»»åŠ¡ä¼˜å…ˆçº§ï¼‰ã€‚

å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ **Redis ä½œä¸º Celery çš„ Broker**ï¼Œå¹¶ä¸”å¸Œæœ›**æ›´ç®€å•**åœ°è°ƒæ•´ä»»åŠ¡é¡ºåºï¼Œå¯ä»¥ä½¿ç”¨ **Redis çš„ LPUSH/RPUSH é‡æ–°æ’å…¥ä»»åŠ¡**ï¼Œé¿å…æ’¤é”€å’Œé‡æ–°æäº¤ä»»åŠ¡å¸¦æ¥çš„ ID å˜åŒ–ã€‚

------

## **æœ€ç®€å•æ–¹æ¡ˆï¼šRedis ç›´æ¥è°ƒæ•´ä»»åŠ¡é˜Ÿåˆ—**

### **æ€è·¯**

1. **ä»»åŠ¡å…¥é˜Ÿæ—¶ä½¿ç”¨ Redis List å­˜å‚¨ä»»åŠ¡ ID**ï¼ˆè€Œä¸æ˜¯è®© Celery ç›´æ¥æ‰§è¡Œï¼‰ã€‚
2. **ç”¨æˆ·å¯ä»¥è°ƒæ•´ Redis List é‡Œçš„é¡ºåº**ï¼ˆLPUSHã€LINSERT æ“ä½œï¼‰ã€‚
3. **Worker ä» Redis List æ‹‰å–ä»»åŠ¡å¹¶æäº¤åˆ° Celery**ã€‚

------

## **å®ç°æ­¥éª¤**

### **ï¼ˆ1ï¼‰ä»»åŠ¡å…¥é˜Ÿï¼ˆæ¨é€åˆ° Redis é˜Ÿåˆ—ï¼‰**

```python
import redis
import json
from myapp.tasks import sample_task  # ä½ çš„ Celery ä»»åŠ¡

redis_client = redis.StrictRedis(host="localhost", port=6379, db=1)
TASK_QUEUE_KEY = "custom_task_queue"

def add_task_to_queue(x, y):
    """ å°†ä»»åŠ¡æ·»åŠ åˆ° Redis é˜Ÿåˆ— """
    task_data = json.dumps({"x": x, "y": y})
    redis_client.rpush(TASK_QUEUE_KEY, task_data)  # ä»»åŠ¡æ’åˆ°é˜Ÿåˆ—æœ«å°¾
    return {"message": "Task added to queue"}
```

------

### **ï¼ˆ2ï¼‰è°ƒæ•´ä»»åŠ¡é¡ºåº**

```python
def reorder_task(old_index, new_index):
    """ è°ƒæ•´ä»»åŠ¡é¡ºåº """
    queue = redis_client.lrange(TASK_QUEUE_KEY, 0, -1)
    if old_index >= len(queue) or new_index >= len(queue):
        return {"error": "Invalid index"}

    task = queue.pop(old_index)  # å–å‡ºä»»åŠ¡
    queue.insert(new_index, task)  # æ’å…¥åˆ°æ–°ä½ç½®

    # æ›´æ–° Redis é˜Ÿåˆ—
    redis_client.delete(TASK_QUEUE_KEY)
    for item in queue:
        redis_client.rpush(TASK_QUEUE_KEY, item)

    return {"message": "Task reordered"}
```

------

### **ï¼ˆ3ï¼‰Worker æ‹‰å–ä»»åŠ¡å¹¶æäº¤ Celery**

```python
def process_task():
    """ ä» Redis é˜Ÿåˆ—æ‹‰å–ä»»åŠ¡å¹¶äº¤ç»™ Celery """
    task_data = redis_client.lpop(TASK_QUEUE_KEY)
    if not task_data:
        return {"error": "No tasks in queue"}

    task = json.loads(task_data)
    celery_task = sample_task.apply_async(args=[task["x"], task["y"]])
    return {"message": "Task submitted", "task_id": celery_task.id}
```

------

## **æœ€ç»ˆæ•ˆæœ**

1. **ç”¨æˆ·æäº¤ä»»åŠ¡** â†’ `rpush` æ’é˜Ÿã€‚
2. **ç”¨æˆ·è°ƒæ•´é¡ºåº** â†’ `lrange` è·å–é˜Ÿåˆ—ï¼Œè°ƒæ•´é¡ºåºå `delete`+`rpush` è¦†ç›–é˜Ÿåˆ—ã€‚
3. **åå° Worker æ‰§è¡Œä»»åŠ¡** â†’ `lpop` è·å–ä»»åŠ¡å¹¶æäº¤åˆ° Celeryã€‚

------

## **ä¼˜ç‚¹**

âœ… **ä»»åŠ¡é¡ºåºå¯éšæ—¶è°ƒæ•´**ï¼ˆä¸éœ€è¦æ’¤é”€ä»»åŠ¡ï¼‰ã€‚
 âœ… **ä»»åŠ¡ ID ä¸å˜**ï¼ˆä»»åŠ¡æ•°æ®å­˜ Redisï¼Œç›´åˆ° Worker å–å‡ºæ‰§è¡Œï¼‰ã€‚
 âœ… **æ— éœ€ä¿®æ”¹ Celery é…ç½®**ï¼Œåªæ˜¯åœ¨ Celery ä¹‹å‰åŠ äº†ä¸€å±‚ Redis ä»»åŠ¡ç®¡ç†ã€‚

------

## **é€‚ç”¨åœºæ™¯**

- **ä»»åŠ¡æ’é˜Ÿæ—¶é—´è¾ƒé•¿**ï¼Œéœ€è¦è°ƒæ•´é¡ºåºçš„æƒ…å†µï¼ˆå¦‚æ‰¹é‡ä»»åŠ¡ï¼‰ã€‚
- **æƒ³è¦æ‰‹åŠ¨æ§åˆ¶ä»»åŠ¡æ‰§è¡Œæ—¶æœº**ï¼Œè€Œä¸æ˜¯ Celery è‡ªåŠ¨å¤„ç†ã€‚

ä½ å¯ä»¥ç»“åˆ **Django API** è®©å‰ç«¯å¯ä»¥æ‹–æ‹½è°ƒæ•´ä»»åŠ¡é¡ºåº ğŸš€ã€‚

å¦‚æœä½ å¸Œæœ› **Redis é˜Ÿåˆ—åœ¨ç©ºé—²æ—¶è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡**ï¼Œä½†**æ’é˜Ÿæ—¶å¯ä»¥æ‰‹åŠ¨è°ƒæ•´é¡ºåº**ï¼Œå¯ä»¥ä½¿ç”¨ **ä¸¤ç§æ¨¡å¼**ï¼š

1. **ä»»åŠ¡å°‘æ—¶**ï¼Œä»»åŠ¡ç›´æ¥äº¤ç»™ Celery **è‡ªåŠ¨æ‰§è¡Œ**ã€‚
2. **ä»»åŠ¡å¤šæ—¶**ï¼Œä»»åŠ¡å…ˆè¿›å…¥ **Redis é˜Ÿåˆ—**ï¼Œå¯**æ‰‹åŠ¨è°ƒæ•´é¡ºåº**ï¼Œç„¶åç”± Worker æ‹‰å–æ‰§è¡Œã€‚

------

## **æ–¹æ¡ˆæ¦‚è¿°**

- ä»»åŠ¡å°‘æ—¶ï¼ˆé˜Ÿåˆ—é•¿åº¦ = 0ï¼‰ï¼šç›´æ¥ `apply_async()` **æäº¤ä»»åŠ¡**ï¼Œè®© Celery ç«‹åˆ»æ‰§è¡Œã€‚
- ä»»åŠ¡å¤šæ—¶ï¼ˆé˜Ÿåˆ—é•¿åº¦ > 0ï¼‰ï¼šä»»åŠ¡ **å…ˆè¿›å…¥ Redis é˜Ÿåˆ—**ï¼Œå¯æ‰‹åŠ¨è°ƒæ•´é¡ºåºï¼Œç„¶åç”± Worker ä¾æ¬¡æäº¤åˆ° Celeryã€‚
- **æ‰‹åŠ¨è°ƒæ•´ä»»åŠ¡é¡ºåº**ï¼šå¯ä»¥**å‰ç«¯æä¾›æ¥å£**ï¼Œè°ƒæ•´ä»»åŠ¡åœ¨ Redis é˜Ÿåˆ—ä¸­çš„ä½ç½®ã€‚

------

## **å®ç°æ­¥éª¤**

### **ï¼ˆ1ï¼‰ä»»åŠ¡æäº¤é€»è¾‘**

```python
import redis
import json
from myapp.tasks import sample_task  # ä½ çš„ Celery ä»»åŠ¡

redis_client = redis.StrictRedis(host="localhost", port=6379, db=1)
TASK_QUEUE_KEY = "custom_task_queue"

def add_task(x, y):
    """ 
    ä»»åŠ¡æäº¤ï¼š
    - å¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼Œç›´æ¥æ‰§è¡Œä»»åŠ¡
    - å¦åˆ™ï¼Œè¿›å…¥ Redis é˜Ÿåˆ—ï¼ˆå¯æ‰‹åŠ¨è°ƒæ•´ï¼‰
    """
    queue_length = redis_client.llen(TASK_QUEUE_KEY)

    task_data = json.dumps({"x": x, "y": y})

    if queue_length == 0:
        # é˜Ÿåˆ—ä¸ºç©ºï¼Œç›´æ¥äº¤ç»™ Celery æ‰§è¡Œ
        task = sample_task.apply_async(args=[x, y])
        return {"message": "Task executed immediately", "task_id": task.id}
    else:
        # é˜Ÿåˆ—å·²æœ‰ä»»åŠ¡ï¼Œå…ˆæ’é˜Ÿ
        redis_client.rpush(TASK_QUEUE_KEY, task_data)
        return {"message": "Task added to queue"}
```

âœ… **ä»»åŠ¡å°‘æ—¶ç›´æ¥æ‰§è¡Œ**ï¼Œä»»åŠ¡å¤šæ—¶è¿›é˜Ÿåˆ—ç­‰å¾…ã€‚

------

### **ï¼ˆ2ï¼‰æ‰‹åŠ¨è°ƒæ•´ä»»åŠ¡é¡ºåº**

```python
def reorder_task(old_index, new_index):
    """ è°ƒæ•´ä»»åŠ¡é¡ºåº """
    queue = redis_client.lrange(TASK_QUEUE_KEY, 0, -1)
    if old_index >= len(queue) or new_index >= len(queue):
        return {"error": "Invalid index"}

    task = queue.pop(old_index)  # å–å‡ºä»»åŠ¡
    queue.insert(new_index, task)  # æ’å…¥åˆ°æ–°ä½ç½®

    # æ›´æ–° Redis é˜Ÿåˆ—
    redis_client.delete(TASK_QUEUE_KEY)
    for item in queue:
        redis_client.rpush(TASK_QUEUE_KEY, item)

    return {"message": "Task reordered"}
```

âœ… **å…è®¸ç”¨æˆ·æ‹–æ‹½è°ƒæ•´ä»»åŠ¡é¡ºåº**ï¼ˆç±»ä¼¼å‰ç«¯æ‹–æ‹½é˜Ÿåˆ—æ’åºï¼‰ã€‚

------

### **ï¼ˆ3ï¼‰Worker å¤„ç†æ’é˜Ÿä»»åŠ¡**

```python
import time

def process_queued_tasks():
    """ å¾ªç¯æ£€æŸ¥ Redis é˜Ÿåˆ—ï¼Œæ‰§è¡Œæ’é˜Ÿä»»åŠ¡ """
    while True:
        queue_length = redis_client.llen(TASK_QUEUE_KEY)

        if queue_length > 0:
            task_data = redis_client.lpop(TASK_QUEUE_KEY)
            if task_data:
                task = json.loads(task_data)
                sample_task.apply_async(args=[task["x"], task["y"]])
                print("Task submitted from queue:", task)
        
        time.sleep(2)  # æ¯ 2 ç§’æ£€æŸ¥ä¸€æ¬¡é˜Ÿåˆ—
```

âœ… **å¦‚æœé˜Ÿåˆ—æœ‰ä»»åŠ¡ï¼Œä¾æ¬¡æäº¤åˆ° Celery å¤„ç†**ã€‚

------

### **ï¼ˆ4ï¼‰å¯åŠ¨ Worker çº¿ç¨‹**

å¯ä»¥åœ¨ **Django å¯åŠ¨æ—¶**ï¼Œæˆ–è€…ä½œä¸ºä¸€ä¸ª **ç‹¬ç«‹è¿›ç¨‹** è¿è¡Œè¿™ä¸ª Workerï¼š

```bash
python manage.py run_task_worker
```

æˆ–è€…ï¼Œåˆ›å»º Django å‘½ä»¤ï¼š

```python
from django.core.management.base import BaseCommand
from myapp.utils import process_queued_tasks

class Command(BaseCommand):
    help = "Process queued Celery tasks"

    def handle(self, *args, **kwargs):
        process_queued_tasks()
```

âœ… **è¿™æ ·ï¼ŒRedis ä»»åŠ¡é˜Ÿåˆ—ä¼šä¸€ç›´è¿è¡Œ**ï¼Œè‡ªåŠ¨æ‹‰å–ä»»åŠ¡æ‰§è¡Œã€‚

------

## **æœ€ç»ˆå®ç°æ•ˆæœ**

| æ“ä½œ                     | å¤„ç†é€»è¾‘                              |
| ------------------------ | ------------------------------------- |
| **ä»»åŠ¡å°‘æ—¶ï¼ˆé˜Ÿåˆ—ç©ºï¼‰**   | ä»»åŠ¡ç›´æ¥äº¤ç»™ Celery ç«‹å³æ‰§è¡Œ          |
| **ä»»åŠ¡å¤šæ—¶ï¼ˆé˜Ÿåˆ—éç©ºï¼‰** | ä»»åŠ¡è¿›å…¥ Redis é˜Ÿåˆ—ï¼Œå¯æ‰‹åŠ¨è°ƒæ•´é¡ºåº   |
| **æ‰‹åŠ¨è°ƒæ•´ä»»åŠ¡**         | ç”¨æˆ·å¯è°ƒæ•´ä»»åŠ¡æ’é˜Ÿé¡ºåº                |
| **åå°è‡ªåŠ¨å¤„ç†ä»»åŠ¡**     | Worker å®šæ—¶æ£€æŸ¥ Redisï¼Œæ‹‰å–ä»»åŠ¡å¹¶æ‰§è¡Œ |

------

## **ä¼˜ç‚¹**

âœ… **ä»»åŠ¡é¡ºåºå¯éšæ—¶è°ƒæ•´**ï¼ˆä»»åŠ¡æ’é˜Ÿæ—¶å¯æ‰‹åŠ¨è°ƒæ•´ï¼‰ã€‚
 âœ… **æ— éœ€æ’¤é”€ä»»åŠ¡**ï¼Œä»»åŠ¡åœ¨ Redis ä¸­è°ƒæ•´ï¼Œè€Œä¸æ˜¯ Celery é˜Ÿåˆ—ä¸­ã€‚
 âœ… **è‡ªåŠ¨ä»»åŠ¡ç®¡ç†**ï¼Œç©ºé—²æ—¶è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡ï¼Œæ’é˜Ÿæ—¶å¯æ‰‹åŠ¨è°ƒæ•´é¡ºåºã€‚

è¿™æ ·ä½ å°±å¯ä»¥ **åœ¨ Celery ä»»åŠ¡æ’é˜Ÿçš„æƒ…å†µä¸‹**ï¼Œéšæ—¶è°ƒæ•´ä»»åŠ¡é¡ºåºï¼Œå¹¶ä¸” **ä¸å½±å“ä»»åŠ¡ ID** ğŸ¯ï¼

ä¸‹é¢æ˜¯å®Œæ•´çš„ Django + Redis + Celery **ä»»åŠ¡ç®¡ç†ç³»ç»Ÿ**åç«¯ä»£ç ï¼Œå®ç°äº†ä»¥ä¸‹åŠŸèƒ½ï¼š

1. **ä»»åŠ¡ç›´æ¥æ‰§è¡Œ**ï¼ˆå¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼‰ã€‚
2. **ä»»åŠ¡æ’é˜Ÿ**ï¼ˆå¦‚æœå·²æœ‰ä»»åŠ¡åœ¨æ’é˜Ÿï¼Œå¯è°ƒæ•´é¡ºåºï¼‰ã€‚
3. **æ‰‹åŠ¨è°ƒæ•´ä»»åŠ¡é¡ºåº**ï¼ˆå¯å‰ç«¯æ“ä½œï¼‰ã€‚
4. **åå° Worker è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡**ï¼ˆä» Redis é˜Ÿåˆ—æ‹‰å–ä»»åŠ¡å¹¶æäº¤ Celeryï¼‰ã€‚

------

## **1. å®‰è£…ä¾èµ–**

ç¡®ä¿å·²å®‰è£… Celeryã€Redis å’Œ Djangoï¼š

```bash
pip install celery redis django django-celery-results
```

------

## **2. é…ç½® Celery**

### **åœ¨ `settings.py` é…ç½® Celery**

```python
# Redis ä½œä¸º Celery Broker
CELERY_BROKER_URL = "redis://localhost:6379/0"

# å­˜å‚¨ Celery ä»»åŠ¡ç»“æœï¼ˆå¯é€‰ï¼‰
CELERY_RESULT_BACKEND = "django-db"
```

------

## **3. é…ç½® `celery.py`**

åˆ›å»º `myproject/celery.py`ï¼š

```python
import os
from celery import Celery

os.environ.setdefault("DJANGO_SETTINGS_MODULE", "myproject.settings")

app = Celery("myproject")
app.config_from_object("django.conf:settings", namespace="CELERY")
app.autodiscover_tasks()
```

åœ¨ `__init__.py` é‡ŒåŠ ä¸Šï¼š

```python
from .celery import app as celery_app

__all__ = ("celery_app",)
```

------

## **4. åˆ›å»º Celery ä»»åŠ¡**

åˆ›å»º `tasks.py`ï¼š

```python
from celery import shared_task
import time

@shared_task
def sample_task(x, y):
    """Celery ä»»åŠ¡ï¼šè®¡ç®— x + y"""
    time.sleep(5)  # æ¨¡æ‹Ÿè€—æ—¶ä»»åŠ¡
    return x + y
```

------

## **5. ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†ï¼ˆRedis æ“ä½œï¼‰**

åˆ›å»º `queue_manager.py`ï¼š

```python
import redis
import json
from myapp.tasks import sample_task

redis_client = redis.StrictRedis(host="localhost", port=6379, db=1)
TASK_QUEUE_KEY = "custom_task_queue"

def add_task(x, y):
    """ ä»»åŠ¡æäº¤ï¼š
    - é˜Ÿåˆ—ä¸ºç©ºï¼Œç›´æ¥æ‰§è¡Œ
    - é˜Ÿåˆ—éç©ºï¼Œè¿›å…¥ Redis ç­‰å¾… """
    queue_length = redis_client.llen(TASK_QUEUE_KEY)

    task_data = json.dumps({"x": x, "y": y})

    if queue_length == 0:
        # é˜Ÿåˆ—ä¸ºç©ºï¼Œç›´æ¥æ‰§è¡Œä»»åŠ¡
        task = sample_task.apply_async(args=[x, y])
        return {"message": "Task executed immediately", "task_id": task.id}
    else:
        # é˜Ÿåˆ—éç©ºï¼ŒåŠ å…¥ç­‰å¾…é˜Ÿåˆ—
        redis_client.rpush(TASK_QUEUE_KEY, task_data)
        return {"message": "Task added to queue"}

def reorder_task(old_index, new_index):
    """ è°ƒæ•´ä»»åŠ¡é¡ºåº """
    queue = redis_client.lrange(TASK_QUEUE_KEY, 0, -1)
    if old_index >= len(queue) or new_index >= len(queue):
        return {"error": "Invalid index"}

    task = queue.pop(old_index)  # å–å‡ºä»»åŠ¡
    queue.insert(new_index, task)  # æ’å…¥æ–°ä½ç½®

    # é‡æ–°å†™å…¥ Redis é˜Ÿåˆ—
    redis_client.delete(TASK_QUEUE_KEY)
    for item in queue:
        redis_client.rpush(TASK_QUEUE_KEY, item)

    return {"message": "Task reordered"}

def process_queued_tasks():
    """ å¤„ç† Redis é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ """
    while True:
        queue_length = redis_client.llen(TASK_QUEUE_KEY)

        if queue_length > 0:
            task_data = redis_client.lpop(TASK_QUEUE_KEY)
            if task_data:
                task = json.loads(task_data)
                sample_task.apply_async(args=[task["x"], task["y"]])
                print("Task submitted from queue:", task)

        time.sleep(2)  # æ¯ 2 ç§’æ£€æŸ¥ä¸€æ¬¡é˜Ÿåˆ—
```

------

## **6. Django APIï¼ˆä»»åŠ¡ç®¡ç†æ¥å£ï¼‰**

åœ¨ `views.py` é‡Œï¼š

```python
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from myapp.queue_manager import add_task, reorder_task

class TaskSubmitView(APIView):
    """ æäº¤ä»»åŠ¡ """
    def post(self, request):
        x = request.data.get("x", 1)
        y = request.data.get("y", 2)
        result = add_task(x, y)
        return Response(result, status=status.HTTP_200_OK)

class TaskReorderView(APIView):
    """ è°ƒæ•´ä»»åŠ¡é¡ºåº """
    def post(self, request):
        old_index = request.data.get("old_index")
        new_index = request.data.get("new_index")
        result = reorder_task(old_index, new_index)
        return Response(result, status=status.HTTP_200_OK)
```

------

## **7. Django è·¯ç”±**

åœ¨ `urls.py` æ·»åŠ ï¼š

```python
from django.urls import path
from myapp.views import TaskSubmitView, TaskReorderView

urlpatterns = [
    path("task/submit/", TaskSubmitView.as_view(), name="task_submit"),
    path("task/reorder/", TaskReorderView.as_view(), name="task_reorder"),
]
```

------

## **8. è¿è¡Œ Celery Worker**

```bash
celery -A myproject worker --loglevel=info
```

------

## **9. å¯åŠ¨åå° Worker å¤„ç† Redis é˜Ÿåˆ—**

åˆ›å»º Django å‘½ä»¤ `myapp/management/commands/process_queue.py`ï¼š

```python
from django.core.management.base import BaseCommand
from myapp.queue_manager import process_queued_tasks

class Command(BaseCommand):
    help = "Process queued Celery tasks"

    def handle(self, *args, **kwargs):
        process_queued_tasks()
```

ç„¶åè¿è¡Œï¼š

```bash
python manage.py process_queue
```

------

## **æœ€ç»ˆæ•ˆæœ**

| æ“ä½œ                     | ç»“æœ                                        |
| ------------------------ | ------------------------------------------- |
| **ä»»åŠ¡å°‘æ—¶**ï¼ˆé˜Ÿåˆ—ä¸ºç©ºï¼‰ | ç›´æ¥äº¤ç»™ Celery ç«‹å³æ‰§è¡Œ                    |
| **ä»»åŠ¡å¤šæ—¶**ï¼ˆé˜Ÿåˆ—éç©ºï¼‰ | ä»»åŠ¡è¿›å…¥ Redis ç­‰å¾…ï¼Œå¯æ‰‹åŠ¨è°ƒæ•´é¡ºåº         |
| **è°ƒæ•´ä»»åŠ¡é¡ºåº**         | å¯å‰ç«¯æä¾› UI æ‹–æ‹½ä»»åŠ¡é¡ºåº                  |
| **Worker è‡ªåŠ¨å¤„ç†ä»»åŠ¡**  | åå° Worker æ£€æŸ¥ Redisï¼Œå¹¶æäº¤ä»»åŠ¡åˆ° Celery |

------

## **æ€»ç»“**

âœ… **ä»»åŠ¡å°‘æ—¶ç«‹å³æ‰§è¡Œï¼Œä»»åŠ¡å¤šæ—¶è¿›å…¥ Redis é˜Ÿåˆ—**
 âœ… **æ”¯æŒæ‰‹åŠ¨è°ƒæ•´ä»»åŠ¡é¡ºåº**ï¼ˆå‰ç«¯å¯è°ƒç”¨ API æ‹–æ‹½æ’åºï¼‰
 âœ… **åå°è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡**ï¼ˆé¿å…ä»»åŠ¡ä¸€ç›´å †ç§¯ï¼‰

è¿™æ ·ä½ å°±æ‹¥æœ‰äº†ä¸€ä¸ª **å¯æ§çš„ Celery ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†ç³»ç»Ÿ** ğŸš€ï¼

åœ¨ä½¿ç”¨ Redis ä½œä¸º Celery Broker æ—¶ï¼Œå†…ç½®çš„ä»»åŠ¡ä¼˜å…ˆçº§æ”¯æŒæ˜¯æœ‰é™çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå³ä½¿åœ¨è°ƒç”¨ä»»åŠ¡æ—¶ä¼ é€’äº† priority å‚æ•°ï¼Œè¿™ä¸ªå‚æ•°é€šå¸¸ä¸ä¼šè¢« Redis Broker å®é™…é‡‡ç”¨ï¼Œå› ä¸º Redis æœ¬èº«å¹¶ä¸æ”¯æŒåŸºäºä¼˜å…ˆçº§çš„é˜Ÿåˆ—æ’åºã€‚

------

### **1. å†…ç½®ä¼˜å…ˆçº§æ”¯æŒ**

- **RabbitMQ**ï¼šCelery åœ¨ä½¿ç”¨ RabbitMQ ä½œä¸º Broker æ—¶æ”¯æŒä»»åŠ¡ä¼˜å…ˆçº§ï¼Œä½ å¯ä»¥åœ¨è°ƒç”¨ä»»åŠ¡æ—¶è®¾ç½® priority å‚æ•°ï¼ŒBroker ä¼šæ ¹æ®è®¾å®šçš„ä¼˜å…ˆçº§è°ƒåº¦ä»»åŠ¡ã€‚
- **Redis**ï¼šRedis ä½œä¸º Broker æ—¶ï¼Œè™½ç„¶åœ¨ API å±‚é¢ä¸Šå¯ä»¥ä¼ é€’ priority å‚æ•°ï¼Œä½†å®ƒä¸ä¼šå¯¹ä»»åŠ¡çš„è°ƒåº¦é¡ºåºäº§ç”Ÿå½±å“ï¼Œä»»åŠ¡è¿˜æ˜¯æŒ‰ç…§ FIFOï¼ˆå…ˆè¿›å…ˆå‡ºï¼‰çš„é¡ºåºå¤„ç†ã€‚

------

### **2. æ¨¡æ‹Ÿä»»åŠ¡ä¼˜å…ˆçº§çš„æ–¹æ¡ˆ**

å¦‚æœä½ éœ€è¦åœ¨ Redis ç¯å¢ƒä¸‹å®ç°ç±»ä¼¼ä¼˜å…ˆçº§çš„è°ƒåº¦ï¼Œå¯ä»¥è€ƒè™‘ä»¥ä¸‹å‡ ç§æ–¹æ¡ˆï¼š

#### **æ–¹æ¡ˆ 1ï¼šä½¿ç”¨å¤šä¸ªé˜Ÿåˆ—**

ä½ å¯ä»¥ä¸ºä¸åŒâ€œä¼˜å…ˆçº§â€çš„ä»»åŠ¡è®¾ç½®ä¸åŒçš„é˜Ÿåˆ—ã€‚æ¯”å¦‚ï¼š

- å®šä¹‰ä¸¤ä¸ªé˜Ÿåˆ—ï¼š`high_priority` å’Œ `low_priority`
- æ ¹æ®ä»»åŠ¡çš„ç´§æ€¥ç¨‹åº¦ï¼Œå°†ä»»åŠ¡å‘é€åˆ°å¯¹åº”é˜Ÿåˆ—
- åœ¨å¯åŠ¨ Worker æ—¶ï¼Œè®© Worker åŒæ—¶ç›‘å¬è¿™ä¸¤ä¸ªé˜Ÿåˆ—ï¼Œå¹¶é€šè¿‡ Worker çš„å¯åŠ¨å‚æ•°æ¥è®¾å®šé˜Ÿåˆ—çš„æ¶ˆè´¹é¡ºåºï¼ˆä¾‹å¦‚ï¼Œè®© Worker ä¼˜å…ˆæ¶ˆè´¹ `high_priority` é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ï¼‰

ç¤ºä¾‹ä»£ç ï¼š

```python
from celery import shared_task

@shared_task(queue="high_priority")
def urgent_task(x, y):
    return x + y

@shared_task(queue="low_priority")
def normal_task(x, y):
    return x - y
```

å¯åŠ¨ Worker æ—¶å¯ä»¥æŒ‡å®šé˜Ÿåˆ—çš„é¡ºåºï¼Œä¾‹å¦‚ï¼š

```bash
celery -A myproject worker --loglevel=info -Q high_priority,low_priority
```

è¿™æ · Worker ä¼šä¼˜å…ˆå¤„ç† `high_priority` é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ã€‚

------

#### **æ–¹æ¡ˆ 2ï¼šè‡ªå®šä¹‰ Redis é˜Ÿåˆ—ç®¡ç†**

å¦‚æœä½ å¸Œæœ›åœ¨ä»»åŠ¡æäº¤åèƒ½åŠ¨æ€è°ƒæ•´ä»»åŠ¡é¡ºåºï¼Œå¯ä»¥é‡‡ç”¨è‡ªå®šä¹‰çš„ Redis é˜Ÿåˆ—ç®¡ç†æ–¹æ¡ˆï¼š

- **ä»»åŠ¡å…¥é˜Ÿ**æ—¶ï¼Œå°†ä»»åŠ¡æ•°æ®å­˜å…¥ Redis çš„ List ä¸­ï¼ˆè€Œä¸æ˜¯ç›´æ¥æäº¤åˆ° Celeryï¼‰ã€‚
- å½“é˜Ÿåˆ—ä¸­å­˜åœ¨ä»»åŠ¡æ—¶ï¼Œä½ å¯ä»¥é€šè¿‡æ¥å£è°ƒæ•´ Redis List ä¸­ä»»åŠ¡çš„é¡ºåºã€‚
- åå°è¿›ç¨‹æˆ– Worker å®šæ—¶æ£€æŸ¥ Redis Listï¼Œå¹¶æ ¹æ®è°ƒæ•´åçš„é¡ºåºé€ä¸ªå°†ä»»åŠ¡æäº¤ç»™ Celery æ‰§è¡Œã€‚

è¿™ç§æ–¹å¼å¯ä»¥è®©ä½ åœ¨ä»»åŠ¡ç­‰å¾…æœŸé—´ï¼Œè‡ªç”±è°ƒæ•´ä»»åŠ¡çš„é¡ºåºï¼Œä½†å®ç°ä¸Šéœ€è¦é¢å¤–ç¼–å†™ä»£ç æ¥ç®¡ç† Redis Listã€‚

------

### **3. broker_transport_options ä¸ä¼˜å…ˆçº§**

åœ¨ Celery çš„é…ç½®ä¸­ï¼Œå¯ä»¥é€šè¿‡ `broker_transport_options` è®¾ç½®ä¸€äº› Redis ç›¸å…³çš„å‚æ•°ï¼Œä¾‹å¦‚ `visibility_timeout` å’Œ `max_connections`ã€‚ä¸è¿‡ï¼Œå…³äºä»»åŠ¡ä¼˜å…ˆçº§ï¼ŒRedis Broker å¹¶ä¸æ”¯æŒåŸç”Ÿçš„ä¼˜å…ˆçº§åŠŸèƒ½ï¼Œæ‰€ä»¥å³ä½¿åœ¨ `broker_transport_options` ä¸­è®¾ç½®äº†è¯¸å¦‚ `"queue_order_strategy": "priority"`ï¼ˆæŸäº›æ—§ç‰ˆæœ¬æˆ–ç‰¹å®šå®ç°ä¸­å¯èƒ½å­˜åœ¨è¯¥é€‰é¡¹ï¼‰ï¼Œä¹Ÿä¸ä¼šåƒ RabbitMQ é‚£æ ·å®ç°çœŸæ­£çš„ä»»åŠ¡ä¼˜å…ˆçº§è°ƒåº¦ã€‚

ç¤ºä¾‹é…ç½®ï¼ˆæ³¨æ„è¿™åªæ˜¯éƒ¨åˆ†é…ç½®ï¼Œä¼˜å…ˆçº§éƒ¨åˆ†åœ¨ Redis ä¸‹æ— æ•ˆï¼‰ï¼š

```python
CELERY_BROKER_URL = "redis://localhost:6379/0"
CELERY_BROKER_TRANSPORT_OPTIONS = {
    "visibility_timeout": 3600,
    "max_connections": 10,
    # "queue_order_strategy": "priority"  # åœ¨ Redis ä¸­æ­¤é…ç½®é€šå¸¸ä¸ç”Ÿæ•ˆ
}
```

------

### **æ€»ç»“**

- **ç›´æ¥ä½¿ç”¨ä¼˜å…ˆçº§å‚æ•°**ï¼šåœ¨ Redis Broker ä¸‹ä¼ é€’ `priority` å‚æ•°ä¸ä¼šæ”¹å˜ä»»åŠ¡çš„æ‰§è¡Œé¡ºåºã€‚
- **æ¨¡æ‹Ÿä¼˜å…ˆçº§è°ƒåº¦**ï¼šå¯ä»¥é€šè¿‡è®¾ç½®å¤šä¸ªé˜Ÿåˆ—æˆ–è‡ªå®šä¹‰ Redis é˜Ÿåˆ—ç®¡ç†çš„æ–¹å¼æ¥å®ç°ç±»ä¼¼çš„æ•ˆæœã€‚
- **å»ºè®®**ï¼šå¦‚æœä»»åŠ¡ä¼˜å…ˆçº§å¯¹ä½ éå¸¸é‡è¦ï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨æ”¯æŒä¼˜å…ˆçº§çš„ Brokerï¼ˆå¦‚ RabbitMQï¼‰ï¼Œæˆ–è€…å®ç°è‡ªå®šä¹‰çš„é˜Ÿåˆ—ç®¡ç†é€»è¾‘ã€‚

é€šè¿‡ä»¥ä¸Šæ–¹å¼ï¼Œä½ å¯ä»¥åœ¨ Redis ç¯å¢ƒä¸‹â€œæ¨¡æ‹Ÿâ€ä»»åŠ¡ä¼˜å…ˆçº§ï¼Œè€Œä¸æ˜¯ä¾èµ– Redis æœ¬èº«å¯¹ä¼˜å…ˆçº§çš„æ”¯æŒã€‚
