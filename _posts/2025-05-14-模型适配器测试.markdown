---
layout:     post
title:      "模型适配器测试"
subtitle:   ""
date:       2025-05-14
author:     " Shallow Dreamer"
header-img: "img/post-bg-js-version.jpg"
tags:
    - torch
---

为了设计一个通用的 **模型训练流程框架**，能够适配多种模型类型（如线性回归、数据分析、大语言模型等），最好的方法是使用 **“适配器模式（Adapter Pattern）”** 来封装不同类型模型的差异，使它们统一实现一套训练和评估接口，便于调度、管理、日志记录、结果展示等。

------

## 🧩 一、核心设计理念

- **统一接口**：定义一个抽象基类 `BaseModelAdapter`，所有模型适配器继承它，实现统一的方法。
- **适配器类**：针对不同模型类型（如线性回归、大语言模型等）定义对应的适配器类。
- **训练管理器**：提供统一的模型调度、训练执行、日志收集、状态保存等功能。
- **可扩展性强**：新增模型类型时，只需新增适配器并注册即可，无需改动主流程。

------

## 📦 二、目录结构建议（Django + Python）

```
ai_platform/
├── adapters/                 # 所有模型适配器
│   ├── base.py              # BaseModelAdapter 抽象类
│   ├── linear.py            # 线性回归适配器
│   ├── analysis.py          # 数据分析适配器
│   └── llm.py               # 大语言模型适配器
├── services/
│   └── trainer.py           # 统一训练器/任务管理器
├── models/
│   └── task.py              # ModelTrainTask 等任务模型
└── utils/
    └── logger.py            # 日志工具
```

------

## 🧱 三、核心接口定义

### ✅ `BaseModelAdapter`（抽象基类）

```python
# adapters/base.py
from abc import ABC, abstractmethod

class BaseModelAdapter(ABC):
    def __init__(self, config, dataset):
        self.config = config      # 用户配置参数
        self.dataset = dataset    # 数据集对象或路径

    @abstractmethod
    def preprocess(self):
        """预处理数据"""
        pass

    @abstractmethod
    def train(self):
        """模型训练主逻辑"""
        pass

    @abstractmethod
    def evaluate(self):
        """模型评估逻辑"""
        pass

    @abstractmethod
    def save_model(self, output_path):
        """保存模型到文件/数据库"""
        pass
```

------

## 🧠 四、模型适配器示例

### 1️⃣ 线性回归适配器

```python
# adapters/linear.py
from .base import BaseModelAdapter
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import joblib

class LinearRegressionAdapter(BaseModelAdapter):
    def preprocess(self):
        self.X = self.dataset.drop(columns=['target'])
        self.y = self.dataset['target']

    def train(self):
        self.model = LinearRegression()
        self.model.fit(self.X, self.y)

    def evaluate(self):
        y_pred = self.model.predict(self.X)
        return {"mse": mean_squared_error(self.y, y_pred)}

    def save_model(self, output_path):
        joblib.dump(self.model, output_path)
```

------

### 2️⃣ 大语言模型适配器（如调用 OpenAI GPT）

```python
# adapters/llm.py
from .base import BaseModelAdapter
import openai

class LLMAdapter(BaseModelAdapter):
    def preprocess(self):
        self.prompt = self.config.get("prompt", "")

    def train(self):
        # 通常大语言模型是 zero/few-shot，无需训练，只推理
        self.output = openai.ChatCompletion.create(
            model=self.config.get("model", "gpt-4"),
            messages=[{"role": "user", "content": self.prompt}],
            temperature=self.config.get("temperature", 0.7)
        )

    def evaluate(self):
        return {"output": self.output["choices"][0]["message"]["content"]}

    def save_model(self, output_path):
        # LLM 模型无法本地保存，仅记录 prompt & output
        with open(output_path, 'w') as f:
            f.write(self.output["choices"][0]["message"]["content"])
```

------

## ⚙️ 五、训练任务管理器（训练入口）

```python
# services/trainer.py
from adapters.linear import LinearRegressionAdapter
from adapters.llm import LLMAdapter

# 注册适配器
ADAPTER_REGISTRY = {
    "linear_regression": LinearRegressionAdapter,
    "llm": LLMAdapter,
    # 可拓展更多模型
}

class ModelTrainer:
    def __init__(self, task_config, dataset):
        self.task_type = task_config["task_type"]
        self.adapter_class = ADAPTER_REGISTRY.get(self.task_type)

        if not self.adapter_class:
            raise ValueError(f"Unsupported model type: {self.task_type}")

        self.adapter = self.adapter_class(task_config, dataset)

    def run(self):
        self.adapter.preprocess()
        self.adapter.train()
        results = self.adapter.evaluate()
        self.adapter.save_model(self._output_path())
        return results

    def _output_path(self):
        return f"/tmp/models/{self.task_type}_result.pkl"
```

------

## 🔌 六、使用方式（Django 视图或 Celery 中调用）

```python
from services.trainer import ModelTrainer
from datasets.utils import load_dataset  # 自定义函数：从数据库或 S3 载入数据

def train_model(task_id):
    task_config = {
        "task_type": "linear_regression",
        "learning_rate": 0.01,
        "prompt": "总结这段文本...",
    }
    dataset = load_dataset(task_id)
    trainer = ModelTrainer(task_config, dataset)
    result = trainer.run()
    return result
```

------

## 🧮 七、模型配置字段建议

| 字段名           | 含义                                          | 模型类型   |
| ---------------- | --------------------------------------------- | ---------- |
| `task_type`      | 模型任务类型（如 `llm`, `linear_regression`） | 所有       |
| `learning_rate`  | 学习率                                        | ML/DL 模型 |
| `prompt`         | 输入提示文本                                  | LLM        |
| `temperature`    | 控制 LLM 输出的随机性                         | LLM        |
| `max_iterations` | 最大训练轮数                                  | ML 模型    |
| `target_column`  | 标签列名                                      | ML 模型    |
| `model_name`     | 预设模型名（如 `gpt-4`, `glm` 等）            | LLM        |

------

## ✅ 八、优势总结

- **解耦强**：每种模型适配器独立实现，不会相互影响。
- **易扩展**：新增模型只需添加一个类并注册。
- **接口统一**：主训练逻辑和调用方式不变，便于统一日志、状态管理、资源调度。
- **适合平台化**：非常适用于 AI 平台、AutoML 系统、训练平台构建。

------

如果你有特定模型、特定输入/输出需求（比如图像、多分类、时序预测等），我可以帮你进一步扩展对应的适配器类。

需要我继续帮你完善数据库模型设计、Celery 任务封装、前端对接建议吗？

了解了，我将基于你的要求重新设计并精简训练与预测流程：

- 从数据库中的模型模板表加载指定模型类型的默认参数；
- 与前端传入的模型参数进行合并（前端值优先）；
- 使用适配器模式完成清洗、预处理、训练、保存、发布、预测的全流程；
- 所有结构解耦、接口清晰、逻辑易读可维护。

我会输出关键模块代码和说明，确保你能直接集成使用。请稍等，我整理完就告诉你。

# 后端模型训练与预测流程设计

## 架构概述

数据管道是一种自动化的数据处理工具，它可以从多个源获取数据，对其进行清洗、转换和整合，然后将其提供给机器学习模型进行训练。在本方案中，流程包括：

- **数据清洗**：合并多个 CSV 数据集、按因子筛选字段并去重；
- **数据预处理**：对标记为归一化的数值列进行标准化；
- **模型训练**：根据模型类型选择对应的适配器进行训练；
- **模型保存与发布**：训练结束后将模型保存到本地文件，用户可选择将其上传到 S3；
- **模型预测**：其他用户提供输入字段，根据已发布模型的 ID 和类型加载模型并推理。

## 数据清洗与预处理模块

首先进行数据清洗：读取并合并前端传入的多个 CSV 字符串，按因子列表筛选所需字段，最后去除重复行。完成数据清洗后，对需要归一化的数值列进行处理，实现基本的标准化。以下是示例代码结构：

```python
import pandas as pd
from typing import List
import io

class DataCleaner:
    @staticmethod
    def merge_datasets(csv_contents: List[str]) -> pd.DataFrame:
        """
        合并多个 CSV 文本数据为一个 DataFrame
        """
        df_list = []
        for csv in csv_contents:
            df_list.append(pd.read_csv(io.StringIO(csv)))
        df = pd.concat(df_list, ignore_index=True)
        return df

    @staticmethod
    def filter_fields(df: pd.DataFrame, field_names: List[str]) -> pd.DataFrame:
        """
        根据字段名筛选列
        """
        return df[field_names]

    @staticmethod
    def drop_duplicates(df: pd.DataFrame) -> pd.DataFrame:
        """
        去除重复行
        """
        return df.drop_duplicates()
import pandas as pd
from typing import Dict

class DataPreprocessor:
    @staticmethod
    def normalize(df: pd.DataFrame, factors: List[Dict]) -> pd.DataFrame:
        """
        对需要归一化的数值列进行标准化处理
        """
        for factor in factors:
            name = factor['name']
            if factor.get('normalize') and pd.api.types.is_numeric_dtype(df[name]):
                # 使用均值-标准差标准化
                df[name] = (df[name] - df[name].mean()) / df[name].std()
        return df
```

## 模型适配器接口与实现

使用适配器模式设计统一的模型接口。定义一个 `BaseModelAdapter` 抽象类，规定 `train`、`predict`、`save`、`load` 等方法，所有模型类型的适配器都继承该接口。例如：

```python
import pandas as pd
from typing import Dict, Any
import joblib
from abc import ABC, abstractmethod

class BaseModelAdapter(ABC):
    @abstractmethod
    def train(self, X: pd.DataFrame, y: pd.Series, params: Dict):
        pass

    @abstractmethod
    def predict(self, X: pd.DataFrame) -> Any:
        pass

    def save(self, filepath: str):
        """
        将训练好的模型保存到文件
        """
        joblib.dump(self.model, filepath)

    @classmethod
    def load(cls, filepath: str):
        """
        从文件加载模型
        """
        adapter = cls()
        adapter.model = joblib.load(filepath)
        return adapter
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor

class LinearRegressionAdapter(BaseModelAdapter):
    def __init__(self):
        self.model = LinearRegression()

    def train(self, X, y, params):
        # 初始化模型时应用参数（如正则化系数等）
        self.model = LinearRegression(**params)
        self.model.fit(X, y)

    def predict(self, X):
        return self.model.predict(X)

class XGBoostAdapter(BaseModelAdapter):
    def __init__(self):
        self.model = XGBRegressor()

    def train(self, X, y, params):
        self.model = XGBRegressor(**params)
        self.model.fit(X, y)

    def predict(self, X):
        return self.model.predict(X)

# 若支持大语言模型，可实现对应适配器
class LLMAdapter(BaseModelAdapter):
    def __init__(self):
        self.model = None  # 初始化大语言模型（例如加载预训练模型）

    def train(self, X, y, params):
        # 对于 LLM 可执行微调或其它训练逻辑
        pass

    def predict(self, X):
        # 使用大语言模型进行推理
        return self.model.generate(X)
```

## 训练调度与参数管理

训练模块负责协调整个训练流程。首先，根据前端传入的模型类型，从模板表加载默认参数，然后与前端给定的参数合并（前端优先）。示例代码如下：

```python
class ModelTemplateRepo:
    """
    模型模板表，存储每种模型类型的默认参数
    """
    TEMPLATE = {
        "linear_regression": {"fit_intercept": True, "normalize": False},
        "xgboost": {"max_depth": 5, "learning_rate": 0.1},
        # 可以添加其他模型类型及其默认参数
    }

    @staticmethod
    def get_default_params(model_type: str) -> Dict:
        return ModelTemplateRepo.TEMPLATE.get(model_type, {})

# 适配器注册表：根据模型类型获取对应的 Adapter 类
ADAPTER_REGISTRY = {
    "linear_regression": LinearRegressionAdapter,
    "xgboost": XGBoostAdapter,
    "llm": LLMAdapter
}

class TrainingScheduler:
    def __init__(self):
        pass

    def train_model(self, factors: List[Dict], model_type: str,
                    user_params: Dict, csv_contents: List[str]) -> str:
        # 数据清洗
        df = DataCleaner.merge_datasets(csv_contents)
        df = DataCleaner.filter_fields(df, [f['name'] for f in factors])
        df = DataCleaner.drop_duplicates(df)
        # 数据预处理
        df = DataPreprocessor.normalize(df, factors)
        # 假设最后一个字段为目标变量
        X = df[[f['name'] for f in factors if f['name'] != factors[-1]['name']]]
        y = df[factors[-1]['name']]
        # 参数合并（模板默认参数 + 用户参数）
        default_params = ModelTemplateRepo.get_default_params(model_type)
        params = {**default_params, **user_params}
        # 训练模型
        adapter_cls = ADAPTER_REGISTRY.get(model_type)
        adapter = adapter_cls()
        adapter.train(X, y, params)
        # 保存模型到本地
        model_path = f"{model_type}_model.pkl"
        adapter.save(model_path)
        return model_path  # 返回模型文件路径或 ID
```

## 模型保存与发布

模型训练结束后，模型文件保存在本地。用户确认后，可将模型上传至 S3 等外部存储，便于后续调用。例如：

```python
import boto3

class ModelRegistry:
    @staticmethod
    def upload_to_s3(local_path: str, bucket_name: str, model_id: str):
        """
        将本地模型文件上传到 S3
        """
        s3 = boto3.client('s3')
        s3.upload_file(local_path, bucket_name, f"{model_id}.pkl")
```

## 模型预测模块

预测模块根据传入的已发布模型 ID 和类型加载模型，并对新数据进行预测：

```python
from pandas import DataFrame

class Predictor:
    def __init__(self, adapter_registry):
        self.adapter_registry = adapter_registry

    def predict(self, model_type: str, model_path: str, input_data: DataFrame):
        """
        加载指定模型并进行预测
        """
        adapter_cls = self.adapter_registry.get(model_type)
        adapter = adapter_cls.load(model_path)
        return adapter.predict(input_data)

# 使用示例
adapter_registry = ADAPTER_REGISTRY
predictor = Predictor(adapter_registry)
# 其他用户传入的预测数据示例
# input_df = pd.DataFrame([...])
# preds = predictor.predict("linear_regression", "linear_regression_model.pkl", input_df)
```

以上代码结构实现了从数据清洗到模型训练再到预测的完整流程。各模块设计通用简洁，可根据需要扩展更多模型类型和功能。

**参考文献：** 数据管道核心概念；多源数据合并去重；适配器模式介绍。

明白了。我将为你设计一个完整的后端框架，使用适配器模式来支持多种模型训练与预测流程，包含数据清洗、预处理、模型训练、模型发布（S3）、预测参数传递等功能，确保结构解耦、清晰可扩展。

我会在完成后提供各个模块的代码结构与逻辑说明，供你直接集成。请稍等，我马上整理完毕。

# 后端模型训练与预测框架设计

## 系统架构概览

- **数据处理模块**：负责合并多个数据集（CSV 内容）、按因子参数选取特征列、去重，并根据配置对数值特征进行归一化等预处理。
- **模型适配器接口**：定义统一的训练与预测接口（`train`、`predict` 等方法），各模型类型通过实现该接口适配器来解耦具体算法。
- **示例适配器**：针对线性回归、逻辑回归、XGBoost、预训练大语言模型等不同模型，实现具体的适配器类，负责调用相应框架训练/推理并保存模型。
- **训练调度器**：负责接收前端请求（因子参数、模型参数、数据文件内容），依次调用数据处理、选择适配器训练，并调用模型注册与发布逻辑进行保存和标记。
- **模型注册与发布模块**：管理训练后的模型元数据（如模型 ID、本地路径、状态），在用户确认发布后通过 boto3 上传至 S3，并更新模型发布状态。
- **预测服务**：允许其他用户调用已发布模型进行预测，动态接收输入参数，加载模型并输出预测结果。

各模块通过接口解耦，例如训练调度器只依赖于数据处理和适配器接口，不直接依赖具体模型库；新增模型类型时，只需新增对应的适配器类并注册到工厂即可，无需修改核心流程。

## 模型适配器接口

采用**适配器模式**为各模型类型定义统一接口，以便训练调度器和预测服务可以透明调用。下面给出一个抽象基类 `ModelAdapter`，定义统一的训练、预测、模型保存/加载接口：

```python
from abc import ABC, abstractmethod

class ModelAdapter(ABC):
    """
    模型适配器基类，定义统一的训练和预测接口。
    """

    def __init__(self, model_params: dict):
        """
        初始化适配器时，可传入模型配置参数。
        """
        self.model_params = model_params
        self.model = None  # 在训练后保存模型实例

    @abstractmethod
    def train(self, X, y):
        """
        训练模型。X 为特征数据集（DataFrame 或 ndarray），y 为目标标签。
        """
        pass

    @abstractmethod
    def predict(self, X):
        """
        使用训练好的模型进行预测。X 为输入特征，可为单条或多条数据。
        返回预测结果。
        """
        pass

    @abstractmethod
    def save_model(self, file_path: str):
        """
        将训练好的模型保存到指定文件路径。
        """
        pass

    @abstractmethod
    def load_model(self, file_path: str):
        """
        从指定路径加载模型，用于预测时使用。
        """
        pass
```

- **解耦设计**：训练调度器和预测服务通过该接口与具体模型适配器交互，不需要知道模型细节。新增模型类型时，只需实现该接口并注册，无需修改已有代码。
- **动态扩展**：可通过工厂模式或注册表维护模型类型与适配器类的映射，如 `"linear_regression" -> LinearRegressionAdapter`，方便动态选择适配器。
- **统一调用**：统一的 `train/predict` 接口，参数为特征数据和输入值，支持动态参数输入。

### 示例适配器

以下提供两个示例适配器，一个用于线性回归，一个用于预训练大语言模型（LLM），以展示不同模型类型的适配器实现思路。

- **线性回归适配器**（使用 scikit-learn）：

```python
from sklearn.linear_model import LinearRegression
import joblib

class LinearRegressionAdapter(ModelAdapter):
    def train(self, X, y):
        self.model = LinearRegression(**self.model_params.get('params', {}))
        self.model.fit(X, y)
        return self.model

    def predict(self, X):
        if self.model is None:
            raise RuntimeError("模型尚未训练或加载")
        return self.model.predict(X)

    def save_model(self, file_path: str):
        if self.model is None:
            raise RuntimeError("无模型可保存")
        joblib.dump(self.model, file_path)

    def load_model(self, file_path: str):
        self.model = joblib.load(file_path)
        return self.model
```

- **LLM（大语言模型）适配器**（使用 Hugging Face Transformers）：

```python
from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline
import torch

class LLMAdapter(ModelAdapter):
    def train(self, train_texts, train_labels):
        """
        简要示例：在分类任务下，用预训练模型进行微调。
        实际实现可使用 Trainer 或自定义训练循环。
        """
        model_name = self.model_params.get('model_name', 'bert-base-uncased')
        num_labels = self.model_params.get('num_labels', 2)
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)
        # 这里可进行微调（代码简略，实际可用 Trainer）
        self.tokenizer = tokenizer
        self.model = model
        return model

    def predict(self, texts):
        """
        使用模型进行文本分类预测。texts 可以是单个字符串或字符串列表。
        """
        if self.model is None:
            raise RuntimeError("模型尚未训练或加载")
        # 使用pipeline简化推理
        classifier = pipeline("text-classification", model=self.model, tokenizer=self.tokenizer)
        results = classifier(texts)
        return results

    def save_model(self, dir_path: str):
        """
        保存整个模型及tokenizer到文件夹。
        """
        if self.model is None:
            raise RuntimeError("无模型可保存")
        self.model.save_pretrained(dir_path)
        self.tokenizer.save_pretrained(dir_path)

    def load_model(self, dir_path: str):
        """
        从文件夹加载模型及tokenizer。
        """
        model_name = self.model_params.get('model_name', 'bert-base-uncased')
        self.tokenizer = AutoTokenizer.from_pretrained(dir_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(dir_path)
        return self.model
```

这两个示例展示了：`LinearRegressionAdapter` 负责调用 sklearn 接口训练、预测，并用 `joblib` 保存模型；`LLMAdapter` 则使用 Hugging Face 进行文本分类示例，展示对微调和推理的包装。其它模型类型（如逻辑回归、XGBoost 等）也可类似实现各自的适配器类，复用相同的统一接口。

## 数据处理模块

数据处理模块负责从前端接收的数据文件内容开始，进行清洗和预处理，最终生成可供模型训练的特征矩阵和标签。设计中将其解耦为单独的类，比如 `DataProcessor`。主要功能包括：

1. **数据清洗**：合并前端传来的多个 CSV 文件内容（字符串形式），根据因子列表提取对应列，并去除重复行。
2. **归一化等预处理**：遍历因子配置，如果某列标记需要归一化且为数值类型，则对该列进行 Min-Max 归一化或其他方式转换。

下面给出一个示例实现：

```python
import pandas as pd
from io import StringIO
from sklearn.preprocessing import MinMaxScaler

class DataProcessor:
    def clean(self, file_contents: list, factors: list) -> pd.DataFrame:
        """
        合并多个 CSV 内容，提取因子相关的列，并去除重复值。
        - file_contents: 包含多个 CSV 格式字符串的列表
        - factors: 因子配置列表，每个因子包含 'name' (列名) 和其他属性
        """
        # 读取并合并所有 CSV 内容
        dfs = [pd.read_csv(StringIO(content)) for content in file_contents]
        df = pd.concat(dfs, ignore_index=True)

        # 提取因子指定的列
        selected_cols = [f['name'] for f in factors]
        df = df.loc[:, selected_cols]

        # 去除完全重复的行
        df = df.drop_duplicates().reset_index(drop=True)
        return df

    def preprocess(self, df: pd.DataFrame, factors: list) -> pd.DataFrame:
        """
        对数值列进行归一化处理（如配置了 normalize=True）。
        - df: 上一步清洗后的 DataFrame
        - factors: 因子配置，包含类型和是否归一化的标志
        """
        for f in factors:
            col = f['name']
            if f.get('type') == 'numeric' and f.get('normalize', False):
                scaler = MinMaxScaler()
                df[col] = scaler.fit_transform(df[[col]])
        return df
```

- **解耦设计**：`TrainingScheduler` 会调用 `DataProcessor`，而不会关心具体的清洗逻辑细节。若需要增加新预处理方法（如标准化、缺失值填充等），只要在 `DataProcessor` 中扩展即可，不影响其他模块。
- **数据读取**：使用 `StringIO` 读取 CSV 内容字符串，实现“文件内容”而非路径传递的读取方式。
- **去重和筛选**：直接使用 `pandas` 的 `drop_duplicates()` 以及列选择功能实现。

## 训练调度器

训练调度器（`TrainingScheduler`）负责协调整个训练流程，将前端传入的参数和数据分发给各子模块，并管理模型训练与保存的流程。主要逻辑包括：

- 接收前端参数：因子配置列表 `factor_params`、模型配置 `model_params`、以及一个或多个数据文件内容 `data_contents`。
- 调用数据处理模块：先进行数据清洗 (`clean`)，再进行预处理 (`preprocess`)。
- 选择模型适配器：根据 `model_params['type']`，从工厂或注册表中获取对应的适配器实例。
- 调用适配器训练：传入特征矩阵和标签进行训练，并保存模型到本地临时路径。
- 注册模型元数据：将模型保存路径、参数等信息注册到模型注册表，并生成模型 ID 。
- 等待发布：训练完成后模型先处于“已训练未发布”状态，待用户确认后上传到 S3。

下面是一个示例实现：

```python
import uuid
import os

class TrainingScheduler:
    def __init__(self, data_processor, adapter_factory, model_registry):
        self.data_processor = data_processor
        self.adapter_factory = adapter_factory
        self.model_registry = model_registry

    def schedule(self, factor_params: list, model_params: dict, data_contents: list) -> str:
        """
        调度训练流程，返回模型ID（唯一标识）。
        """
        # 1. 数据清洗和预处理
        df_clean = self.data_processor.clean(data_contents, factor_params)
        df_processed = self.data_processor.preprocess(df_clean, factor_params)

        # 提取特征矩阵X和标签y
        target_col = model_params['target']  # 假设模型参数里指定了目标列
        feature_cols = [f['name'] for f in factor_params if f['name'] != target_col]
        X = df_processed[feature_cols]
        y = df_processed[target_col]

        # 2. 获取对应的模型适配器并训练
        model_type = model_params['type']
        adapter = self.adapter_factory.get_adapter(model_type, model_params)
        adapter.train(X, y)

        # 3. 模型保存（本地）
        model_id = str(uuid.uuid4())
        local_dir = f"/tmp/model_{model_id}"
        os.makedirs(local_dir, exist_ok=True)
        adapter.save_model(local_dir)  # 保存模型或模型文件夹

        # 4. 注册模型信息
        self.model_registry.register(model_id, {
            'type': model_type,
            'local_path': local_dir,
            'params': model_params,
            'published': False
        })
        return model_id

    def publish_model(self, model_id: str):
        """
        用户确认发布后调用此方法，将模型上传到 S3 并更新状态。
        """
        record = self.model_registry.get(model_id)
        if not record:
            raise ValueError("模型ID不存在")
        if record['published']:
            return  # 已发布无需重复
        local_path = record['local_path']
        # 构造 S3 key，可根据需求使用模型ID等信息命名
        s3_key = f"models/{model_id}.zip"
        uploader = S3Uploader(bucket_name="your-bucket-name")
        # 假设模型保存为一个目录，这里先压缩为zip上传，示例代码
        zip_path = f"{local_path}.zip"
        os.system(f"zip -r {zip_path} {local_path}")
        uploader.upload_file(zip_path, s3_key)
        # 更新发布状态
        record['published'] = True
        record['s3_key'] = s3_key
        self.model_registry.update(model_id, record)
```

- **模型ID**：生成唯一 `model_id`（如使用 `uuid`），便于后续引用和状态管理。
- **本地保存**：先将模型保存到后端本地路径（或临时目录），再在发布时统一上传。
- **待发布状态**：训练完成后，模型在注册表中标记为未发布状态，等待用户确认再触发 S3 上传。
- **S3 上传**：示例中用 `S3Uploader`（见下文）进行上传，这里假设模型先压缩后上传到指定 bucket。实际可根据模型类型选择不同的打包方式。

## 模型注册与发布

`ModelRegistry` 负责维护所有模型的元数据，包括状态（已训练/已发布）、本地路径、S3 路径等信息。下面是一个简单的注册表设计：

```python
class ModelRegistry:
    def __init__(self):
        # 存储模型元数据，key 为 model_id
        self._store = {}

    def register(self, model_id: str, metadata: dict):
        """
        注册新模型信息。
        """
        self._store[model_id] = metadata

    def update(self, model_id: str, metadata: dict):
        """
        更新模型元数据（如发布状态、S3路径等）。
        """
        if model_id in self._store:
            self._store[model_id].update(metadata)
        else:
            raise KeyError("模型ID未找到")

    def get(self, model_id: str) -> dict:
        """
        获取模型元数据。
        """
        return self._store.get(model_id)
```

- **元数据管理**：`metadata` 包含了模型类型、参数、本地存储路径、是否发布、S3 存储键等信息。实际系统中可以结合数据库或持久化存储，此处简化为内存字典。
- **发布逻辑**：当调用 `TrainingScheduler.publish_model(model_id)` 时，会上传模型至 S3，并更新 `metadata['published'] = True` 及相应的 S3 存储路径。这样预测服务可依据 `published` 状态决定是否允许预测调用。
- **后续扩展**：可增加版本控制、访问权限、模型描述等字段，使模型注册表更加完善。

## S3 上传工具

使用 `boto3` 客户端实现模型文件上传到 S3。示例工具类如下：

```python
import boto3

class S3Uploader:
    def __init__(self, bucket_name: str):
        self.s3 = boto3.client('s3')
        self.bucket = bucket_name

    def upload_file(self, file_path: str, key: str):
        """
        上传本地文件到指定 S3 bucket 的 key 路径。
        """
        self.s3.upload_file(file_path, self.bucket, key)
```

- 在生产环境中，需要配置 AWS 的访问密钥或使用 IAM 角色进行认证。
- `file_path` 支持本地路径，`key` 定义了存储在 S3 上的文件名（可包含目录）。
- 上传完成后，注册表中保存对应的 S3 路径信息，以便后续加载使用。

## 模型预测服务

预测服务允许其他用户指定已发布的模型 ID 并输入特征进行预测。主要步骤：

1. **加载模型**：根据模型 ID 从注册表获取模型元数据，检查是否已发布。若模型文件尚在本地，可直接 `load_model`；若仅在 S3 上，则先下载（或通过 `load_model` 支持直接S3 URL）。
2. **动态输入**：接收前端传入的预测参数，通常为键值对形式的特征值。在使用时需要将其转换为模型适配器能接受的格式（如 DataFrame 或矩阵）。
3. **调用预测**：使用适配器的 `predict` 方法进行预测，并返回结果给前端。

示例实现如下：

```python
class PredictionService:
    def __init__(self, adapter_factory, model_registry):
        self.adapter_factory = adapter_factory
        self.model_registry = model_registry

    def predict(self, model_id: str, input_data: dict):
        """
        使用已发布模型进行预测。
        - model_id: 注册表中的模型ID
        - input_data: 包含特征名称和值的字典（动态参数输入）
        """
        record = self.model_registry.get(model_id)
        if not record or not record.get('published', False):
            raise ValueError("模型未发布或不存在")

        model_type = record['type']
        model_params = record['params']
        # 获取对应适配器
        adapter = self.adapter_factory.get_adapter(model_type, model_params)

        # 若需要，从 S3 下载模型，这里假设本地已有模型目录，否则实现下载逻辑
        local_path = record['local_path']
        adapter.load_model(local_path)

        # 将输入数据转换为 DataFrame (或适配器支持的格式)
        import pandas as pd
        input_df = pd.DataFrame([input_data])

        # 预测
        predictions = adapter.predict(input_df)
        return predictions
```

- **动态参数**：前端可传入任意需要的特征字段和值，服务端将其包装为单行的 `DataFrame` 进行预测。这样 `predict` 接口无需固定输入维度。
- **模型加载**：假设模型已经上传并下载至本地（或本地保留训练结果），`load_model` 负责加载模型实例。若模型仅在 S3，可在此处加下载代码（如 `boto3.download_file`）后再加载。
- **返回结果**：将模型输出直接返回给前端。对于分类任务可能需要映射类别标签，回归则返回数值。

## 代码调用示例

下面给出一个简单的流程示例，说明如何使用上述组件完成训练和预测：

```python
# 假设前端传递：
factor_params = [
    {'name': 'age', 'type': 'numeric', 'normalize': True},
    {'name': 'salary', 'type': 'numeric', 'normalize': True},
    {'name': 'gender', 'type': 'categorical', 'normalize': False},
    {'name': 'income', 'type': 'numeric', 'normalize': False},  # 目标列
]
model_params = {
    'type': 'linear_regression',
    'target': 'income',
    'params': {}  # 线性回归超参数
}
data_contents = [csv_string1, csv_string2]  # CSV文件内容字符串列表

# 初始化组件
data_processor = DataProcessor()
adapter_factory = ModelAdapterFactory()  # 假设工厂已实现类型->适配器映射
model_registry = ModelRegistry()
scheduler = TrainingScheduler(data_processor, adapter_factory, model_registry)

# 调度训练
model_id = scheduler.schedule(factor_params, model_params, data_contents)
print(f"模型已训练完成，ID = {model_id}，等待发布。")

# 用户确认发布后调用
scheduler.publish_model(model_id)
print("模型已发布至 S3。")

# 预测示例
prediction_service = PredictionService(adapter_factory, model_registry)
input_features = {'age': 30, 'salary': 60000, 'gender': 'Male'}
result = prediction_service.predict(model_id, input_features)
print("预测结果：", result)
```

以上示例演示了整个流程：前端传入数据后，**训练调度器**完成数据处理和模型训练；训练完成后，管理员确认发布模型；其他用户再调用**预测服务**，通过模型 ID 和动态输入参数获取预测结果。整个过程中的各模块职责清晰，使用**适配器模式**保证了对不同模型类型的一致调用接口，并通过工厂/注册表支持灵活扩展新的模型类型。

下面是一个**高度解耦、可扩展**的**AI 模型训练与预测通用流程**实现，采用**适配器模式**来支持多种模型（线性回归、XGBoost、大语言模型等），并围绕你的需求（数据清洗、预处理、模型训练、保存、发布、预测）进行模块化拆分。

------

## 🧩 1. 目录结构建议

```
ai_platform/
├── adapters/                 # 各类模型适配器
│   ├── base.py              # 模型适配器接口
│   ├── linear_regression.py
│   ├── xgboost_model.py
│   └── llm_model.py
├── core/
│   ├── cleaner.py           # 数据清洗
│   ├── preprocessor.py      # 数据预处理
│   ├── scheduler.py         # 训练调度器
│   ├── registry.py          # 模型保存和发布
│   └── predictor.py         # 预测模块
├── config/
│   └── registry.py          # 模型类型注册表
└── main.py                  # 训练/预测入口
```

------

## 🧠 2. 适配器接口定义（`adapters/base.py`）

```python
from abc import ABC, abstractmethod
import pandas as pd
from typing import Dict, Any

class BaseModelAdapter(ABC):
    @abstractmethod
    def train(self, X: pd.DataFrame, y: pd.Series, params: Dict[str, Any]):
        pass

    @abstractmethod
    def predict(self, X: pd.DataFrame) -> Any:
        pass

    @abstractmethod
    def save(self, path: str):
        pass

    @abstractmethod
    def load(self, path: str):
        pass
```

------

## 📈 3. 示例模型适配器：线性回归（`adapters/linear_regression.py`）

```python
from sklearn.linear_model import LinearRegression
from .base import BaseModelAdapter
import joblib

class LinearRegressionAdapter(BaseModelAdapter):
    def __init__(self):
        self.model = None

    def train(self, X, y, params):
        self.model = LinearRegression(**params)
        self.model.fit(X, y)

    def predict(self, X):
        return self.model.predict(X)

    def save(self, path):
        joblib.dump(self.model, path)

    def load(self, path):
        self.model = joblib.load(path)
```

其他模型如 XGBoost 和 LLM 同理。

------

## 🧼 4. 数据清洗和预处理模块（`core/cleaner.py`, `core/preprocessor.py`）

```python
# cleaner.py
import pandas as pd
import io
from typing import List

class DataCleaner:
    @staticmethod
    def clean(csv_contents: List[str], factor_names: List[str]) -> pd.DataFrame:
        dfs = [pd.read_csv(io.StringIO(c)) for c in csv_contents]
        df = pd.concat(dfs).drop_duplicates()
        return df[factor_names]
# preprocessor.py
class DataPreprocessor:
    @staticmethod
    def normalize(df: pd.DataFrame, factors: List[Dict]):
        for factor in factors:
            name = factor["name"]
            if factor.get("normalize") and pd.api.types.is_numeric_dtype(df[name]):
                df[name] = (df[name] - df[name].mean()) / df[name].std()
        return df
```

------

## 🧠 5. 模型调度器：训练执行器（`core/scheduler.py`）

```python
from config.registry import ADAPTER_REGISTRY
from .cleaner import DataCleaner
from .preprocessor import DataPreprocessor
import pandas as pd
import os

class TrainingScheduler:
    def train(self, model_type: str, factors: List[Dict], model_params: Dict, csv_contents: List[str]) -> str:
        # 1. 清洗数据
        field_names = [f["name"] for f in factors]
        df = DataCleaner.clean(csv_contents, field_names)

        # 2. 预处理
        df = DataPreprocessor.normalize(df, factors)

        # 3. 生成 X/y
        target = field_names[-1]
        X = df.drop(columns=[target])
        y = df[target]

        # 4. 获取适配器
        adapter_cls = ADAPTER_REGISTRY[model_type]
        model = adapter_cls()
        model.train(X, y, model_params)

        # 5. 保存模型
        path = f"models/{model_type}_{hash(tuple(field_names))}.pkl"
        os.makedirs("models", exist_ok=True)
        model.save(path)

        return path
```

------

## ☁️ 6. 发布模块（`core/registry.py`）

```python
import boto3

class ModelPublisher:
    def upload_to_s3(self, local_path: str, model_key: str, bucket: str):
        s3 = boto3.client("s3")
        s3.upload_file(local_path, bucket, model_key)
```

------

## 🔍 7. 推理模块（`core/predictor.py`）

```python
from config.registry import ADAPTER_REGISTRY

class Predictor:
    def predict(self, model_type: str, model_path: str, input_df):
        adapter_cls = ADAPTER_REGISTRY[model_type]
        model = adapter_cls()
        model.load(model_path)
        return model.predict(input_df)
```

------

## 🧩 8. 模型注册表（`config/registry.py`）

```python
from adapters.linear_regression import LinearRegressionAdapter
from adapters.xgboost_model import XGBoostAdapter
from adapters.llm_model import LLMAdapter

ADAPTER_REGISTRY = {
    "linear_regression": LinearRegressionAdapter,
    "xgboost": XGBoostAdapter,
    "llm": LLMAdapter
}
```

------

## 🚀 9. 主调用流程（`main.py` 示例）

```python
from core.scheduler import TrainingScheduler
from core.predictor import Predictor

# 模拟前端输入
factors = [
    {"name": "feature1", "normalize": True},
    {"name": "feature2", "normalize": False},
    {"name": "target", "normalize": False}
]
model_type = "linear_regression"
model_params = {"fit_intercept": True}
csvs = [open("data1.csv").read(), open("data2.csv").read()]

# 训练流程
scheduler = TrainingScheduler()
model_path = scheduler.train(model_type, factors, model_params, csvs)

# 推理流程
predictor = Predictor()
import pandas as pd
input_data = pd.DataFrame([{"feature1": 1.2, "feature2": 3.4}])
pred = predictor.predict(model_type, model_path, input_data)
print(pred)
```

------

## ✅ 总结：核心解耦点

| 模块                               | 功能         | 解耦说明                   |
| ---------------------------------- | ------------ | -------------------------- |
| `BaseModelAdapter`                 | 模型标准接口 | 适配不同模型训练与推理逻辑 |
| `TrainingScheduler`                | 调度训练流程 | 独立于具体模型与数据格式   |
| `DataCleaner` + `DataPreprocessor` | 数据处理模块 | 不依赖模型逻辑，按因子驱动 |
| `ADAPTER_REGISTRY`                 | 适配器注册表 | 模型扩展零侵入             |
| `Predictor`                        | 推理统一入口 | 封装模型加载和推理逻辑     |

------

如你需要，我可以进一步补充：

- FastAPI 接口封装；
- S3 接口本地 mock 测试；
- 对接任务队列（如 Celery）执行异步训练。

是否需要我继续封装这些模块？

