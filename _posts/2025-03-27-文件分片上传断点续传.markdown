---
layout:     post
title:      "æ–‡ä»¶åˆ†ç‰‡ä¸Šä¼ æ–­ç‚¹ç»­ä¼ "
subtitle:   ""
date:       2025-03-27
author:     " Shallow Dreamer"
header-img: "img/post-bg-js-version.jpg"
tags:
    - vue3
    - axios
    - Django
    - s3
---

åœ¨ Vue 3 å‰ç«¯ã€Django åç«¯ï¼Œå¹¶ä½¿ç”¨ AWS S3 ä½œä¸ºå­˜å‚¨çš„ç¯å¢ƒä¸‹ï¼Œå®ç°**åˆ†ç‰‡ä¸Šä¼ **å’Œ**æ–­ç‚¹ç»­ä¼ **ï¼Œé€šå¸¸æ¶‰åŠä»¥ä¸‹æ­¥éª¤ï¼š

------

## **1. ä¸»è¦æµç¨‹**

1. **å‰ç«¯åˆ†ç‰‡**ï¼š
   - è¯»å–æ–‡ä»¶ï¼Œå¹¶æŒ‰ç…§å›ºå®šå¤§å°ï¼ˆå¦‚ 5MBï¼‰è¿›è¡Œåˆ†ç‰‡ã€‚
2. **è®¡ç®—æ–‡ä»¶å”¯ä¸€æ ‡è¯†**ï¼š
   - é€šè¿‡ SHA-256 å“ˆå¸Œè®¡ç®—æ–‡ä»¶æ ‡è¯†ï¼Œç”¨äºæ£€æŸ¥ S3 æ˜¯å¦å·²æœ‰éƒ¨åˆ†åˆ†ç‰‡ã€‚
3. **è¯·æ±‚ S3 ä¸Šä¼  URL**ï¼š
   - Django é€šè¿‡ `boto3` ç”Ÿæˆ S3 é¢„ç­¾å URLï¼Œå…è®¸å‰ç«¯ç›´æ¥ä¸Šä¼ åˆ†ç‰‡åˆ° S3ã€‚
4. **ä¸Šä¼ åˆ†ç‰‡**ï¼š
   - ä½¿ç”¨ `fetch` å‘é€ `PUT` è¯·æ±‚è‡³ S3 é¢„ç­¾å URL ã€‚
5. **åˆå¹¶åˆ†ç‰‡**ï¼š
   - ä¸Šä¼ å®Œæˆåï¼Œé€šçŸ¥ Django åç«¯è§¦å‘ S3 **åˆå¹¶åˆ†ç‰‡**ã€‚
6. **æ–­ç‚¹ç»­ä¼ **ï¼š
   - æŸ¥è¯¢ S3 å·²ä¸Šä¼ çš„åˆ†ç‰‡ï¼Œè·³è¿‡å·²å®Œæˆçš„éƒ¨åˆ†ã€‚

------

## **2. å‰ç«¯ Vue 3 å®ç°**

### **2.1 è®¡ç®—æ–‡ä»¶å“ˆå¸Œ**

```javascript
async function calculateFileHash(file) {
  const chunkSize = 2 * 1024 * 1024; // 2MB
  const chunks = Math.ceil(file.size / chunkSize);
  const spark = new Uint8Array();

  for (let i = 0; i < chunks; i++) {
    const chunk = file.slice(i * chunkSize, (i + 1) * chunkSize);
    const buffer = await chunk.arrayBuffer();
    spark.set(new Uint8Array(buffer));
  }

  const hashBuffer = await crypto.subtle.digest("SHA-256", spark);
  return Array.from(new Uint8Array(hashBuffer)).map(b => b.toString(16).padStart(2, "0")).join("");
}
```

------

### **2.2 åˆ†ç‰‡æ–‡ä»¶**

```javascript
function sliceFile(file, chunkSize = 5 * 1024 * 1024) {
  const chunks = [];
  let start = 0;

  while (start < file.size) {
    chunks.push(file.slice(start, start + chunkSize));
    start += chunkSize;
  }

  return chunks;
}
```

------

### **2.3 è¯·æ±‚ S3 ä¸Šä¼  URL**

```javascript
async function getUploadUrls(fileHash, totalChunks) {
  const response = await fetch("/api/upload/initiate", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ hash: fileHash, totalChunks })
  });

  return await response.json(); // è¿”å› { uploadId, urls: [url1, url2, ...] }
}
```

------

### **2.4 ä¸Šä¼ åˆ†ç‰‡**

```javascript
async function uploadChunkToS3(url, chunk) {
  return fetch(url, {
    method: "PUT",
    body: chunk,
    headers: { "Content-Type": "application/octet-stream" }
  });
}
```

------

### **2.5 è§¦å‘åˆå¹¶**

```javascript
async function completeUpload(fileHash, uploadId) {
  await fetch("/api/upload/complete", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ hash: fileHash, uploadId })
  });
}
```

------

### **2.6 è§¦å‘ä¸Šä¼ **

```javascript
async function handleUpload(file) {
  const fileHash = await calculateFileHash(file);
  const chunks = sliceFile(file);

  const { uploadId, urls } = await getUploadUrls(fileHash, chunks.length);

  for (let i = 0; i < chunks.length; i++) {
    await uploadChunkToS3(urls[i], chunks[i]);
  }

  await completeUpload(fileHash, uploadId);
  console.log("ä¸Šä¼ å®Œæˆï¼");
}
```

------

## **3. Django åç«¯å®ç°**

å®‰è£… `boto3`ï¼š

```sh
pip install boto3
```

é…ç½® Django è®¿é—® AWS S3ï¼š

```python
import boto3
from django.conf import settings

s3_client = boto3.client(
    's3',
    aws_access_key_id=settings.AWS_ACCESS_KEY_ID,
    aws_secret_access_key=settings.AWS_SECRET_ACCESS_KEY,
    region_name=settings.AWS_REGION
)
```

------

### **3.1 åˆå§‹åŒ– S3 å¤šéƒ¨åˆ†ä¸Šä¼ **

```python
from django.http import JsonResponse
import uuid

def initiate_upload(request):
    data = request.json()
    file_hash = data["hash"]
    total_chunks = data["totalChunks"]
    
    upload_id = str(uuid.uuid4())  # ç”Ÿæˆå”¯ä¸€çš„ upload_id

    presigned_urls = [
        s3_client.generate_presigned_url(
            "put_object",
            Params={"Bucket": settings.AWS_STORAGE_BUCKET_NAME, "Key": f"uploads/{file_hash}/part-{i+1}", "ContentType": "application/octet-stream"},
            ExpiresIn=3600
        ) for i in range(total_chunks)
    ]
    
    return JsonResponse({"uploadId": upload_id, "urls": presigned_urls})
```

------

### **3.2 å®Œæˆä¸Šä¼ **

```python
def complete_upload(request):
    data = request.json()
    file_hash = data["hash"]
    upload_id = data["uploadId"]
    
    parts = [
        {"ETag": s3_client.head_object(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Key=f"uploads/{file_hash}/part-{i+1}")["ETag"], "PartNumber": i+1}
        for i in range(len(s3_client.list_objects_v2(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Prefix=f"uploads/{file_hash}")["Contents"]))
    ]
    
    s3_client.complete_multipart_upload(
        Bucket=settings.AWS_STORAGE_BUCKET_NAME,
        Key=f"uploads/{file_hash}/final",
        UploadId=upload_id,
        MultipartUpload={"Parts": parts}
    )
    
    return JsonResponse({"message": "Upload completed"})
```

------

## **4. æ–­ç‚¹ç»­ä¼ **

### **4.1 æŸ¥è¯¢å·²ä¸Šä¼ çš„åˆ†ç‰‡**

```python
def check_uploaded_chunks(request):
    file_hash = request.GET.get("hash")
    
    existing_chunks = []
    response = s3_client.list_objects_v2(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Prefix=f"uploads/{file_hash}")

    if "Contents" in response:
        existing_chunks = [obj["Key"].split("-")[-1] for obj in response["Contents"]]
    
    return JsonResponse({"uploadedChunks": existing_chunks})
```

------

### **4.2 å‰ç«¯è·å–å·²ä¸Šä¼ çš„åˆ†ç‰‡**

```javascript
async function checkUploadedChunks(fileHash) {
  const response = await fetch(`/api/upload/check?hash=${fileHash}`);
  return await response.json(); // è¿”å›å·²ä¸Šä¼ çš„åˆ†ç‰‡ç´¢å¼•æ•°ç»„
}
```

------

## **5. è§¦å‘ä¸Šä¼ ï¼ˆå¸¦æ–­ç‚¹ç»­ä¼ ï¼‰**

```javascript
async function handleUpload(file) {
  const fileHash = await calculateFileHash(file);
  const chunks = sliceFile(file);

  const { uploadId, urls } = await getUploadUrls(fileHash, chunks.length);
  const uploadedChunks = await checkUploadedChunks(fileHash);

  for (let i = 0; i < chunks.length; i++) {
    if (!uploadedChunks.includes(String(i + 1))) {
      await uploadChunkToS3(urls[i], chunks[i]);
    }
  }

  await completeUpload(fileHash, uploadId);
  console.log("ä¸Šä¼ å®Œæˆï¼");
}
```

------

## **6. æ€»ç»“**

âœ… **åˆ†ç‰‡ä¸Šä¼ **ï¼šå‰ç«¯åˆ‡ç‰‡åä¸Šä¼ è‡³ S3
 âœ… **é¢„ç­¾å URL**ï¼šDjango åç«¯ç”Ÿæˆ S3 é¢„ç­¾å URL
 âœ… **æ–­ç‚¹ç»­ä¼ **ï¼šæŸ¥è¯¢å·²ä¸Šä¼ çš„åˆ†ç‰‡ï¼Œè·³è¿‡å·²ä¸Šä¼ éƒ¨åˆ†
 âœ… **åˆå¹¶æ–‡ä»¶**ï¼šDjango è§¦å‘ S3 åˆå¹¶åˆ†ç‰‡

è¿™æ ·å°±å®Œæˆäº† Vue 3 + Django + S3 çš„**åˆ†ç‰‡ä¸Šä¼ **å’Œ**æ–­ç‚¹ç»­ä¼ **ğŸš€ã€‚

è¦å®ç°**é¡µé¢åˆ·æ–°åç»§ç»­æ–­ç‚¹ç»­ä¼ **æˆ–**æ¸…é™¤å·²ä¸Šä¼ çš„åˆ†ç‰‡**ï¼Œå¯ä»¥é‡‡ç”¨ä»¥ä¸‹æ–¹æ¡ˆï¼š

------

## **ğŸ“Œ æ–¹æ¡ˆ 1ï¼šé¡µé¢åˆ·æ–°åç»§ç»­ä¸Šä¼ **

**æ ¸å¿ƒæ€è·¯**ï¼š

- **æœ¬åœ°å­˜å‚¨è¿›åº¦**ï¼šå°† `fileHash` å’Œ `uploadId` å­˜å‚¨åœ¨ `localStorage` æˆ– IndexedDB ä¸­ã€‚
- **æ£€æŸ¥å·²ä¸Šä¼ åˆ†ç‰‡**ï¼šé¡µé¢åˆ·æ–°åï¼Œå‰ç«¯ä»æœåŠ¡å™¨è·å–å·²ä¸Šä¼ çš„åˆ†ç‰‡ä¿¡æ¯ï¼Œç»§ç»­ä¸Šä¼ å‰©ä½™éƒ¨åˆ†ã€‚

------

### **âœ… 1.1 å­˜å‚¨ä¸Šä¼ è¿›åº¦**

åœ¨ `localStorage` é‡Œè®°å½• `fileHash` å’Œ `uploadId`ï¼š

```javascript
function saveUploadProgress(fileHash, uploadId) {
  localStorage.setItem("uploadProgress", JSON.stringify({ fileHash, uploadId }));
}

function getUploadProgress() {
  return JSON.parse(localStorage.getItem("uploadProgress"));
}

function clearUploadProgress() {
  localStorage.removeItem("uploadProgress");
}
```

------

### **âœ… 1.2 æ–­ç‚¹ç»­ä¼ ï¼ˆé¡µé¢åˆ·æ–°åæ¢å¤ä¸Šä¼ ï¼‰**

```javascript
async function resumeUpload() {
  const progress = getUploadProgress();
  if (!progress) return;

  const { fileHash, uploadId } = progress;
  const uploadedChunks = await checkUploadedChunks(fileHash);

  const file = getFileFromUser(); // ç”¨æˆ·é‡æ–°é€‰æ‹©ç›¸åŒçš„æ–‡ä»¶
  if (!file) return alert("è¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼");

  const chunks = sliceFile(file);

  for (let i = 0; i < chunks.length; i++) {
    if (!uploadedChunks.includes(String(i + 1))) {
      const urls = await getUploadUrls(fileHash, chunks.length);
      await uploadChunkToS3(urls[i], chunks[i]);
    }
  }

  await completeUpload(fileHash, uploadId);
  clearUploadProgress();
  console.log("ä¸Šä¼ å®Œæˆï¼");
}
```

------

### **âœ… 1.3 é¡µé¢åˆ·æ–°åè‡ªåŠ¨æ£€æŸ¥**

```javascript
window.addEventListener("load", async () => {
  if (getUploadProgress()) {
    const resume = confirm("æ£€æµ‹åˆ°æœªå®Œæˆçš„ä¸Šä¼ ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ");
    if (resume) await resumeUpload();
    else clearUploadProgress();
  }
});
```

------

## **ğŸ“Œ æ–¹æ¡ˆ 2ï¼šæ¸…é™¤å·²ä¸Šä¼ åˆ†ç‰‡**

å¦‚æœç”¨æˆ·æƒ³**æ¸…é™¤å·²ä¸Šä¼ çš„åˆ†ç‰‡**ï¼Œåç«¯éœ€è¦æä¾›ä¸€ä¸ª API æ¥åˆ é™¤ S3 ä¸­çš„å·²ä¸Šä¼ éƒ¨åˆ†ã€‚

------

### **âœ… 2.1 åç«¯åˆ é™¤ S3 åˆ†ç‰‡**

```python
def abort_upload(request):
    data = request.json()
    file_hash = data["hash"]

    # è·å–æ‰€æœ‰å·²ä¸Šä¼ çš„åˆ†ç‰‡
    objects_to_delete = s3_client.list_objects_v2(Bucket=settings.AWS_STORAGE_BUCKET_NAME, Prefix=f"uploads/{file_hash}")
    
    if "Contents" in objects_to_delete:
        s3_client.delete_objects(
            Bucket=settings.AWS_STORAGE_BUCKET_NAME,
            Delete={"Objects": [{"Key": obj["Key"]} for obj in objects_to_delete["Contents"]]}
        )

    return JsonResponse({"message": "å·²ä¸Šä¼ çš„åˆ†ç‰‡å·²æ¸…é™¤"})
```

------

### **âœ… 2.2 å‰ç«¯è°ƒç”¨æ¸…é™¤ API**

```javascript
async function clearUploadedChunks(fileHash) {
  await fetch("/api/upload/abort", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ hash: fileHash })
  });
  clearUploadProgress();
  console.log("å·²æ¸…é™¤ä¸Šä¼ åˆ†ç‰‡");
}
```

------

## **ğŸ“Œ æ€»ç»“**

### âœ… **é¡µé¢åˆ·æ–°åç»§ç»­ä¸Šä¼ **

1. **æœ¬åœ°å­˜å‚¨ `fileHash` å’Œ `uploadId`**
2. **é¡µé¢åˆ·æ–°åè·å–å·²ä¸Šä¼ çš„åˆ†ç‰‡**
3. **ç»§ç»­ä¸Šä¼ å‰©ä½™åˆ†ç‰‡**

### âœ… **æ¸…é™¤å·²ä¸Šä¼ æ•°æ®**

1. **ç”¨æˆ·æ‰‹åŠ¨è§¦å‘æ¸…é™¤ API**
2. **åç«¯åˆ é™¤ S3 å·²ä¸Šä¼ çš„åˆ†ç‰‡**
3. **æ¸…é™¤æœ¬åœ°å­˜å‚¨çš„è¿›åº¦**

è¿™æ ·æ— è®ºæ˜¯**æ–­ç‚¹ç»­ä¼ **è¿˜æ˜¯**æ¸…é™¤å·²ä¸Šä¼ æ•°æ®**ï¼Œéƒ½å¯ä»¥æµç•…åœ°å¤„ç†ï¼ğŸš€

### **ğŸ“Œ éœ€æ±‚åˆ†æ**

ä½ å¸Œæœ›ï¼š

1. **åŒæ—¶ä¸Šä¼ å¤šä¸ªåˆ†ç‰‡**ï¼Œæå‡ä¸Šä¼ é€Ÿåº¦ã€‚
2. **ä¸Šä¼ å®Œæˆä¸€ä¸ªåˆ†ç‰‡åï¼Œç«‹å³å¯åŠ¨æ–°çš„åˆ†ç‰‡**ï¼Œä¿è¯å¹¶å‘æ§åˆ¶ã€‚
3. **å¯ä»¥è‡ªç”±è®¾ç½®å¹¶å‘ä¸Šä¼ çš„åˆ†ç‰‡æ•°é‡**ã€‚

è¿™ç§æ–¹å¼ç§°ä¸º **â€œæµå¼å¹¶å‘ä¸Šä¼ â€**ï¼Œå¯ä»¥ä½¿ç”¨ **Promise é˜Ÿåˆ—** æ§åˆ¶ä¸Šä¼ å¹¶å‘æ•°ã€‚

------

## **âœ… å®ç°æ€è·¯**

1. **è®¾å®šæœ€å¤§å¹¶å‘æ•° `maxConcurrent`**ï¼Œä¾‹å¦‚ 3 ä¸ªã€‚
2. **ä½¿ç”¨é˜Ÿåˆ—è°ƒåº¦**ï¼šç»´æŠ¤ä¸€ä¸ªæ´»åŠ¨é˜Ÿåˆ—ï¼Œä¿è¯æœ€å¤šåŒæ—¶æ‰§è¡Œ `maxConcurrent` ä¸ªä¸Šä¼ ä»»åŠ¡ã€‚
3. **å®Œæˆä¸€ä¸ªåˆ†ç‰‡åç«‹å³å¯åŠ¨ä¸‹ä¸€ä¸ª**ï¼Œç›´åˆ°æ‰€æœ‰åˆ†ç‰‡å®Œæˆã€‚

------

## **âœ… Vue 3 å‰ç«¯å®ç°**

```javascript
async function uploadFileWithConcurrency(file, maxConcurrent = 3) {
  const fileHash = await calculateFileHash(file);
  const chunks = sliceFile(file);
  const { uploadId, urls } = await getUploadUrls(fileHash, chunks.length);

  let activeUploads = 0; // å½“å‰æ­£åœ¨ä¸Šä¼ çš„åˆ†ç‰‡æ•°
  let nextIndex = 0; // ä¸‹ä¸€ä¸ªå¾…ä¸Šä¼ çš„åˆ†ç‰‡ç´¢å¼•
  let completed = 0; // è®°å½•å®Œæˆçš„åˆ†ç‰‡æ•°

  return new Promise((resolve, reject) => {
    const uploadNext = async () => {
      if (nextIndex >= chunks.length) return;

      const index = nextIndex++; // å–å½“å‰ä¸Šä¼ çš„åˆ†ç‰‡ç´¢å¼•
      activeUploads++; // é€’å¢æ­£åœ¨ä¸Šä¼ çš„ä»»åŠ¡æ•°

      try {
        await uploadChunkToS3(urls[index], chunks[index]);
        completed++;
        console.log(`åˆ†ç‰‡ ${index + 1}/${chunks.length} ä¸Šä¼ å®Œæˆ`);
      } catch (error) {
        console.error(`åˆ†ç‰‡ ${index + 1} ä¸Šä¼ å¤±è´¥`, error);
        reject(error);
      }

      activeUploads--; // ä»»åŠ¡å®Œæˆï¼Œé‡Šæ”¾å¹¶å‘æ•°
      if (completed === chunks.length) {
        resolve(); // æ‰€æœ‰åˆ†ç‰‡ä¸Šä¼ å®Œæˆ
      } else {
        uploadNext(); // ç»§ç»­ä¸Šä¼ ä¸‹ä¸€ä¸ªåˆ†ç‰‡
      }
    };

    // å¯åŠ¨ `maxConcurrent` ä¸ªä¸Šä¼ ä»»åŠ¡
    for (let i = 0; i < Math.min(maxConcurrent, chunks.length); i++) {
      uploadNext();
    }
  }).then(() => completeUpload(fileHash, uploadId));
}
```

------

## **âœ… ä»£ç è§£æ**

1. **`maxConcurrent` æ§åˆ¶æœ€å¤§åŒæ—¶ä¸Šä¼ çš„ä»»åŠ¡æ•°**
2. **`activeUploads` è®°å½•å½“å‰æ­£åœ¨ä¸Šä¼ çš„åˆ†ç‰‡æ•°é‡**
3. **`nextIndex` è®°å½•ä¸‹ä¸€ä¸ªè¦ä¸Šä¼ çš„åˆ†ç‰‡ç´¢å¼•**
4. **`uploadNext()` é€’å½’è§¦å‘ä¸‹ä¸€ä¸ªåˆ†ç‰‡ä¸Šä¼ **
5. **å½“æ‰€æœ‰åˆ†ç‰‡å®Œæˆåï¼Œåˆå¹¶ S3 åˆ†ç‰‡**

------

## **âœ… å¦‚ä½•ä½¿ç”¨**

```javascript
const file = getFileFromUser(); // è®©ç”¨æˆ·é€‰æ‹©æ–‡ä»¶
uploadFileWithConcurrency(file, 5) // å¹¶å‘ 5 ä¸ªä¸Šä¼ 
  .then(() => console.log("âœ… æ–‡ä»¶ä¸Šä¼ å®Œæˆ"))
  .catch((err) => console.error("âŒ ä¸Šä¼ å¤±è´¥", err));
```

------

## **âœ… è¿™æ ·æœ‰ä»€ä¹ˆå¥½å¤„ï¼Ÿ**

ğŸš€ **å¹¶å‘æ§åˆ¶**ï¼šé¿å…ä¸€æ¬¡æ€§ä¸Šä¼ è¿‡å¤šåˆ†ç‰‡ï¼Œå‡å°‘ç½‘ç»œå‹åŠ›
 ğŸ“Œ **åŠ¨æ€è°ƒåº¦**ï¼šæ¯æ¬¡å®Œæˆä¸€ä¸ªåˆ†ç‰‡å°±è§¦å‘æ–°çš„ä¸Šä¼ 
 âš¡ **ä¸Šä¼ æ›´å¿«**ï¼šç›¸è¾ƒäºä¸²è¡Œä¸Šä¼ ï¼Œé€Ÿåº¦å¤§å¤§æå‡

è¿™æ ·ï¼Œä½ å¯ä»¥è‡ªç”±æ§åˆ¶**å¹¶å‘ä¸Šä¼ æ•°é‡**ï¼Œå¹¶ä¸”ä¿è¯æ–‡ä»¶ä¸Šä¼ çš„æµç•…æ€§å’Œç¨³å®šæ€§ï¼ğŸ”¥

### **ğŸ“Œ éœ€æ±‚åˆ†æ**

ä½ å¸Œæœ›åœ¨**åˆ†ç‰‡ä¸Šä¼ **æ—¶èƒ½å¤Ÿå®æ—¶è·å–**ä¸Šä¼ è¿›åº¦**ï¼Œä¸»è¦å…³æ³¨**åˆ†ç‰‡ä¸Šä¼ çš„è¿›åº¦**ï¼Œè€Œä¸éœ€è¦æ•´ä¸ªæ–‡ä»¶çš„è¿›åº¦ã€‚

### **âœ… è§£å†³æ–¹æ¡ˆ**

- **åˆ©ç”¨ `onprogress` ç›‘å¬ä¸Šä¼ è¿›åº¦**ï¼šåœ¨ `fetch` è¯·æ±‚æ—¶ï¼Œä½¿ç”¨ `XMLHttpRequest` ä»£æ›¿ `fetch`ï¼Œå¯ä»¥ç›‘å¬ `progress` äº‹ä»¶ã€‚
- **ç»´æŠ¤ `uploadedChunks` æ•°ç»„**ï¼šè®°å½•å·²å®Œæˆä¸Šä¼ çš„åˆ†ç‰‡æ•°é‡ã€‚
- **è®¡ç®—åˆ†ç‰‡è¿›åº¦**ï¼šé€šè¿‡ `(å·²ä¸Šä¼ åˆ†ç‰‡ / æ€»åˆ†ç‰‡) * 100` æ¥è®¡ç®—è¿›åº¦ã€‚

------

## **âœ… Vue 3 ä»£ç **

```javascript
async function uploadFileWithProgress(file, maxConcurrent = 3, onProgress = () => {}) {
  const fileHash = await calculateFileHash(file);
  const chunks = sliceFile(file);
  const { uploadId, urls } = await getUploadUrls(fileHash, chunks.length);

  let activeUploads = 0;
  let nextIndex = 0;
  let completedChunks = 0; // è®°å½•å®Œæˆçš„åˆ†ç‰‡æ•°é‡

  return new Promise((resolve, reject) => {
    const uploadNext = async () => {
      if (nextIndex >= chunks.length) return;

      const index = nextIndex++;
      activeUploads++;

      try {
        await uploadChunkWithProgress(urls[index], chunks[index], (progress) => {
          console.log(`åˆ†ç‰‡ ${index + 1} è¿›åº¦: ${progress}%`);
        });

        completedChunks++;
        onProgress((completedChunks / chunks.length) * 100); // æ›´æ–°æ•´ä½“è¿›åº¦
        console.log(`åˆ†ç‰‡ ${index + 1}/${chunks.length} ä¸Šä¼ å®Œæˆ`);
      } catch (error) {
        console.error(`åˆ†ç‰‡ ${index + 1} ä¸Šä¼ å¤±è´¥`, error);
        reject(error);
      }

      activeUploads--;
      if (completedChunks === chunks.length) {
        resolve();
      } else {
        uploadNext();
      }
    };

    for (let i = 0; i < Math.min(maxConcurrent, chunks.length); i++) {
      uploadNext();
    }
  }).then(() => completeUpload(fileHash, uploadId));
}
```

------

## **âœ… ç›‘å¬å•ä¸ªåˆ†ç‰‡ä¸Šä¼ è¿›åº¦**

```javascript
function uploadChunkWithProgress(url, chunk, onProgress) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    xhr.open("PUT", url, true);
    xhr.setRequestHeader("Content-Type", "application/octet-stream");

    xhr.upload.onprogress = (event) => {
      if (event.lengthComputable) {
        const progress = Math.round((event.loaded / event.total) * 100);
        onProgress(progress); // æ›´æ–°è¿›åº¦
      }
    };

    xhr.onload = () => {
      if (xhr.status === 200) {
        resolve();
      } else {
        reject(new Error(`ä¸Šä¼ å¤±è´¥: ${xhr.status}`));
      }
    };

    xhr.onerror = () => reject(new Error("ç½‘ç»œé”™è¯¯"));
    xhr.send(chunk);
  });
}
```

------

## **âœ… ä½¿ç”¨ç¤ºä¾‹**

```javascript
const file = getFileFromUser();

uploadFileWithProgress(file, 3, (progress) => {
  console.log(`ä¸Šä¼ è¿›åº¦: ${progress.toFixed(2)}%`);
}).then(() => {
  console.log("âœ… æ–‡ä»¶ä¸Šä¼ å®Œæˆ");
}).catch((err) => {
  console.error("âŒ ä¸Šä¼ å¤±è´¥", err);
});
```

------

## **âœ… æ•ˆæœ**

- **å¹¶å‘ä¸Šä¼ å¤šä¸ªåˆ†ç‰‡**
- **æ¯ä¸ªåˆ†ç‰‡ä¸Šä¼ æ—¶æœ‰è¿›åº¦å›è°ƒ**
- **è®¡ç®—æ•´ä½“ä¸Šä¼ è¿›åº¦**
- **æ¯å®Œæˆä¸€ä¸ªåˆ†ç‰‡å°±è§¦å‘æ–°çš„åˆ†ç‰‡ä¸Šä¼ **

è¿™æ ·ï¼Œä½ å¯ä»¥åœ¨å‰ç«¯ UI ä¸Š**å®æ—¶æ˜¾ç¤ºä¸Šä¼ è¿›åº¦**ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼ğŸš€ğŸ”¥

### **ğŸ“Œ æ–­ç‚¹ç»­ä¼  & é¡µé¢åˆ·æ–°åç»§ç»­ä¸Šä¼ **

> **é—®é¢˜ï¼š** é¡µé¢åˆ·æ–°åï¼Œ**æ–‡ä»¶å¯¹è±¡å·²ä¸¢å¤±**ï¼Œæ— æ³•ç»§ç»­ä¸Šä¼ ã€‚å¦‚ä½•è§£å†³ï¼Ÿ

------

## **âœ… è§£å†³æ–¹æ¡ˆ**

1. **è®°å½•ä¸Šä¼ çŠ¶æ€**ï¼šä½¿ç”¨ `localStorage` è®°å½• `fileHash`ã€`uploadId`ã€å·²ä¸Šä¼ åˆ†ç‰‡åˆ—è¡¨ã€‚
2. **æœåŠ¡å™¨æ£€æŸ¥å·²ä¸Šä¼ åˆ†ç‰‡**ï¼šåˆ·æ–°é¡µé¢åï¼Œå‰ç«¯å‘æœåŠ¡å™¨è¯·æ±‚å·²ä¸Šä¼ åˆ†ç‰‡ä¿¡æ¯ã€‚
3. **ç”¨æˆ·é€‰æ‹©åŒä¸€æ–‡ä»¶**ï¼šæç¤ºç”¨æˆ·é€‰æ‹©**ç›¸åŒçš„æ–‡ä»¶**ï¼Œç„¶åæ¯”å¯¹ `fileHash`ï¼Œç»§ç»­ä¸Šä¼ æœªå®Œæˆçš„åˆ†ç‰‡ã€‚

------

## **âœ… æ–¹æ¡ˆ 1ï¼šä½¿ç”¨ `localStorage` è®°å½•ä¸Šä¼ çŠ¶æ€**

```javascript
function saveUploadProgress(fileHash, uploadId, uploadedChunks) {
  localStorage.setItem("uploadProgress", JSON.stringify({ fileHash, uploadId, uploadedChunks }));
}

function getUploadProgress() {
  return JSON.parse(localStorage.getItem("uploadProgress"));
}

function clearUploadProgress() {
  localStorage.removeItem("uploadProgress");
}
```

### **âœ… è®°å½•ä¸Šä¼ è¿›åº¦**

æ¯å®Œæˆä¸€ä¸ªåˆ†ç‰‡ï¼Œå°±å­˜å‚¨ä¸Šä¼ è¿›åº¦ï¼š

```javascript
function updateUploadedChunks(fileHash, chunkIndex) {
  let progress = getUploadProgress();
  if (progress && progress.fileHash === fileHash) {
    progress.uploadedChunks.push(chunkIndex);
    saveUploadProgress(progress.fileHash, progress.uploadId, progress.uploadedChunks);
  }
}
```

------

## **âœ… æ–¹æ¡ˆ 2ï¼šé¡µé¢åˆ·æ–°åæ¢å¤ä¸Šä¼ **

1. **æ£€æŸ¥ `localStorage` æ˜¯å¦æœ‰æœªå®Œæˆçš„ä¸Šä¼ ä»»åŠ¡**ã€‚
2. **å‘æœåŠ¡å™¨è¯·æ±‚ `å·²ä¸Šä¼ åˆ†ç‰‡åˆ—è¡¨`**ï¼Œç¡®è®¤å“ªäº›åˆ†ç‰‡å·²å®Œæˆã€‚
3. **ç”¨æˆ·é€‰æ‹©ç›¸åŒçš„æ–‡ä»¶**ï¼Œæ¯”å¯¹ `fileHash` æ˜¯å¦ä¸€è‡´ã€‚
4. **ç»§ç»­ä¸Šä¼ æœªå®Œæˆçš„åˆ†ç‰‡**ã€‚

```javascript
async function resumeUpload() {
  const progress = getUploadProgress();
  if (!progress) return;

  const { fileHash, uploadId, uploadedChunks } = progress;

  // æœåŠ¡å™¨æ£€æŸ¥å·²ä¸Šä¼ çš„åˆ†ç‰‡
  const serverUploadedChunks = await checkUploadedChunks(fileHash);
  
  const file = getFileFromUser(); // ç”¨æˆ·é‡æ–°é€‰æ‹©æ–‡ä»¶
  if (!file) return alert("è¯·é‡æ–°é€‰æ‹©æ–‡ä»¶ï¼");

  // è®¡ç®—æ–‡ä»¶ hashï¼Œç¡®ä¿æ˜¯ç›¸åŒæ–‡ä»¶
  const newFileHash = await calculateFileHash(file);
  if (newFileHash !== fileHash) {
    alert("æ–‡ä»¶ä¸åŒ¹é…ï¼Œè¯·é€‰æ‹©ç›¸åŒçš„æ–‡ä»¶ï¼");
    return;
  }

  const chunks = sliceFile(file);
  const remainingChunks = chunks.filter((_, index) => !serverUploadedChunks.includes(index));

  for (const index of remainingChunks.keys()) {
    const urls = await getUploadUrls(fileHash, chunks.length);
    await uploadChunkToS3(urls[index], chunks[index]);
    updateUploadedChunks(fileHash, index);
  }

  await completeUpload(fileHash, uploadId);
  clearUploadProgress();
  console.log("ä¸Šä¼ å®Œæˆï¼");
}
```

------

## **âœ… æ–¹æ¡ˆ 3ï¼šåç«¯æ£€æŸ¥å·²ä¸Šä¼ çš„åˆ†ç‰‡**

> **Django æœåŠ¡å™¨ç«¯ API**

```python
from django.http import JsonResponse
import boto3
from my_project.settings import AWS_STORAGE_BUCKET_NAME

s3_client = boto3.client("s3")

def check_uploaded_chunks(request):
    file_hash = request.GET.get("hash")

    # è·å–æ‰€æœ‰å·²ä¸Šä¼ çš„åˆ†ç‰‡
    objects = s3_client.list_objects_v2(Bucket=AWS_STORAGE_BUCKET_NAME, Prefix=f"uploads/{file_hash}")

    uploaded_chunks = []
    if "Contents" in objects:
        uploaded_chunks = [obj["Key"].split("_")[-1] for obj in objects["Contents"]]

    return JsonResponse({"uploadedChunks": uploaded_chunks})
```

------

## **âœ… æ–¹æ¡ˆ 4ï¼šé¡µé¢åˆ·æ–°åè‡ªåŠ¨æ£€æŸ¥**

```javascript
window.addEventListener("load", async () => {
  if (getUploadProgress()) {
    const resume = confirm("æ£€æµ‹åˆ°æœªå®Œæˆçš„ä¸Šä¼ ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ");
    if (resume) await resumeUpload();
    else clearUploadProgress();
  }
});
```

------

## **âœ… æ–¹æ¡ˆ 5ï¼šç”¨æˆ·æ‰‹åŠ¨æ¸…é™¤å·²ä¸Šä¼ åˆ†ç‰‡**

å¦‚æœç”¨æˆ·**ä¸æƒ³ç»§ç»­ä¸Šä¼ **ï¼Œå¸Œæœ›æ¸…é™¤å·²ä¸Šä¼ çš„åˆ†ç‰‡ï¼š

```javascript
async function clearUploadedChunks(fileHash) {
  await fetch("/api/upload/abort", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ hash: fileHash })
  });
  clearUploadProgress();
  console.log("å·²æ¸…é™¤ä¸Šä¼ åˆ†ç‰‡");
}
```

------

## **âœ… æ€»ç»“**

### **ğŸŒŸ æ–­ç‚¹ç»­ä¼ æ–¹æ¡ˆ**

âœ… **å‰ç«¯å­˜å‚¨ä¸Šä¼ çŠ¶æ€ (`localStorage`)**
 âœ… **åç«¯æ£€æŸ¥å·²ä¸Šä¼ çš„åˆ†ç‰‡**
 âœ… **ç”¨æˆ·é€‰æ‹©ç›¸åŒæ–‡ä»¶ï¼Œæ ¡éªŒ `fileHash`**
 âœ… **ç»§ç»­ä¸Šä¼ æœªå®Œæˆçš„åˆ†ç‰‡**

### **âš¡ å¤„ç†åˆ·æ–°é—®é¢˜**

ğŸ”¹ **åˆ·æ–°é¡µé¢åï¼Œæç¤ºç”¨æˆ·é€‰æ‹©ç›¸åŒçš„æ–‡ä»¶**
 ğŸ”¹ **æ¯”å¯¹ `fileHash`ï¼Œé˜²æ­¢è¯¯ä¸Šä¼ **
 ğŸ”¹ **å‰ç«¯è·å– `localStorage` è®°å½•ï¼Œåç«¯æ£€æŸ¥å·²ä¸Šä¼ åˆ†ç‰‡**
 ğŸ”¹ **ä¸Šä¼ å‰©ä½™åˆ†ç‰‡ï¼Œå®Œæˆååˆå¹¶**

ğŸš€ è¿™æ ·å³ä½¿**é¡µé¢åˆ·æ–°ã€ç½‘ç»œä¸­æ–­**ï¼Œä¹Ÿèƒ½**æ— ç¼ç»§ç»­ä¸Šä¼ **ï¼ğŸ”¥

### **ğŸ“Œ é—®é¢˜åˆ†æ**

å¦‚æœ**ç”¨æˆ·åˆ·æ–°é¡µé¢åä¸é€‰æ‹©æ–‡ä»¶**ï¼Œæˆ‘ä»¬é¢ä¸´ä¸¤ä¸ªé—®é¢˜ï¼š

1. **æ–‡ä»¶å¯¹è±¡å·²ä¸¢å¤±**ï¼šæ— æ³•ç›´æ¥ç»§ç»­ä¸Šä¼ ï¼Œå› ä¸ºæµè§ˆå™¨ä¸ä¼šå­˜å‚¨ `File` å¯¹è±¡ã€‚
2. **ç”¨æˆ·å¯èƒ½ä¸æƒ³ç»§ç»­ä¸Šä¼ **ï¼šéœ€è¦æä¾›é€‰é¡¹è®©ç”¨æˆ·**ç»§ç»­ä¸Šä¼ **æˆ–**æ¸…é™¤å·²ä¸Šä¼ çš„æ•°æ®**ã€‚

------

## **âœ… è§£å†³æ–¹æ¡ˆ**

### **1ï¸âƒ£ è®©ç”¨æˆ·é€‰æ‹©æ–‡ä»¶**

- å¦‚æœç”¨æˆ·ä¸é€‰æ‹©æ–‡ä»¶ï¼Œæˆ‘ä»¬æ— æ³•ç»§ç»­ä¸Šä¼ ã€‚
- æç¤ºç”¨æˆ·**å¿…é¡»é€‰æ‹©ç›¸åŒçš„æ–‡ä»¶**ï¼Œå¦åˆ™æ— æ³•æ¢å¤ä¸Šä¼ ã€‚

```javascript
async function promptUserForFile() {
  return new Promise((resolve) => {
    const input = document.createElement("input");
    input.type = "file";
    input.onchange = () => resolve(input.files[0]);
    input.click();
  });
}
```

------

### **2ï¸âƒ£ é¡µé¢åˆ·æ–°åè‡ªåŠ¨æ£€æµ‹ä¸Šä¼ çŠ¶æ€**

**ğŸŒŸ é€»è¾‘**ï¼š

1. **æ£€æŸ¥ `localStorage` æ˜¯å¦æœ‰æœªå®Œæˆçš„ä¸Šä¼ **ã€‚
2. **æç¤ºç”¨æˆ·ç»§ç»­æˆ–æ¸…é™¤ä¸Šä¼ æ•°æ®**ã€‚
3. **å¦‚æœç”¨æˆ·é€‰æ‹©ç»§ç»­ï¼Œè¦æ±‚é€‰æ‹©ç›¸åŒçš„æ–‡ä»¶**ã€‚
4. **å¦‚æœç”¨æˆ·é€‰æ‹©å–æ¶ˆï¼Œæ¸…é™¤å·²ä¸Šä¼ çš„åˆ†ç‰‡**ã€‚

```javascript
window.addEventListener("load", async () => {
  const progress = getUploadProgress();
  if (!progress) return; // æ²¡æœ‰æœªå®Œæˆçš„ä¸Šä¼ 

  const resume = confirm("æ£€æµ‹åˆ°æœªå®Œæˆçš„ä¸Šä¼ ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ");

  if (resume) {
    const file = await promptUserForFile();
    if (!file) {
      alert("ä½ å¿…é¡»é€‰æ‹©ç›¸åŒçš„æ–‡ä»¶æ‰èƒ½ç»§ç»­ä¸Šä¼ ï¼");
      return;
    }

    const newFileHash = await calculateFileHash(file);
    if (newFileHash !== progress.fileHash) {
      alert("æ–‡ä»¶ä¸åŒ¹é…ï¼Œæ— æ³•ç»§ç»­ä¸Šä¼ ï¼");
      return;
    }

    await resumeUpload(file);
  } else {
    clearUploadProgress();
    await clearUploadedChunks(progress.fileHash);
    alert("å·²æ¸…é™¤æœªå®Œæˆçš„ä¸Šä¼ ï¼");
  }
});
```

------

### **3ï¸âƒ£ ç”¨æˆ·ä¸é€‰æ‹©æ–‡ä»¶æ€ä¹ˆåŠï¼Ÿ**

å¦‚æœç”¨æˆ·å…³é—­æ–‡ä»¶é€‰æ‹©æ¡†ï¼Œæˆ‘ä»¬å¯ä»¥ï¼š

- **ä¸€ç›´å¼¹å‡ºæç¤ºï¼Œç›´åˆ°ç”¨æˆ·é€‰æ‹©æ–‡ä»¶**ï¼ˆä¸æ¨èï¼Œå½±å“ä½“éªŒï¼‰ã€‚
- **ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨æ¢å¤**ï¼ˆæ¨èï¼‰ã€‚

> **ğŸŒŸ è§£å†³æ–¹æ¡ˆ**
>
> - å¦‚æœç”¨æˆ·ä¸é€‰æ‹©æ–‡ä»¶ï¼Œä¸ä¼šç»§ç»­ä¸Šä¼ ï¼Œä½†**ä¸ä¼šåˆ é™¤å·²ä¸Šä¼ çš„åˆ†ç‰‡**ã€‚
> - ä»¥åç”¨æˆ·ä»ç„¶å¯ä»¥é‡æ–°è¿›å…¥é¡µé¢ï¼Œæ‰‹åŠ¨æ¢å¤ä¸Šä¼ ã€‚

------

### **4ï¸âƒ£ æä¾›â€œç¨åæ¢å¤â€åŠŸèƒ½**

å¦‚æœç”¨æˆ·æš‚æ—¶ä¸æƒ³ä¸Šä¼ ï¼Œä½†æœªæ¥å¯èƒ½æƒ³ç»§ç»­ä¸Šä¼ ï¼š

1. **æä¾›ä¸€ä¸ªâ€œç¨åæ¢å¤â€æŒ‰é’®**ï¼Œå…è®¸ç”¨æˆ·æ‰‹åŠ¨æ¢å¤ä¸Šä¼ ã€‚
2. **è®© `localStorage` å­˜å‚¨æœªå®Œæˆçš„ä¸Šä¼ æ•°æ®**ï¼Œé¡µé¢åˆ·æ–°åä»ç„¶å¯ç”¨ã€‚

```html
<button id="resume-upload">æ¢å¤ä¸Šä¼ </button>
document.getElementById("resume-upload").addEventListener("click", async () => {
  const progress = getUploadProgress();
  if (!progress) {
    alert("æ²¡æœ‰æœªå®Œæˆçš„ä¸Šä¼ ï¼");
    return;
  }

  const file = await promptUserForFile();
  if (!file) {
    alert("ä½ å¿…é¡»é€‰æ‹©ç›¸åŒçš„æ–‡ä»¶æ‰èƒ½ç»§ç»­ä¸Šä¼ ï¼");
    return;
  }

  const newFileHash = await calculateFileHash(file);
  if (newFileHash !== progress.fileHash) {
    alert("æ–‡ä»¶ä¸åŒ¹é…ï¼Œæ— æ³•ç»§ç»­ä¸Šä¼ ï¼");
    return;
  }

  await resumeUpload(file);
});
```

------

## **âœ… æœ€ç»ˆæµç¨‹**

### **ğŸŒŸ ç”¨æˆ·åˆ·æ–°é¡µé¢å**

1. **æ£€æµ‹æ˜¯å¦æœ‰æœªå®Œæˆçš„ä¸Šä¼ **
2. **å¼¹å‡ºæç¤ºï¼šæ˜¯å¦ç»§ç»­ä¸Šä¼ ï¼Ÿ**
   - âœ… **ç”¨æˆ·åŒæ„** â†’ è®©ç”¨æˆ·é€‰æ‹©æ–‡ä»¶ â†’ æ ¡éªŒ `fileHash` â†’ ç»§ç»­ä¸Šä¼ 
   - âŒ **ç”¨æˆ·æ‹’ç»** â†’ è¯¢é—®æ˜¯å¦åˆ é™¤å·²ä¸Šä¼ çš„éƒ¨åˆ† â†’ æ¸…é™¤æ•°æ®
3. **ç”¨æˆ·å…³é—­æ–‡ä»¶é€‰æ‹©æ¡†**
   - **ä¸ä¼šç»§ç»­ä¸Šä¼ **
   - **ç¨åå¯ä»¥ç‚¹å‡»â€œæ¢å¤ä¸Šä¼ â€æŒ‰é’®ç»§ç»­**

------

## **âœ… æ€»ç»“**

**ğŸ“Œ ç”¨æˆ·ä¸é€‰æ‹©æ–‡ä»¶æ—¶çš„è§£å†³æ–¹æ¡ˆ**

| åœºæ™¯               | è§£å†³æ–¹æ¡ˆ                             |
| ------------------ | ------------------------------------ |
| ç”¨æˆ·åˆ·æ–°é¡µé¢å     | æç¤ºç»§ç»­ä¸Šä¼ æˆ–æ¸…é™¤æ•°æ®               |
| ç”¨æˆ·ä¸é€‰æ‹©æ–‡ä»¶     | ä¿ç•™å·²ä¸Šä¼ çš„åˆ†ç‰‡ï¼Œç­‰å¾…æ‰‹åŠ¨æ¢å¤       |
| ç”¨æˆ·æƒ³ç¨åä¸Šä¼      | æä¾›â€œæ¢å¤ä¸Šä¼ â€æŒ‰é’®ï¼Œæ‰‹åŠ¨æ¢å¤         |
| ç”¨æˆ·é€‰æ‹©é”™è¯¯çš„æ–‡ä»¶ | æ¯”å¯¹ `fileHash`ï¼Œé˜²æ­¢è¯¯ä¸Šä¼           |
| ç”¨æˆ·æ‹’ç»ç»§ç»­ä¸Šä¼    | æ¸…é™¤ `localStorage` å¹¶åˆ é™¤å·²ä¸Šä¼ åˆ†ç‰‡ |

------

## **âœ… è¿™æ ·æœ‰ä»€ä¹ˆå¥½å¤„ï¼Ÿ**

âœ… **ç”¨æˆ·æœ‰é€‰æ‹©æƒ**ï¼šå¯ä»¥ç»§ç»­ä¸Šä¼ ï¼Œä¹Ÿå¯ä»¥æ”¾å¼ƒ
 âœ… **æ•°æ®ä¸ä¼šä¸¢å¤±**ï¼šå³ä½¿ç”¨æˆ·å…³é—­é¡µé¢ï¼Œå·²ä¸Šä¼ çš„éƒ¨åˆ†ä»ç„¶ä¿å­˜
 âœ… **ä¸å½±å“ä½“éªŒ**ï¼šç”¨æˆ·å¯ä»¥ç¨åæ‰‹åŠ¨æ¢å¤ï¼Œä¸ä¼šå¼ºåˆ¶è¦æ±‚ç«‹åˆ»ä¸Šä¼ 

è¿™æ ·ï¼Œå³ä½¿ç”¨æˆ·åˆ·æ–°é¡µé¢ã€ä¸é€‰æ‹©æ–‡ä»¶ï¼Œç³»ç»Ÿä»ç„¶èƒ½å¤Ÿ**ä¿æŒçµæ´»æ€§**ï¼Œæä¾›æœ€å¥½çš„ç”¨æˆ·ä½“éªŒï¼ğŸš€ğŸ”¥

### **ğŸ“Œ Vue 3 + Django + S3 åˆ†ç‰‡ä¸Šä¼ ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰**

> æ–¹æ¡ˆæ”¯æŒ **å¤šåˆ†ç‰‡å¹¶å‘ä¸Šä¼ ã€é¡µé¢åˆ·æ–°åç»§ç»­ä¸Šä¼ ã€ç”¨æˆ·æ‰‹åŠ¨æ¢å¤ã€æ¸…é™¤å·²ä¸Šä¼ æ•°æ®**ã€‚

------

## **âœ… 1. å‰ç«¯ Vue 3 ä»£ç **

### **ğŸ“Œ 1.1 æ ¸å¿ƒä¸Šä¼ é€»è¾‘**

```javascript
import axios from "axios";

const S3_UPLOAD_API = "/api/upload"; // Django æœåŠ¡å™¨ä¸Šä¼  API

export default {
  data() {
    return {
      file: null,
      fileHash: null,
      uploadId: null,
      uploadedChunks: [],
      totalChunks: 0,
      maxConcurrent: 3, // å¹¶å‘ä¸Šä¼ åˆ†ç‰‡æ•°
    };
  },

  methods: {
    /** é€‰æ‹©æ–‡ä»¶ */
    async selectFile(event) {
      this.file = event.target.files[0];
      if (!this.file) return;

      this.fileHash = await this.calculateFileHash(this.file);
      this.loadPreviousProgress();
    },

    /** è®¡ç®—æ–‡ä»¶å“ˆå¸Œ */
    async calculateFileHash(file) {
      const buffer = await file.arrayBuffer();
      const hashBuffer = await crypto.subtle.digest("SHA-256", buffer);
      return Array.from(new Uint8Array(hashBuffer))
        .map((b) => b.toString(16).padStart(2, "0"))
        .join("");
    },

    /** åˆ‡ç‰‡æ–‡ä»¶ */
    sliceFile(file, chunkSize = 5 * 1024 * 1024) {
      const chunks = [];
      let offset = 0;
      while (offset < file.size) {
        chunks.push(file.slice(offset, offset + chunkSize));
        offset += chunkSize;
      }
      this.totalChunks = chunks.length;
      return chunks;
    },

    /** è¯·æ±‚ S3 ä¸Šä¼  URL */
    async getUploadUrls() {
      const response = await axios.post(`${S3_UPLOAD_API}/initiate`, {
        fileHash: this.fileHash,
        totalChunks: this.totalChunks,
      });
      this.uploadId = response.data.uploadId;
      return response.data.urls;
    },

    /** åŠ è½½å†å²è¿›åº¦ */
    async loadPreviousProgress() {
      const storedData = JSON.parse(localStorage.getItem("uploadProgress"));
      if (storedData?.fileHash === this.fileHash) {
        const serverResponse = await axios.get(`${S3_UPLOAD_API}/status`, {
          params: { fileHash: this.fileHash },
        });
        this.uploadedChunks = serverResponse.data.uploadedChunks;
        this.uploadId = storedData.uploadId;
        this.resumeUpload();
      } else {
        localStorage.removeItem("uploadProgress");
      }
    },

    /** æ–­ç‚¹ç»­ä¼  */
    async resumeUpload() {
      const chunks = this.sliceFile(this.file);
      const urls = await this.getUploadUrls();

      for (let i = 0; i < this.totalChunks; i++) {
        if (!this.uploadedChunks.includes(i)) {
          await this.uploadChunk(urls[i], chunks[i], i);
        }
      }

      await this.completeUpload();
    },

    /** ä¸Šä¼ åˆ†ç‰‡ */
    async uploadChunk(url, chunk, index) {
      return new Promise((resolve, reject) => {
        const xhr = new XMLHttpRequest();
        xhr.open("PUT", url, true);
        xhr.setRequestHeader("Content-Type", "application/octet-stream");

        xhr.upload.onprogress = (event) => {
          if (event.lengthComputable) {
            console.log(`åˆ†ç‰‡ ${index + 1}/${this.totalChunks} è¿›åº¦: ${Math.round((event.loaded / event.total) * 100)}%`);
          }
        };

        xhr.onload = () => {
          if (xhr.status === 200) {
            this.uploadedChunks.push(index);
            this.saveUploadProgress();
            resolve();
          } else {
            reject(new Error(`ä¸Šä¼ å¤±è´¥: ${xhr.status}`));
          }
        };

        xhr.onerror = () => reject(new Error("ç½‘ç»œé”™è¯¯"));
        xhr.send(chunk);
      });
    },

    /** ä¿å­˜ä¸Šä¼ è¿›åº¦ */
    saveUploadProgress() {
      localStorage.setItem("uploadProgress", JSON.stringify({
        fileHash: this.fileHash,
        uploadId: this.uploadId,
        uploadedChunks: this.uploadedChunks,
      }));
    },

    /** å®Œæˆä¸Šä¼  */
    async completeUpload() {
      await axios.post(`${S3_UPLOAD_API}/complete`, {
        fileHash: this.fileHash,
        uploadId: this.uploadId,
      });
      localStorage.removeItem("uploadProgress");
      alert("ä¸Šä¼ å®Œæˆï¼");
    },

    /** å–æ¶ˆä¸Šä¼  */
    async cancelUpload() {
      await axios.post(`${S3_UPLOAD_API}/abort`, { fileHash: this.fileHash });
      localStorage.removeItem("uploadProgress");
      alert("ä¸Šä¼ å·²å–æ¶ˆï¼");
    },
  },
};
```

------

## **âœ… 2. åç«¯ Django ä»£ç **

### **ğŸ“Œ 2.1 é…ç½® Django è§†å›¾**

```python
import boto3
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
import json
from my_project.settings import AWS_STORAGE_BUCKET_NAME

s3_client = boto3.client("s3")

@csrf_exempt
def initiate_upload(request):
    data = json.loads(request.body)
    file_hash = data["fileHash"]
    total_chunks = data["totalChunks"]

    upload_urls = []
    for i in range(total_chunks):
        upload_urls.append(
            s3_client.generate_presigned_url(
                "put_object",
                Params={
                    "Bucket": AWS_STORAGE_BUCKET_NAME,
                    "Key": f"uploads/{file_hash}_{i}",
                    "ContentType": "application/octet-stream",
                },
                ExpiresIn=3600,
            )
        )

    return JsonResponse({"uploadId": file_hash, "urls": upload_urls})


@csrf_exempt
def check_upload_status(request):
    file_hash = request.GET.get("fileHash")
    objects = s3_client.list_objects_v2(Bucket=AWS_STORAGE_BUCKET_NAME, Prefix=f"uploads/{file_hash}_")
    
    uploaded_chunks = []
    if "Contents" in objects:
        uploaded_chunks = [int(obj["Key"].split("_")[-1]) for obj in objects["Contents"]]

    return JsonResponse({"uploadedChunks": uploaded_chunks})


@csrf_exempt
def complete_upload(request):
    data = json.loads(request.body)
    file_hash = data["fileHash"]

    # æœåŠ¡å™¨å¯åœ¨æ­¤åˆå¹¶æ–‡ä»¶ï¼ˆå¦‚é€‚ç”¨ï¼‰
    return JsonResponse({"message": "Upload complete"})


@csrf_exempt
def abort_upload(request):
    data = json.loads(request.body)
    file_hash = data["fileHash"]

    objects = s3_client.list_objects_v2(Bucket=AWS_STORAGE_BUCKET_NAME, Prefix=f"uploads/{file_hash}_")
    if "Contents" in objects:
        for obj in objects["Contents"]:
            s3_client.delete_object(Bucket=AWS_STORAGE_BUCKET_NAME, Key=obj["Key"])

    return JsonResponse({"message": "Upload aborted"})
```

------

## **âœ… 3. è¿è¡Œæ–¹å¼**

### **ğŸŒŸ å‰ç«¯**

```sh
npm install axios
npm run dev
```

### **ğŸŒŸ åç«¯**

```sh
pip install boto3 django
python manage.py runserver
```

------

## **âœ… 4. æ–¹æ¡ˆè§£æ**

### **ğŸŒŸ æ–­ç‚¹ç»­ä¼ é€»è¾‘**

1. **ç”¨æˆ·é€‰æ‹©æ–‡ä»¶**
2. **è®¡ç®— `fileHash`**ï¼Œæ¯”å¯¹æ˜¯å¦å·²ä¸Šä¼ 
3. **æœåŠ¡å™¨è¿”å›å·²ä¸Šä¼ çš„åˆ†ç‰‡**
4. **ä¸Šä¼ å‰©ä½™çš„åˆ†ç‰‡**
5. **å®Œæˆä¸Šä¼ **

### **ğŸŒŸ é¡µé¢åˆ·æ–°å¤„ç†**

- **å­˜å‚¨ä¸Šä¼ è¿›åº¦ (`localStorage`)**
- **æœåŠ¡å™¨æ£€æŸ¥å·²ä¸Šä¼ åˆ†ç‰‡**
- **è¦æ±‚ç”¨æˆ·é€‰æ‹©ç›¸åŒæ–‡ä»¶**
- **æ¯”å¯¹ `fileHash`ï¼Œç»§ç»­ä¸Šä¼ **

------

## **âœ… 5. ç»ˆæä¼˜åŒ–**

âœ… **å¹¶å‘ä¸Šä¼ å¤šä¸ªåˆ†ç‰‡**
 âœ… **æ–­ç‚¹ç»­ä¼ ï¼ˆåˆ·æ–°åç»§ç»­ä¸Šä¼ ï¼‰**
 âœ… **å®æ—¶ä¸Šä¼ è¿›åº¦**
 âœ… **ç”¨æˆ·æ‰‹åŠ¨æ¢å¤æˆ–å–æ¶ˆä¸Šä¼ **
 âœ… **S3 é¢„ç­¾å URL ç›´ä¼ **

è¿™æ ·ï¼Œå³ä½¿ç”¨æˆ·**åˆ·æ–°é¡µé¢ã€æ–­ç½‘æˆ–é€‰æ‹©ç¨åä¸Šä¼ **ï¼Œä»èƒ½**æ— ç¼æ¢å¤ä¸Šä¼ **ï¼ğŸš€ğŸ”¥

### **ğŸ“Œ Vue 3 + Axios + Django + S3 é«˜æ€§èƒ½åˆ†ç‰‡ä¸Šä¼ **

> **ç›®æ ‡**ï¼š
>
> - âœ… **å‰ç«¯ Axios å¯å¤ç”¨å°è£…**
> - âœ… **åç«¯é«˜æ€§èƒ½å¤„ç†**
> - âœ… **å¤šåˆ†ç‰‡å¹¶å‘ä¸Šä¼ **
> - âœ… **æ”¯æŒæ–­ç‚¹ç»­ä¼ **
> - âœ… **S3 é¢„ç­¾å URL ç›´ä¼ **

------

## **âœ… 1. å‰ç«¯ Vue 3 ä»£ç **

> **ğŸŒŸ ä½¿ç”¨ Axios è¿›è¡Œå¯å¤ç”¨å°è£…**

### **ğŸ“Œ 1.1 åˆ†ç‰‡ä¸Šä¼ å°è£…**

```javascript
import axios from "axios";

const S3_UPLOAD_API = "/api/upload";

export default class ChunkUploader {
  constructor(file, options = {}) {
    this.file = file;
    this.chunkSize = options.chunkSize || 5 * 1024 * 1024; // 5MB åˆ†ç‰‡
    this.maxConcurrent = options.maxConcurrent || 3; // å¹¶å‘æ•°
    this.uploadId = null;
    this.fileHash = null;
    this.uploadedChunks = [];
  }

  /** è®¡ç®—æ–‡ä»¶ Hashï¼ˆSHA-256ï¼‰ */
  async calculateFileHash() {
    const buffer = await this.file.arrayBuffer();
    const hashBuffer = await crypto.subtle.digest("SHA-256", buffer);
    this.fileHash = Array.from(new Uint8Array(hashBuffer))
      .map((b) => b.toString(16).padStart(2, "0"))
      .join("");
  }

  /** åˆ‡ç‰‡æ–‡ä»¶ */
  sliceFile() {
    const chunks = [];
    let offset = 0;
    while (offset < this.file.size) {
      chunks.push(this.file.slice(offset, offset + this.chunkSize));
      offset += this.chunkSize;
    }
    return chunks;
  }

  /** åˆå§‹åŒ–ä¸Šä¼  */
  async initiateUpload() {
    await this.calculateFileHash();
    const response = await axios.post(`${S3_UPLOAD_API}/initiate`, {
      fileHash: this.fileHash,
      totalChunks: this.sliceFile().length,
    });
    this.uploadId = response.data.uploadId;
    return response.data.urls;
  }

  /** è·å–å·²ä¸Šä¼ çš„åˆ†ç‰‡ */
  async checkUploadedChunks() {
    const response = await axios.get(`${S3_UPLOAD_API}/status`, {
      params: { fileHash: this.fileHash },
    });
    this.uploadedChunks = response.data.uploadedChunks || [];
  }

  /** ä¸Šä¼ å•ä¸ªåˆ†ç‰‡ */
  async uploadChunk(url, chunk, index) {
    return axios.put(url, chunk, {
      headers: { "Content-Type": "application/octet-stream" },
      onUploadProgress: (event) => {
        if (event.lengthComputable) {
          console.log(`åˆ†ç‰‡ ${index + 1} ä¸Šä¼ è¿›åº¦: ${Math.round((event.loaded / event.total) * 100)}%`);
        }
      },
    }).then(() => {
      this.uploadedChunks.push(index);
      this.saveProgress();
    });
  }

  /** æ–­ç‚¹ç»­ä¼  */
  async resumeUpload() {
    await this.checkUploadedChunks();
    const chunks = this.sliceFile();
    const urls = await this.initiateUpload();

    const uploadQueue = [];
    for (let i = 0; i < chunks.length; i++) {
      if (!this.uploadedChunks.includes(i)) {
        const uploadPromise = this.uploadChunk(urls[i], chunks[i], i);
        uploadQueue.push(uploadPromise);

        if (uploadQueue.length >= this.maxConcurrent) {
          await Promise.race(uploadQueue);
          uploadQueue.splice(0, uploadQueue.length - this.maxConcurrent);
        }
      }
    }
    
    await Promise.all(uploadQueue);
    await this.completeUpload();
  }

  /** å®Œæˆä¸Šä¼  */
  async completeUpload() {
    await axios.post(`${S3_UPLOAD_API}/complete`, {
      fileHash: this.fileHash,
      uploadId: this.uploadId,
    });
    localStorage.removeItem("uploadProgress");
    console.log("ä¸Šä¼ å®Œæˆï¼");
  }

  /** ä¿å­˜è¿›åº¦ */
  saveProgress() {
    localStorage.setItem("uploadProgress", JSON.stringify({
      fileHash: this.fileHash,
      uploadId: this.uploadId,
      uploadedChunks: this.uploadedChunks,
    }));
  }

  /** å–æ¶ˆä¸Šä¼  */
  async cancelUpload() {
    await axios.post(`${S3_UPLOAD_API}/abort`, { fileHash: this.fileHash });
    localStorage.removeItem("uploadProgress");
    console.log("ä¸Šä¼ å·²å–æ¶ˆï¼");
  }
}
```

------

### **ğŸ“Œ 1.2 Vue ç»„ä»¶è°ƒç”¨**

```vue
<template>
  <div>
    <input type="file" @change="handleFileSelect" />
    <button @click="resumeUpload">æ¢å¤ä¸Šä¼ </button>
  </div>
</template>

<script>
import ChunkUploader from "@/utils/ChunkUploader";

export default {
  data() {
    return {
      uploader: null,
    };
  },
  methods: {
    async handleFileSelect(event) {
      const file = event.target.files[0];
      if (!file) return;
      this.uploader = new ChunkUploader(file);
      await this.uploader.resumeUpload();
    },
    async resumeUpload() {
      if (this.uploader) {
        await this.uploader.resumeUpload();
      }
    },
  },
};
</script>
```

------

## **âœ… 2. åç«¯ Django é«˜æ€§èƒ½ API**

### **ğŸ“Œ 2.1 é«˜æ•ˆ S3 ç›´ä¼ **

```python
import boto3
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
import json
from my_project.settings import AWS_STORAGE_BUCKET_NAME

s3_client = boto3.client("s3")

@csrf_exempt
def initiate_upload(request):
    data = json.loads(request.body)
    file_hash = data["fileHash"]
    total_chunks = data["totalChunks"]

    urls = [
        s3_client.generate_presigned_url(
            "put_object",
            Params={
                "Bucket": AWS_STORAGE_BUCKET_NAME,
                "Key": f"uploads/{file_hash}_{i}",
                "ContentType": "application/octet-stream",
            },
            ExpiresIn=3600,
        )
        for i in range(total_chunks)
    ]

    return JsonResponse({"uploadId": file_hash, "urls": urls})

@csrf_exempt
def check_upload_status(request):
    file_hash = request.GET.get("fileHash")
    objects = s3_client.list_objects_v2(Bucket=AWS_STORAGE_BUCKET_NAME, Prefix=f"uploads/{file_hash}_")

    uploaded_chunks = []
    if "Contents" in objects:
        uploaded_chunks = [int(obj["Key"].split("_")[-1]) for obj in objects["Contents"]]

    return JsonResponse({"uploadedChunks": uploaded_chunks})

@csrf_exempt
def complete_upload(request):
    data = json.loads(request.body)
    file_hash = data["fileHash"]
    
    return JsonResponse({"message": "Upload complete"})

@csrf_exempt
def abort_upload(request):
    data = json.loads(request.body)
    file_hash = data["fileHash"]

    objects = s3_client.list_objects_v2(Bucket=AWS_STORAGE_BUCKET_NAME, Prefix=f"uploads/{file_hash}_")
    if "Contents" in objects:
        for obj in objects["Contents"]:
            s3_client.delete_object(Bucket=AWS_STORAGE_BUCKET_NAME, Key=obj["Key"])

    return JsonResponse({"message": "Upload aborted"})
```

------

## **âœ… 3. æ–¹æ¡ˆç‰¹ç‚¹**

âœ… **å‰ç«¯ Axios å°è£…ï¼Œå¯å¤ç”¨**
 âœ… **å¤šåˆ†ç‰‡å¹¶å‘ä¸Šä¼ ï¼Œæå‡é€Ÿåº¦**
 âœ… **è‡ªåŠ¨æ–­ç‚¹ç»­ä¼ ï¼ˆé¡µé¢åˆ·æ–°åå¯ç»§ç»­ä¸Šä¼ ï¼‰**
 âœ… **å¯æ‰‹åŠ¨å–æ¶ˆä¸Šä¼ å¹¶æ¸…é™¤å·²ä¸Šä¼ çš„åˆ†ç‰‡**
 âœ… **S3 é¢„ç­¾å URL ç›´ä¼ ï¼Œå‡å°‘åç«¯è´Ÿæ‹…**
 âœ… **Django é«˜æ€§èƒ½å¤„ç†ï¼Œæ— éœ€ä¸­è½¬æ•°æ®**

è¿™æ ·ï¼Œå³ä½¿ç”¨æˆ·**åˆ·æ–°é¡µé¢ã€æ–­ç½‘ã€æˆ–è€…ç¨åä¸Šä¼ **ï¼Œä»ç„¶èƒ½**æ— ç¼æ¢å¤ä¸Šä¼ **ï¼ğŸš€

### **ğŸ“Œ å¢åŠ æ–‡ä»¶çº§åˆ«çš„ä¸Šä¼ è¿›åº¦**

æˆ‘ä»¬éœ€è¦åœ¨ **å‰ç«¯** è®¡ç®—æ•´ä¸ªæ–‡ä»¶çš„è¿›åº¦ï¼Œè€Œä¸ä»…ä»…æ˜¯å•ä¸ªåˆ†ç‰‡çš„è¿›åº¦ã€‚

------

## **âœ… 1. ä¿®æ”¹å‰ç«¯ `ChunkUploader` æ”¯æŒæ•´ä½“è¿›åº¦**

**å…³é”®æ”¹åŠ¨ï¼š**

1. **è®¡ç®—æ•´ä½“è¿›åº¦**ï¼šä½¿ç”¨ `totalUploadedBytes / file.size`ã€‚
2. **æ¯ä¸ªåˆ†ç‰‡ä¸Šä¼ å®Œæˆåï¼Œæ›´æ–°è¿›åº¦**ã€‚
3. **æ”¯æŒ `onProgress` å›è°ƒ**ï¼Œæ–¹ä¾¿ UI ç»„ä»¶ç›‘å¬ã€‚

```javascript
import axios from "axios";

const S3_UPLOAD_API = "/api/upload";

export default class ChunkUploader {
  constructor(file, options = {}) {
    this.file = file;
    this.chunkSize = options.chunkSize || 5 * 1024 * 1024; // 5MB åˆ†ç‰‡
    this.maxConcurrent = options.maxConcurrent || 3; // å¹¶å‘ä¸Šä¼ æ•°
    this.uploadId = null;
    this.fileHash = null;
    this.uploadedChunks = [];
    this.totalUploadedBytes = 0;
    this.onProgress = options.onProgress || (() => {}); // è¿›åº¦å›è°ƒ
  }

  /** è®¡ç®—æ–‡ä»¶ Hash */
  async calculateFileHash() {
    const buffer = await this.file.arrayBuffer();
    const hashBuffer = await crypto.subtle.digest("SHA-256", buffer);
    this.fileHash = Array.from(new Uint8Array(hashBuffer))
      .map((b) => b.toString(16).padStart(2, "0"))
      .join("");
  }

  /** åˆ‡ç‰‡æ–‡ä»¶ */
  sliceFile() {
    const chunks = [];
    let offset = 0;
    while (offset < this.file.size) {
      chunks.push(this.file.slice(offset, offset + this.chunkSize));
      offset += this.chunkSize;
    }
    return chunks;
  }

  /** åˆå§‹åŒ–ä¸Šä¼  */
  async initiateUpload() {
    await this.calculateFileHash();
    const response = await axios.post(`${S3_UPLOAD_API}/initiate`, {
      fileHash: this.fileHash,
      totalChunks: this.sliceFile().length,
    });
    this.uploadId = response.data.uploadId;
    return response.data.urls;
  }

  /** è·å–å·²ä¸Šä¼ çš„åˆ†ç‰‡ */
  async checkUploadedChunks() {
    const response = await axios.get(`${S3_UPLOAD_API}/status`, {
      params: { fileHash: this.fileHash },
    });
    this.uploadedChunks = response.data.uploadedChunks || [];
    this.totalUploadedBytes = this.uploadedChunks.length * this.chunkSize;
  }

  /** ä¸Šä¼ å•ä¸ªåˆ†ç‰‡ */
  async uploadChunk(url, chunk, index) {
    return axios.put(url, chunk, {
      headers: { "Content-Type": "application/octet-stream" },
      onUploadProgress: (event) => {
        if (event.lengthComputable) {
          const chunkProgress = event.loaded / event.total;
          this.totalUploadedBytes = this.uploadedChunks.length * this.chunkSize + event.loaded;
          this.updateProgress();
        }
      },
    }).then(() => {
      this.uploadedChunks.push(index);
      this.totalUploadedBytes = this.uploadedChunks.length * this.chunkSize;
      this.updateProgress();
      this.saveProgress();
    });
  }

  /** æ›´æ–°æ–‡ä»¶æ€»è¿›åº¦ */
  updateProgress() {
    const progress = Math.min((this.totalUploadedBytes / this.file.size) * 100, 100);
    this.onProgress(progress);
  }

  /** æ–­ç‚¹ç»­ä¼  */
  async resumeUpload() {
    await this.checkUploadedChunks();
    const chunks = this.sliceFile();
    const urls = await this.initiateUpload();

    const uploadQueue = [];
    for (let i = 0; i < chunks.length; i++) {
      if (!this.uploadedChunks.includes(i)) {
        const uploadPromise = this.uploadChunk(urls[i], chunks[i], i);
        uploadQueue.push(uploadPromise);

        if (uploadQueue.length >= this.maxConcurrent) {
          await Promise.race(uploadQueue);
          uploadQueue.splice(0, uploadQueue.length - this.maxConcurrent);
        }
      }
    }
    
    await Promise.all(uploadQueue);
    await this.completeUpload();
  }

  /** å®Œæˆä¸Šä¼  */
  async completeUpload() {
    await axios.post(`${S3_UPLOAD_API}/complete`, {
      fileHash: this.fileHash,
      uploadId: this.uploadId,
    });
    localStorage.removeItem("uploadProgress");
    this.updateProgress();
    console.log("ä¸Šä¼ å®Œæˆï¼");
  }

  /** ä¿å­˜è¿›åº¦ */
  saveProgress() {
    localStorage.setItem("uploadProgress", JSON.stringify({
      fileHash: this.fileHash,
      uploadId: this.uploadId,
      uploadedChunks: this.uploadedChunks,
    }));
  }

  /** å–æ¶ˆä¸Šä¼  */
  async cancelUpload() {
    await axios.post(`${S3_UPLOAD_API}/abort`, { fileHash: this.fileHash });
    localStorage.removeItem("uploadProgress");
    console.log("ä¸Šä¼ å·²å–æ¶ˆï¼");
  }
}
```

------

## **âœ… 2. ä¿®æ”¹ Vue ç»„ä»¶ï¼Œæ˜¾ç¤ºæ–‡ä»¶è¿›åº¦**

**å…³é”®ç‚¹**ï¼š

1. **ç›‘å¬ `onProgress` äº‹ä»¶**ï¼Œå®æ—¶æ›´æ–° UIã€‚
2. **è¿›åº¦æ¡æ˜¾ç¤ºå½“å‰æ–‡ä»¶çš„ä¸Šä¼ è¿›åº¦**ã€‚

```vue
<template>
  <div>
    <input type="file" @change="handleFileSelect" />
    <button @click="resumeUpload" v-if="uploader">æ¢å¤ä¸Šä¼ </button>
    <div v-if="progress > 0">
      ä¸Šä¼ è¿›åº¦: {{ progress.toFixed(2) }}%
      <progress :value="progress" max="100"></progress>
    </div>
  </div>
</template>

<script>
import ChunkUploader from "@/utils/ChunkUploader";

export default {
  data() {
    return {
      uploader: null,
      progress: 0,
    };
  },
  methods: {
    async handleFileSelect(event) {
      const file = event.target.files[0];
      if (!file) return;
      this.uploader = new ChunkUploader(file, {
        onProgress: (progress) => {
          this.progress = progress;
        },
      });
      await this.uploader.resumeUpload();
    },
    async resumeUpload() {
      if (this.uploader) {
        await this.uploader.resumeUpload();
      }
    },
  },
};
</script>
```

------

## **âœ… 3. ç»“æœ**

### **ğŸ”¥ ç°åœ¨ï¼Œä½ èƒ½å®ç°**

âœ” **æ”¯æŒæ–‡ä»¶çº§è¿›åº¦æ˜¾ç¤º** ğŸ¯
 âœ” **åˆ†ç‰‡ä¸Šä¼ å®Œæˆå³æ›´æ–° UI** ğŸ“Š
 âœ” **é¡µé¢åˆ·æ–°åè¿˜èƒ½ç»§ç»­æ˜¾ç¤ºè¿›åº¦** ğŸ”„
 âœ” **æ–­ç‚¹ç»­ä¼ ï¼Œæ–­æ‰ä¹Ÿèƒ½ç»§ç»­ä¸Šä¼ ** ğŸš€

è¿™æ ·ï¼Œæ•´ä¸ªä¸Šä¼ è¿‡ç¨‹çš„**è¿›åº¦**å°±å¯ä»¥**å®æ—¶æ˜¾ç¤º**ï¼ğŸš€
