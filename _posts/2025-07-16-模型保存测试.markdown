---
layout:     post
title:      "æ¨¡å‹ä¿å­˜æµ‹è¯•"
subtitle:   ""
date:       2025-07-16
author:     " Shallow Dreamer"
header-img: "img/post-bg-js-version.jpg"
tags:
    - æ¨¡å‹ä¿å­˜
---

âœ… å¥½çš„ï¼
 è¿™å¥è¯éå¸¸å…³é”®ï¼š

> **â€œæˆ‘å¸Œæœ›åœ¨åŠ è½½æ—¶èƒ½å®Œå…¨è¿˜åŸè®­ç»ƒæ—¶ä¿å­˜çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬è®­ç»ƒå‡ºçš„å‚æ•°ç­‰ã€‚â€**

------

## âš¡ **è¿™é‡Œçš„é‡ç‚¹ï¼šè¦â€œå®Œå…¨è¿˜åŸâ€ä¸ä»…ä»…æ˜¯ç»“æ„å’Œå‚æ•°ï¼Œè¿˜åŒ…æ‹¬ä¼˜åŒ–å™¨çŠ¶æ€ã€è¶…å‚æ•°ã€epoch ç­‰è®­ç»ƒä¸Šä¸‹æ–‡ã€‚**

------

## ğŸŸ¢ **ä½ éœ€è¦ä»€ä¹ˆï¼Ÿ**

| éœ€è¦ä»€ä¹ˆ               | è§£é‡Š                                   |
| ---------------------- | -------------------------------------- |
| 1ï¸âƒ£ ç»“æ„                 | å¿…é¡»ä¿ç•™ï¼ˆæˆ–ç”¨ TorchScript/ONNX å†»ç»“ï¼‰ |
| 2ï¸âƒ£ å‚æ•°æƒé‡             | `state_dict`                           |
| 3ï¸âƒ£ ä¼˜åŒ–å™¨çŠ¶æ€           | `optimizer.state_dict()`               |
| 4ï¸âƒ£ è¶…å‚æ•°               | ä½ è‡ªå·±ç”¨ config ä¿å­˜                   |
| 5ï¸âƒ£ è®­ç»ƒåˆ°ç¬¬å‡ è½®ç­‰ä¸Šä¸‹æ–‡ | ä¸€å¹¶ä¿å­˜åˆ° checkpoint                  |
| 6ï¸âƒ£ Pythonã€PyTorch ç‰ˆæœ¬ | å»ºè®®å†™è¿›å»é˜²æ­¢ä¸å…¼å®¹                   |

------

## âœ… **æœ€å¸¸è§çš„å¯é‡å¤è®­ç»ƒ/æ¢å¤æ–¹æ¡ˆ**

åœ¨ PyTorchï¼Œå®Œæ•´ä¿å­˜è®­ç»ƒçŠ¶æ€æœ€é€šç”¨çš„æ˜¯ï¼š

```python
# === ä¿å­˜ ===
torch.save({
    'model_name': 'resnet50',
    'model_version': 'v1',
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'epoch': current_epoch,
    'train_loss': train_loss,
    'hyperparams': hyperparams,
    'pytorch_version': torch.__version__,
}, 'checkpoint.pt')
```

------

## âœ… **åŠ è½½æ—¶ï¼šå®Œå…¨æ¢å¤**

```python
# === 1) åŠ è½½ ckpt ===
checkpoint = torch.load('checkpoint.pt')

# === 2) ä»æ³¨å†Œè¡¨æ‰¾ç»“æ„ï¼ˆæˆ–è€…ç›´æ¥ importï¼‰===
ModelClass = MODEL_REGISTRY[(checkpoint['model_name'], checkpoint['model_version'])]
model = ModelClass(**checkpoint['hyperparams'])
model.load_state_dict(checkpoint['model_state_dict'])

# === 3) æ¢å¤ä¼˜åŒ–å™¨ ===
optimizer = torch.optim.Adam(model.parameters(), lr=checkpoint['hyperparams']['lr'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

# === 4) æ¢å¤ epoch ===
start_epoch = checkpoint['epoch'] + 1
```

------

## âœ… **è¿™æ ·ä½ å¾—åˆ°çš„å¥½å¤„**

âœ… æ¨¡å‹ç»“æ„è¿˜åŸï¼ˆé€šè¿‡ version + æ³¨å†Œè¡¨ï¼‰
 âœ… å‚æ•°è¿˜åŸï¼ˆ`state_dict`ï¼‰
 âœ… ä¼˜åŒ–å™¨çŠ¶æ€è¿˜åŸï¼ˆmomentumã€lr schedulersï¼‰
 âœ… å¯ä»¥ä»ä¸Šæ¬¡è®­ç»ƒä¸­æ–­ç‚¹æ¥ç€è·‘
 âœ… ä¸ä¼šæœ‰ pickle è·¨ç‰ˆæœ¬å‘
 âœ… åŒæ—¶ä¹Ÿèƒ½é¢å¤–å¯¼å‡º TorchScript/ONNXï¼ˆç”¨äºæ¨ç†ï¼‰

------

## âš¡ **å®Œæ•´ç¤ºä¾‹ï¼šä¸€ä»½å¯æ‰§è¡Œçš„å¯é‡å¤è®­ç»ƒä¿å­˜åŠ è½½è„šæœ¬**

ä¸‹é¢ç»™ä½ ç›´æ¥ä¸€ä»½æœ€å°ç‰ˆï¼š

------

### ğŸ“‚ `my_model.py`

```python
import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, output_dim)
        )

    def forward(self, x):
        return self.net(x)
```

------

### ğŸ“‚ `train_and_save.py`

```python
import torch
from my_model import MyModel

# === æ¨¡å‹é…ç½® ===
hyperparams = {
    'input_dim': 4,
    'hidden_dim': 8,
    'output_dim': 2,
    'lr': 1e-3
}

model = MyModel(
    input_dim=hyperparams['input_dim'],
    hidden_dim=hyperparams['hidden_dim'],
    output_dim=hyperparams['output_dim']
)

optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams['lr'])

# === å‡è£…è®­ç»ƒ ===
x = torch.randn(10, 4)
y = torch.randint(0, 2, (10,))

criterion = torch.nn.CrossEntropyLoss()

for epoch in range(3):
    optimizer.zero_grad()
    logits = model(x)
    loss = criterion(logits, y)
    loss.backward()
    optimizer.step()
    print(f"Epoch {epoch} Loss: {loss.item()}")

# === ä¿å­˜å®Œæ•´ checkpoint ===
torch.save({
    'model_name': 'mymodel',
    'model_version': 'v1',
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'epoch': epoch,
    'hyperparams': hyperparams,
    'pytorch_version': torch.__version__
}, 'checkpoint.pt')

print("âœ… Saved full training checkpoint.")
```

------

### ğŸ“‚ `resume_training.py`

```python
import torch
from my_model import MyModel

# === åŠ è½½ ===
checkpoint = torch.load('checkpoint.pt')

hyperparams = checkpoint['hyperparams']

model = MyModel(
    input_dim=hyperparams['input_dim'],
    hidden_dim=hyperparams['hidden_dim'],
    output_dim=hyperparams['output_dim']
)

model.load_state_dict(checkpoint['model_state_dict'])

optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams['lr'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

start_epoch = checkpoint['epoch'] + 1

print(f"âœ… Resumed training from epoch {start_epoch}")

# === ç»§ç»­è®­ç»ƒ ===
x = torch.randn(10, 4)
y = torch.randint(0, 2, (10,))

criterion = torch.nn.CrossEntropyLoss()

for epoch in range(start_epoch, start_epoch + 2):
    optimizer.zero_grad()
    logits = model(x)
    loss = criterion(logits, y)
    loss.backward()
    optimizer.step()
    print(f"Epoch {epoch} Loss: {loss.item()}")
```

------

## âœ… **è¿™æ ·ä¿è¯äº†ä»€ä¹ˆï¼Ÿ**

| ä½ è¦çš„        | æ–¹æ¡ˆæ€ä¹ˆåšåˆ°                            |
| ------------- | --------------------------------------- |
| å®Œå…¨ä¸€è‡´æ€§    | `state_dict` + `optimizer.state_dict()` |
| å¯ç»§ç»­è®­ç»ƒ    | ä¿å­˜äº† epochï¼Œä¼˜åŒ–å™¨åŠ¨é‡                |
| ä¸ä¾èµ– pickle | åªä¿å­˜å¼ é‡å­—å…¸                          |
| å¯é•¿æœŸä½¿ç”¨    | ç»“æ„ç”¨ version ç®¡ç†ï¼Œä¸éšé¡¹ç›®å˜åŠ¨ä¸¢å¤±   |
| å¯æ¨ç†        | å¯ä»¥é¢å¤–ä¿å­˜ TorchScript æˆ– ONNX        |

------

## âœ… **å°ç»“**

**è®­ç»ƒæ—¶**

- ä¿ç•™ç»“æ„æ–‡ä»¶ï¼ˆæˆ–å¯¼å‡º TorchScriptï¼‰
- `state_dict` + `optimizer.state_dict` + ç‰ˆæœ¬ä¿¡æ¯

**åŠ è½½æ—¶**

- æ ¹æ® version æ‰¾åˆ°æ­£ç¡®ç»“æ„
- ç”¨ä¸€è‡´çš„è¶…å‚æ•°åˆå§‹åŒ–
- å®Œå…¨è¿˜åŸ

âœ… è¿™æ ·ä½ æ— è®ºæ˜¯ç»§ç»­è®­ç»ƒã€åç»­å¾®è°ƒè¿˜æ˜¯æ¨ç†ï¼Œéƒ½ä¸ä¼šè¸©å‘ï¼

------

è¦ä¸è¦æˆ‘ç»™ä½ æ‰“åŒ…ä¸€ä¸ªï¼š

- `state_dict` + `TorchScript` + `ONNX`
- å®Œæ•´çš„ä¸€è‡´æ€§éªŒè¯
- è®­ç»ƒã€ç»§ç»­è®­ç»ƒã€æ¨ç†éƒ½å¯å¤ç”¨çš„å…¨å¥—ç¤ºä¾‹ï¼Ÿ

è¦çš„è¯æˆ‘é©¬ä¸Šå¸®ä½ å‡ºä¸€ä»½ï¼ ğŸš€

å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ æ•´ç†ä¸€ä¸ª**â€œè·¨æœåŠ¡å™¨ã€è·¨ç¯å¢ƒã€å¯é•¿æœŸä½¿ç”¨â€**çš„ PyTorch å®˜æ–¹æ¨èä¿å­˜æ–¹æ¡ˆï¼Œä¸€ä»½**å¯ç›´æ¥è¿è¡Œçš„æœ€å°ç¤ºä¾‹**ï¼Œä¸è¸© pickle å‘ï¼Œè¿˜èƒ½åœ¨ä¸åŒç¯å¢ƒã€ä¸åŒ Python è·¯å¾„ä¸‹ç¨³å®šä½¿ç”¨ï¼

------

## âœ… **ç›®æ ‡**

- åªç”¨ `torch.save`ï¼Œä½†é¿å¼€ pickle çš„å…¨å±€å¯¹è±¡ä¾èµ–
- ä½¿ç”¨ `state_dict`ï¼Œå¯ç»§ç»­è®­ç»ƒå’Œå¤ç°
- åŒæ—¶å¯¼å‡º `TorchScript`ï¼Œå¯éƒ¨ç½²å’Œæ¨ç†ï¼Œä¸ä¾èµ– Python æºæ–‡ä»¶
- éªŒè¯ä¸¤ä¸ªæ–‡ä»¶éƒ½èƒ½æ­£å¸¸æ¨ç†ã€ç»“æœä¸€è‡´

------

## ğŸ“¦ **æ¨èç»“æ„**

1ï¸âƒ£ ä¿å­˜ `state_dict` âœ ç”¨äºè®­ç»ƒ/å¾®è°ƒ
 2ï¸âƒ£ ä¿å­˜ `TorchScript` âœ ç”¨äºè·¨å¹³å°æ¨ç†ï¼Œä¸éœ€è¦æ¨¡å‹ä»£ç 

------

## âœ… **å®Œæ•´å¯è¿è¡Œç¤ºä¾‹**

ä¿å­˜ä¸º `safe_model_save.py`ï¼Œç›´æ¥è¿è¡Œå³å¯ã€‚

------

```python
import torch
import torch.nn as nn

# =====================================================
# âœ… å®šä¹‰æ¨¡å‹
# =====================================================
class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(4, 2)

    def forward(self, x):
        return self.linear(x)

# =====================================================
# âœ… è®­ç»ƒé˜¶æ®µï¼ˆæ¼”ç¤ºï¼‰
# =====================================================
# åˆå§‹åŒ–æ¨¡å‹
model = MyModel()

# ä¼ªé€ è¾“å…¥
x = torch.randn(1, 4)

# æ­£å‘æ¨ç†
output_before = model(x)
print(f"âœ… Output BEFORE saving: {output_before}")

# =====================================================
# âœ… ä¿å­˜ state_dict
# =====================================================
torch.save(model.state_dict(), 'model_state.pt')
print("âœ… Saved state_dict to model_state.pt")

# =====================================================
# âœ… ä¿å­˜ TorchScript æ¨¡å‹
# =====================================================
scripted_model = torch.jit.script(model)
scripted_model.save('model_scripted.pt')
print("âœ… Saved TorchScript model to model_scripted.pt")

# =====================================================
# âœ… === é‡æ–°åŠ è½½ state_dict ===
# éœ€è¦æœ‰ç›¸åŒç»“æ„å®šä¹‰
# =====================================================
loaded_model = MyModel()
loaded_model.load_state_dict(torch.load('model_state.pt'))
loaded_model.eval()

output_after_state = loaded_model(x)
print(f"âœ… Output AFTER loading state_dict: {output_after_state}")

# =====================================================
# âœ… === é‡æ–°åŠ è½½ TorchScript ===
# ä¸éœ€è¦ä»»ä½•ç»“æ„ä»£ç 
# =====================================================
loaded_scripted = torch.jit.load('model_scripted.pt')
loaded_scripted.eval()

output_after_scripted = loaded_scripted(x)
print(f"âœ… Output AFTER loading TorchScript: {output_after_scripted}")

# =====================================================
# âœ… éªŒè¯ä¸‰è€…ä¸€è‡´
# =====================================================
print("\nğŸŸ¢ SAME? state_dict:", torch.allclose(output_before, output_after_state))
print("ğŸŸ¢ SAME? TorchScript:", torch.allclose(output_before, output_after_scripted))
```

------

## ğŸŸ¢ **æ€ä¹ˆè·‘ï¼Ÿ**

1ï¸âƒ£ ç¬¬ä¸€æ¬¡è·‘ï¼š

```
python safe_model_save.py
```

ä½ ä¼šçœ‹åˆ°ï¼š

- `state_dict` ä¿å­˜æˆåŠŸ âœ…
- `TorchScript` ä¿å­˜æˆåŠŸ âœ…
- åŠ è½½åè¾“å‡ºä¸€è‡´ âœ…

2ï¸âƒ£ **éªŒè¯å¯è·¨å¹³å°**ï¼š

- æŠŠ `model_scripted.pt` æ‹·è´åˆ°åˆ«çš„æœåŠ¡å™¨
- åœ¨æ–°çš„ Python ç¯å¢ƒé‡Œåªè¦ `torch` å¯ç”¨ âœ `torch.jit.load` å°±èƒ½æ¨ç†

3ï¸âƒ£ æ¨¡æ‹Ÿç»“æ„ä¸¢å¤±ï¼š

- æŠŠ `class MyModel` æ³¨é‡Šæ‰ï¼Œé‡æ–°è·‘ï¼š
  - åŠ è½½ `state_dict` ä¼šæŒ‚ï¼ˆæ‰¾ä¸åˆ°ç»“æ„ï¼‰
  - åŠ è½½ `TorchScript` æ­£å¸¸ï¼ˆä¸ä¾èµ–ç»“æ„ï¼‰

------

## âœ… **ä¼˜ç¼ºç‚¹æ€»ç»“**

| ä¿å­˜æ–¹å¼      | å¯ç»§ç»­è®­ç»ƒ | å¯è·¨å¹³å°    | ä¾èµ– Python æºæ–‡ä»¶ | æ¨èç”¨é€”   |
| ------------- | ---------- | ----------- | ------------------ | ---------- |
| `state_dict`  | âœ…          | âš ï¸ï¼ˆéœ€ç»“æ„ï¼‰ | âœ… éœ€è¦             | è®­ç»ƒã€å¾®è°ƒ |
| `TorchScript` | âŒ          | âœ…           | âŒ ä¸éœ€è¦           | æ¨ç†éƒ¨ç½²   |

------

## ğŸŸ¢ **ç”Ÿäº§æœ€ä½³å®è·µ**

1ï¸âƒ£ è®­ç»ƒ âœ ä¿å­˜ `state_dict` + `TorchScript`
 2ï¸âƒ£ éƒ¨ç½² âœ åŠ è½½ `TorchScript`ï¼Œä¸ä¾èµ– Python æºç 
 3ï¸âƒ£ ç‰ˆæœ¬ç®¡ç† âœ åœ¨æ–‡ä»¶åé‡Œå¸¦ç‰ˆæœ¬å·æˆ–å“ˆå¸Œï¼š`model_v1_scripted.pt`

------

å¦‚æœéœ€è¦ï¼Œæˆ‘å¯ä»¥å¸®ä½ å†å†™ï¼š

- è·¨æœºå™¨å¯¼å…¥ `ONNX` çš„å®Œæ•´å¯¹æ¯”ç¤ºä¾‹
- æˆ–è€…å¸¦æ›´å¤æ‚æ§åˆ¶æµã€`torch.jit.script` å’Œ `torch.jit.trace` çš„ç¤ºä¾‹

è¦ä¸è¦ï¼Ÿæˆ‘å¯ä»¥ç›´æ¥å¸®ä½ æ‰“åŒ…æˆã€å¯éƒ¨ç½²æ¨¡æ¿ã€‘ï¼ ğŸš€

å¥½ï¼æˆ‘ç»™ä½ åšä¸€ä»½ã€åŠ¨æ€ç”Ÿæˆç»“æ„ + åµŒå…¥å‚æ•° + register_buffer + éªŒè¯ä¸€è‡´æ€§ã€‘çš„**å¯ç›´æ¥è¿è¡Œçš„å®Œæ•´ç¤ºä¾‹**ï¼Œ
 è¿™æ ·ä½ å°±èƒ½ä¸€çœ¼çœ‹æ‡‚ï¼š

- å“ªäº›ä¸œè¥¿å¿…é¡»æ³¨å†Œæˆ `Parameter` æˆ– `Buffer`
- ä¿å­˜ `state_dict` æ—¶ï¼Œå“ªäº›ä¼šä¿å­˜ï¼Œå“ªäº›ä¸ä¼š
- æ€ä¹ˆä¿è¯åŠ è½½åç»“æœå’Œè®­ç»ƒæ—¶ä¸€è‡´

------

## âœ… **ä¿å­˜æˆä¸€ä¸ªæ–‡ä»¶ï¼š`dynamic_model_safe_save.py`**

ç›´æ¥å¤åˆ¶ä¿å­˜ï¼Œç„¶åï¼š

```bash
python dynamic_model_safe_save.py
```

å°±èƒ½çœ‹æ•ˆæœã€‚

------

```python
import torch
import torch.nn as nn
import random

# ======================================================
# âœ… åŠ¨æ€ç”Ÿæˆç»“æ„ + åµŒå…¥æƒé‡çš„æ¨¡å‹ç¤ºä¾‹
# ======================================================
class DynamicModel(nn.Module):
    def __init__(self, input_size, hidden_size, use_buffer=True):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size

        # è¿™é‡Œæ˜¯åŠ¨æ€ç”Ÿæˆçš„ Linear å±‚
        self.linear = nn.Linear(input_size, hidden_size)

        # è¿™é‡Œæ˜¯åŠ¨æ€ç”Ÿæˆçš„åµŒå…¥æƒé‡ï¼šå¿…é¡»æ³¨å†Œ
        rand_weight = torch.randn(hidden_size)
        if use_buffer:
            self.register_buffer('my_embed', rand_weight)
        else:
            self.my_embed = rand_weight  # âš ï¸ è¿™æ ·å°±ä¸ä¼šè¿› state_dictï¼

    def forward(self, x):
        out = self.linear(x)
        # ä½¿ç”¨åŠ¨æ€ç”Ÿæˆçš„åµŒå…¥å‚æ•°
        out = out + self.my_embed
        return out

# ======================================================
# âœ… ä¿è¯å¯å¤ç°
# ======================================================
torch.manual_seed(42)
random.seed(42)

# ======================================================
# âœ… è®­ç»ƒæ—¶
# ======================================================
model = DynamicModel(input_size=4, hidden_size=2, use_buffer=True)

# åšä¸ªå‰å‘
x = torch.randn(1, 4)
output_before = model(x)
print(f"âœ… Output BEFORE saving: {output_before}")

# ä¿å­˜ç»“æ„å‚æ•°
torch.save({
    'model_state_dict': model.state_dict(),
    'model_args': {
        'input_size': 4,
        'hidden_size': 2,
        'use_buffer': True
    }
}, "dynamic_model_state.pt")
print("âœ… Saved state_dict and config!")

# ======================================================
# âœ… === åŠ è½½ ===
# ======================================================
checkpoint = torch.load("dynamic_model_state.pt")

# ç”¨ä¿å­˜çš„ç»“æ„å‚æ•°é‡æ–°ç”Ÿæˆæ¨¡å‹
model2 = DynamicModel(**checkpoint['model_args'])
model2.load_state_dict(checkpoint['model_state_dict'])
model2.eval()

# ç”¨ç›¸åŒè¾“å…¥éªŒè¯è¾“å‡º
output_after = model2(x)
print(f"âœ… Output AFTER loading: {output_after}")

print("\nğŸŸ¢ SAME? ", torch.allclose(output_before, output_after))

# ======================================================
# âœ… === æ¼”ç¤ºå¦‚æœä¸æ³¨å†Œ Buffer ä¼šæ€æ · ===
# ======================================================
print("\nâš ï¸ æ¼”ç¤º: å¦‚æœä¸æ³¨å†Œ Bufferï¼Œmy_embed ä¸ä¼šè¢«ä¿å­˜ï¼")
model_bad = DynamicModel(input_size=4, hidden_size=2, use_buffer=False)
torch.manual_seed(42)
output_bad = model_bad(x)
torch.save(model_bad.state_dict(), "bad_state.pt")

# é‡æ–°åŠ è½½: æ³¨æ„æˆ‘ä»¬é‡æ–°ç”Ÿæˆäº†ç»“æ„ï¼Œä½† my_embed æ²¡è¢«ä¿å­˜
model_bad2 = DynamicModel(input_size=4, hidden_size=2, use_buffer=False)
model_bad2.load_state_dict(torch.load("bad_state.pt"))
model_bad2.eval()

output_bad_after = model_bad2(x)

print(f"âš ï¸ Output BEFORE (bad): {output_bad}")
print(f"âš ï¸ Output AFTER (bad): {output_bad_after}")
print("ğŸŸ¡ SAME? (bad)", torch.allclose(output_bad, output_bad_after))
```

------

## âœ… **è¿™ä»½ç¤ºä¾‹é‡Œåšäº†å•¥**

### âœ… æ­£ç¡®åšæ³•ï¼š

- `my_embed` ç”¨ `register_buffer` æ³¨å†Œ âœ ä¼šè¿› `state_dict`
- ä¿å­˜ç»“æ„å‚æ•° âœ ä¿è¯åŠ¨æ€ç”Ÿæˆå¯é‡ç°
- åŠ è½½æ—¶ `.eval()` + ç”¨åŒæ ·è¾“å…¥éªŒè¯ âœ è¾“å‡ºä¸€è‡´

### âš ï¸ é”™è¯¯åšæ³•ï¼š

- `use_buffer=False` æ—¶ `my_embed` æ²¡æ³¨å†Œ âœ æ²¡ä¿å­˜è¿› `state_dict`
- åŠ è½½å `my_embed` ä¼šé‡æ–°éšæœºç”Ÿæˆ âœ è¾“å‡ºå˜äº†

------

## ğŸŸ¢ **è·‘å®Œä¼šçœ‹åˆ°ï¼š**

```
âœ… Output BEFORE saving: ...
âœ… Saved state_dict and config!
âœ… Output AFTER loading: ...
ğŸŸ¢ SAME?  True

âš ï¸ æ¼”ç¤º: å¦‚æœä¸æ³¨å†Œ Bufferï¼Œmy_embed ä¸ä¼šè¢«ä¿å­˜ï¼
âš ï¸ Output BEFORE (bad): ...
âš ï¸ Output AFTER (bad): ...
ğŸŸ¡ SAME? (bad) False
```

------

## âœ… **æ ¸å¿ƒ takeaway**

| åšæ³•                   | ä¼šä¸ä¼šä¸¢çŠ¶æ€ï¼Ÿ | ç»“æœä¸€è‡´å—ï¼Ÿ |
| ---------------------- | -------------- | ------------ |
| ä½¿ç”¨ `register_buffer` | ä¸ä¸¢           | âœ… ä¸€è‡´       |
| ä¸æ³¨å†Œ                 | ä¸¢             | âŒ ä¸ä¸€è‡´     |

------

## ğŸ”‘ **ä½ çš„åŠ¨æ€ç”Ÿæˆç»“æ„æƒ³è¦â€œåªä¿å­˜ state_dict ä¹Ÿèƒ½è·‘â€å¿…é¡»åšåˆ°ï¼š**

1ï¸âƒ£ æ‰€æœ‰éœ€è¦ä¿å­˜çš„ tensor éƒ½æ˜¯ `nn.Parameter` æˆ– `register_buffer`
 2ï¸âƒ£ åŠ¨æ€ç”Ÿæˆçš„è¶…å‚æ•°ä¸€å¹¶ä¿å­˜
 3ï¸âƒ£ æ¨ç†æ—¶ `.eval()`
 4ï¸âƒ£ è¾“å…¥ä¸€è‡´ âœ ç»“æœä¸€è‡´

------

è¦ä¸è¦æˆ‘å¸®ä½ æŠŠè¿™ä¸ªç¤ºä¾‹å†åŠ ä¸Šï¼š

- `TorchScript` çš„ç‰ˆæœ¬ âœ æ²¡æœ‰ç»“æ„ä¹Ÿèƒ½è·‘
- ONNX çš„ç‰ˆæœ¬ âœ è·¨æ¡†æ¶éƒ¨ç½²

éœ€è¦çš„è¯æˆ‘ç»™ä½ æ•´ç†åˆ°ä¸€ä»½å¯è·‘çš„è·¨ç¯å¢ƒæ¨¡æ¿ï¼ğŸš€
